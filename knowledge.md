Python 3.10.16
pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121

conda activate mind

channels:
  - defaults
custom_channels:
    conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
    simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
default_channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2
show_channel_urls: True

# **é¡¹ç›®åŒ…å«**

- my_minimind-LLMç»“æ„çš„å…¨éƒ¨ä»£ç ï¼ˆDense+MoEæ¨¡å‹ï¼‰ã€‚
- åŒ…å«Tokenizeråˆ†è¯å™¨è¯¦ç»†è®­ç»ƒä»£ç ã€‚
- åŒ…å«Pretrainã€SFTã€LoRAã€RLHF-DPOã€æ¨¡å‹è’¸é¦çš„å…¨è¿‡ç¨‹è®­ç»ƒä»£ç ã€‚
- æ”¶é›†ã€è’¸é¦ã€æ•´ç†å¹¶æ¸…æ´—å»é‡æ‰€æœ‰é˜¶æ®µçš„é«˜è´¨é‡æ•°æ®é›†ï¼Œä¸”å…¨éƒ¨å¼€æºã€‚
- ä»0å®ç°é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒã€LoRAã€DPOå¼ºåŒ–å­¦ä¹ ï¼Œç™½ç›’æ¨¡å‹è’¸é¦ã€‚å…³é”®ç®—æ³•å‡ ä¹ä¸ä¾èµ–ç¬¬ä¸‰æ–¹å°è£…çš„æ¡†æ¶ï¼Œä¸”å…¨éƒ¨å¼€æºã€‚
- åŒæ—¶å…¼å®¹`transformers`ã€`trl`ã€`peft`ç­‰ç¬¬ä¸‰æ–¹ä¸»æµæ¡†æ¶ã€‚
- è®­ç»ƒæ”¯æŒå•æœºå•å¡ã€å•æœºå¤šå¡(DDPã€DeepSpeed)è®­ç»ƒï¼Œæ”¯æŒwandbå¯è§†åŒ–è®­ç»ƒæµç¨‹ã€‚æ”¯æŒåŠ¨æ€å¯åœè®­ç»ƒã€‚
- åœ¨ç¬¬ä¸‰æ–¹æµ‹è¯„æ¦œï¼ˆC-Evalã€C-MMLUã€OpenBookQAç­‰ï¼‰è¿›è¡Œæ¨¡å‹æµ‹è¯•ã€‚
- å®ç°Openai-Apiåè®®çš„æç®€æœåŠ¡ç«¯ï¼Œä¾¿äºé›†æˆåˆ°ç¬¬ä¸‰æ–¹ChatUIä½¿ç”¨ï¼ˆFastGPTã€Open-WebUIç­‰ï¼‰ã€‚
- åŸºäºstreamlitå®ç°æœ€ç®€èŠå¤©WebUIå‰ç«¯ã€‚
- å¤ç°(è’¸é¦/RL)å¤§å‹æ¨ç†æ¨¡å‹DeepSeek-R1çš„my_minimind-Reasonæ¨¡å‹ï¼Œ**æ•°æ®+æ¨¡å‹**å…¨éƒ¨å¼€æº

# ğŸ“Œ å¿«é€Ÿå¼€å§‹

<details style="color:rgb(128,128,128)">
<summary>åˆ†äº«æœ¬äººçš„è½¯ç¡¬ä»¶é…ç½®ï¼ˆä»…ä¾›å‚è€ƒï¼‰</summary>



* CPU: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz
* RAM: 128 GB
* GPU: NVIDIA GeForce RTX 3090(24GB) * 8
* Ubuntu==20.04
* CUDA==12.1
* Python==3.10.16
* [requirements.txt](./requirements.txt)

</details>

```bash
git clone https://github.com/jingyaogong/my_minimind.git

'2.2.2+cu121'
```

## â…  æµ‹è¯•å·²æœ‰æ¨¡å‹æ•ˆæœ

### 1.ç¯å¢ƒå‡†å¤‡

```bash
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### 2.ä¸‹è½½æ¨¡å‹

```bash
# my_minimind2æ”¾åœ¨my_minimindçš„æ ¹ç›®å½•
git clone https://huggingface.co/jingyaogong/my_minimind2
```

### 3.å¯åŠ¨WebUI

```bash
# å¯èƒ½éœ€è¦`python>=3.10` å®‰è£… `pip install streamlit`
cd scripts
streamlit run web_demo.py
```

## å¼€å§‹è®­ç»ƒ

### é¢„è®­ç»ƒ(Pretrain)ï¼ˆå­¦çŸ¥è¯†ï¼‰

è¿™ä¸ªè¿‡ç¨‹æ˜¯â€œæ— ç›‘ç£â€çš„ï¼Œå³äººç±»ä¸éœ€è¦åœ¨è¿‡ç¨‹ä¸­åšä»»ä½•â€œæœ‰ç›‘ç£â€çš„æ ¡æ­£ï¼Œè€Œæ˜¯ç”±æ¨¡å‹è‡ªå·±ä»å¤§é‡æ–‡æœ¬ä¸­æ€»ç»“è§„å¾‹å­¦ä¹ çŸ¥è¯†ç‚¹ã€‚
æ¨¡å‹æ­¤é˜¶æ®µç›®çš„åªæœ‰ä¸€ä¸ªï¼š**å­¦ä¼šè¯è¯­æ¥é¾™**ã€‚ä¾‹å¦‚æˆ‘ä»¬è¾“å…¥â€œç§¦å§‹çš‡â€å››ä¸ªå­—ï¼Œå®ƒå¯ä»¥æ¥é¾™â€œæ˜¯ä¸­å›½çš„ç¬¬ä¸€ä½çš‡å¸â€ã€‚

> ```bash
> python train_pretrain.py
> ```
>
> è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”`100æ­¥`ä¿å­˜ä¸º `pretrain_*.pth` ä½œä¸ºé¢„è®­ç»ƒçš„è¾“å‡ºæƒé‡ï¼ˆå…¶ä¸­*ä¸ºæ¨¡å‹çš„dimensionï¼Œé»˜è®¤ä¸º512ï¼‰

### æœ‰ç›‘ç£å¾®è°ƒ(Supervised Fine-Tuning):ï¼ˆå­¦å¯¹è¯æ–¹å¼ï¼‰

SFTé˜¶æ®µå°±éœ€è¦æŠŠåŠæˆå“LLMæ–½åŠ ä¸€ä¸ªè‡ªå®šä¹‰çš„èŠå¤©æ¨¡æ¿è¿›è¡Œå¾®è°ƒã€‚
ä¾‹å¦‚æ¨¡å‹é‡åˆ°è¿™æ ·çš„æ¨¡æ¿ã€é—®é¢˜->å›ç­”ï¼Œé—®é¢˜->å›ç­”ã€‘åä¸å†æ— è„‘æ¥é¾™ï¼Œè€Œæ˜¯æ„è¯†åˆ°è¿™æ˜¯ä¸€æ®µå®Œæ•´çš„å¯¹è¯ç»“æŸã€‚
ç§°è¿™ä¸ªè¿‡ç¨‹ä¸ºæŒ‡ä»¤å¾®è°ƒï¼Œå°±å¦‚åŒè®©å·²ç»å­¦å¯Œäº”è½¦çš„ã€Œç‰›é¡¿ã€å…ˆç”Ÿé€‚åº”21ä¸–çºªæ™ºèƒ½æ‰‹æœºçš„èŠå¤©ä¹ æƒ¯ï¼Œå­¦ä¹ å±å¹•å·¦ä¾§æ˜¯å¯¹æ–¹æ¶ˆæ¯ï¼Œå³ä¾§æ˜¯æœ¬äººæ¶ˆæ¯è¿™ä¸ªè§„å¾‹ã€‚
åœ¨è®­ç»ƒæ—¶ï¼Œmy_minimindçš„æŒ‡ä»¤å’Œå›ç­”é•¿åº¦è¢«æˆªæ–­åœ¨512ï¼Œæ˜¯ä¸ºäº†èŠ‚çœæ˜¾å­˜ç©ºé—´ã€‚å°±åƒæˆ‘ä»¬å­¦ä¹ æ—¶ï¼Œä¼šå…ˆä»çŸ­çš„æ–‡ç« å¼€å§‹ï¼Œå½“å­¦ä¼šå†™ä½œ200å­—ä½œæ–‡åï¼Œ800å­—æ–‡ç« ä¹Ÿå¯ä»¥æ‰‹åˆ°æ“’æ¥ã€‚

> ```bash
> python train_full_sft.py
> ```
>
> æ‰§è¡Œç›‘ç£å¾®è°ƒï¼Œå¾—åˆ° `full_sft_*.pth` ä½œä¸ºæŒ‡ä»¤å¾®è°ƒçš„è¾“å‡ºæƒé‡ï¼ˆå…¶ä¸­`full`å³ä¸ºå…¨å‚æ•°å¾®è°ƒï¼‰
>
> 
> æ‰€æœ‰è®­ç»ƒè¿‡ç¨‹é»˜è®¤æ¯éš”100æ­¥ä¿å­˜1æ¬¡å‚æ•°åˆ°æ–‡ä»¶`./out/***.pth`ï¼ˆæ¯æ¬¡ä¼šè¦†ç›–æ‰æ—§æƒé‡æ–‡ä»¶ï¼‰ã€‚
>
> ç®€å•èµ·è§ï¼Œæ­¤å¤„åªå†™æ˜ä¸¤ä¸ªé˜¶æ®µè®­ç»ƒè¿‡ç¨‹ã€‚å¦‚éœ€å…¶å®ƒè®­ç»ƒ (LoRA, è’¸é¦, å¼ºåŒ–å­¦ä¹ , å¾®è°ƒæ¨ç†ç­‰) å¯å‚è€ƒä¸‹æ–‡ã€å®éªŒã€‘å°èŠ‚çš„è¯¦ç»†è¯´æ˜ã€‚

### äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ (Reinforcement Learning from Human Feedback, RLHF)

åœ¨å‰é¢çš„è®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¨¡å‹å·²ç»å…·å¤‡äº†åŸºæœ¬çš„å¯¹è¯èƒ½åŠ›ï¼Œä½†æ˜¯è¿™æ ·çš„èƒ½åŠ›å®Œå…¨åŸºäºå•è¯æ¥é¾™ï¼Œç¼ºå°‘æ­£åæ ·ä¾‹çš„æ¿€åŠ±ã€‚
æ¨¡å‹æ­¤æ—¶å°šæœªçŸ¥ä»€ä¹ˆå›ç­”æ˜¯å¥½çš„ï¼Œä»€ä¹ˆæ˜¯å·®çš„ã€‚æˆ‘ä»¬å¸Œæœ›å®ƒèƒ½å¤Ÿæ›´ç¬¦åˆäººçš„åå¥½ï¼Œé™ä½è®©äººç±»ä¸æ»¡æ„ç­”æ¡ˆçš„äº§ç”Ÿæ¦‚ç‡ã€‚
è¿™ä¸ªè¿‡ç¨‹å°±åƒæ˜¯è®©æ¨¡å‹å‚åŠ æ–°çš„åŸ¹è®­ï¼Œä»ä¼˜ç§€å‘˜å·¥çš„ä½œä¸ºä¾‹å­ï¼Œæ¶ˆæå‘˜å·¥ä½œä¸ºåä¾‹ï¼Œå­¦ä¹ å¦‚ä½•æ›´å¥½åœ°å›å¤ã€‚
æ­¤å¤„ä½¿ç”¨çš„æ˜¯RLHFç³»åˆ—ä¹‹-ç›´æ¥åå¥½ä¼˜åŒ–(Direct Preference Optimization, DPO)ã€‚
ä¸PPO(Proximal Policy Optimization)è¿™ç§éœ€è¦å¥–åŠ±æ¨¡å‹ã€ä»·å€¼æ¨¡å‹çš„RLç®—æ³•ä¸åŒï¼›
DPOé€šè¿‡æ¨å¯¼PPOå¥–åŠ±æ¨¡å‹çš„æ˜¾å¼è§£ï¼ŒæŠŠåœ¨çº¿å¥–åŠ±æ¨¡å‹æ¢æˆç¦»çº¿æ•°æ®ï¼ŒRefæ¨¡å‹è¾“å‡ºå¯ä»¥æå‰ä¿å­˜ã€‚
DPOæ€§èƒ½å‡ ä¹ä¸å˜ï¼Œåªç”¨è·‘ actor_model å’Œ ref_model ä¸¤ä¸ªæ¨¡å‹ï¼Œå¤§å¤§èŠ‚çœæ˜¾å­˜å¼€é”€å’Œå¢åŠ è®­ç»ƒç¨³å®šæ€§ã€‚

> æ³¨ï¼šRLHFè®­ç»ƒæ­¥éª¤**å¹¶éå¿…é¡»**ï¼Œæ­¤æ­¥éª¤éš¾ä»¥æå‡æ¨¡å‹â€œæ™ºåŠ›â€è€Œé€šå¸¸ä»…ç”¨äºæå‡æ¨¡å‹çš„â€œç¤¼è²Œâ€ï¼Œæœ‰åˆ©ï¼ˆç¬¦åˆåå¥½ã€å‡å°‘æœ‰å®³å†…å®¹ï¼‰ä¹Ÿæœ‰å¼Šï¼ˆæ ·æœ¬æ”¶é›†æ˜‚è´µã€åé¦ˆåå·®ã€å¤šæ ·æ€§æŸå¤±ï¼‰ã€‚

```bash
torchrun --nproc_per_node 1 train_dpo.py
# or
python train_dpo.py
```

> è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”`100æ­¥`ä¿å­˜ä¸º: `rlhf_*.pth`ï¼ˆ*
> ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰

full_sftæ¨¡å‹åœ¨ç®€æ´æ€§å’Œä¿¡æ¯å‡†ç¡®æ€§æ–¹é¢è¡¨ç°æ›´å¥½ï¼›rlhfæ¨¡å‹åœ¨å›ç­”ä¸­å€¾å‘äºæä¾›æ›´å¤šçš„èƒŒæ™¯ä¿¡æ¯ï¼Œä½†ä¿¡æ¯å‡†ç¡®æ€§æœ‰å¾…æ”¹è¿›ã€‚
æ€»çš„æ¥è¯´RLHFåçš„æ¨¡å‹å€¾å‘äºå­¦ä¹ ï¼šè¯´æ›´å¤šæœ‰ç¤¼è²Œä½†æ— ç”¨çš„åºŸè¯è®¨å¥½â€œå¯¹è¯â€æœ¬èº«ï¼Œè€Œå¯¹ä¿¡æ¯å‡†ç¡®æ€§åˆ™æœ‰è½»å¾®æŸå¤±ã€‚
å¤©ä¸‹æ²¡æœ‰å…è´¹çš„åˆé¤ï¼Œè¿˜éœ€è¦ç»§ç»­æå‡RLHFæ•°æ®é›†çš„è´¨é‡ï¼Œä¹Ÿè¦æ¥å—æ¨¡å‹èƒ½åŠ›æ— æ³•é¿å…çš„æŸå¤±(ç¨‹åº¦æœ‰è½»é‡)ã€‚
DPOå’Œåœ¨çº¿PPOçš„åŒºåˆ«åœ¨äºrejectå’Œchosenéƒ½æ˜¯ç¦»çº¿å‡†å¤‡çš„ï¼Œå’Œmy_minimindæ¨¡å‹æœ¬èº«çš„è¾“å‡ºå¿…ç„¶å­˜åœ¨å¾ˆå¤§çš„åˆ†å¸ƒå·®å¼‚ã€‚
é€šä¿—åœ°è¯´DPOç®—æ³•ä½¿æ¨¡å‹è§‚çœ‹ä¹’ä¹“çƒä¸–ç•Œå† å†›çš„æ‰“æ³•ã€Œå½•åƒã€è¿›è¡ŒRLï¼Œè€Œä¸æ˜¯åƒPPOä¸€æ ·è¯·rewardæ¨¡å‹åšã€Œæ•™ç»ƒã€çº æ­£è‡ªå·±çš„æ‰“æ³•è¿›è¡ŒRL

### çŸ¥è¯†è’¸é¦(Knowledge Distillation, KD)

åœ¨å‰é¢çš„æ‰€æœ‰è®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¨¡å‹å·²ç»å®Œå…¨å…·å¤‡äº†åŸºæœ¬èƒ½åŠ›ï¼Œé€šå¸¸å¯ä»¥å­¦æˆå‡ºå¸ˆäº†ã€‚
è€ŒçŸ¥è¯†è’¸é¦å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½å’Œæ•ˆç‡ï¼Œæ‰€è°“çŸ¥è¯†è’¸é¦ï¼Œå³å­¦ç”Ÿæ¨¡å‹é¢å‘æ•™å¸ˆæ¨¡å‹å­¦ä¹ ã€‚
æ•™å¸ˆæ¨¡å‹é€šå¸¸æ˜¯ç»è¿‡å……åˆ†è®­ç»ƒçš„å¤§æ¨¡å‹ï¼Œå…·æœ‰è¾ƒé«˜çš„å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚
å­¦ç”Ÿæ¨¡å‹æ˜¯ä¸€ä¸ªè¾ƒå°çš„æ¨¡å‹ï¼Œç›®æ ‡æ˜¯å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„è¡Œä¸ºï¼Œè€Œä¸æ˜¯ç›´æ¥ä»åŸå§‹æ•°æ®ä¸­å­¦ä¹ ã€‚
åœ¨SFTå­¦ä¹ ä¸­ï¼Œæ¨¡å‹çš„ç›®æ ‡æ˜¯æ‹Ÿåˆè¯Tokenåˆ†ç±»ç¡¬æ ‡ç­¾ï¼ˆhard labelsï¼‰ï¼Œå³çœŸå®çš„ç±»åˆ«æ ‡ç­¾ï¼ˆå¦‚ 0 æˆ– 6400ï¼‰ã€‚
åœ¨çŸ¥è¯†è’¸é¦ä¸­ï¼Œæ•™å¸ˆæ¨¡å‹çš„softmaxæ¦‚ç‡åˆ†å¸ƒè¢«ç”¨ä½œè½¯æ ‡ç­¾ï¼ˆsoft labelsï¼‰ã€‚å°æ¨¡å‹ä»…å­¦ä¹ è½¯æ ‡ç­¾ï¼Œå¹¶ä½¿ç”¨KL-Lossæ¥ä¼˜åŒ–æ¨¡å‹çš„å‚æ•°ã€‚
é€šä¿—åœ°è¯´ï¼ŒSFTç›´æ¥å­¦ä¹ è€å¸ˆç»™çš„è§£é¢˜ç­”æ¡ˆã€‚è€ŒKDè¿‡ç¨‹ç›¸å½“äºâ€œæ‰“å¼€â€è€å¸ˆèªæ˜çš„å¤§è„‘ï¼Œå°½å¯èƒ½åœ°æ¨¡ä»¿è€å¸ˆâ€œå¤§è„‘â€æ€è€ƒé—®é¢˜çš„ç¥ç»å…ƒçŠ¶æ€ã€‚
ä¾‹å¦‚ï¼Œå½“è€å¸ˆæ¨¡å‹è®¡ç®—`1+1=2`è¿™ä¸ªé—®é¢˜çš„æ—¶å€™ï¼Œæœ€åä¸€å±‚ç¥ç»å…ƒaçŠ¶æ€ä¸º0ï¼Œç¥ç»å…ƒbçŠ¶æ€ä¸º100ï¼Œç¥ç»å…ƒcçŠ¶æ€ä¸º-99...
å­¦ç”Ÿæ¨¡å‹é€šè¿‡å¤§é‡æ•°æ®ï¼Œå­¦ä¹ æ•™å¸ˆæ¨¡å‹å¤§è„‘å†…éƒ¨çš„è¿è½¬è§„å¾‹ã€‚è¿™ä¸ªè¿‡ç¨‹å³ç§°ä¹‹ä¸ºï¼šçŸ¥è¯†è’¸é¦ã€‚
çŸ¥è¯†è’¸é¦çš„ç›®çš„åªæœ‰ä¸€ä¸ªï¼šè®©å°æ¨¡å‹ä½“ç§¯æ›´å°çš„åŒæ—¶æ•ˆæœæ›´å¥½ã€‚
ç„¶è€Œéšç€LLMè¯ç”Ÿå’Œå‘å±•ï¼Œæ¨¡å‹è’¸é¦ä¸€è¯è¢«å¹¿æ³›æ»¥ç”¨ï¼Œä»è€Œäº§ç”Ÿäº†â€œç™½ç›’/é»‘ç›’â€çŸ¥è¯†è’¸é¦ä¸¤ä¸ªæ´¾åˆ«ã€‚
GPT-4è¿™ç§é—­æºæ¨¡å‹ï¼Œç”±äºæ— æ³•è·å–å…¶å†…éƒ¨ç»“æ„ï¼Œå› æ­¤åªèƒ½é¢å‘å®ƒæ‰€è¾“å‡ºçš„æ•°æ®å­¦ä¹ ï¼Œè¿™ä¸ªè¿‡ç¨‹ç§°ä¹‹ä¸ºé»‘ç›’è’¸é¦ï¼Œä¹Ÿæ˜¯å¤§æ¨¡å‹æ—¶ä»£æœ€æ™®éçš„åšæ³•ã€‚
é»‘ç›’è’¸é¦ä¸SFTè¿‡ç¨‹å®Œå…¨ä¸€è‡´ï¼Œåªä¸è¿‡æ•°æ®æ˜¯ä»å¤§æ¨¡å‹çš„è¾“å‡ºæ”¶é›†ï¼Œå› æ­¤åªéœ€è¦å‡†å¤‡æ•°æ®å¹¶ä¸”è¿›ä¸€æ­¥FTå³å¯ã€‚
æ³¨æ„æ›´æ”¹è¢«åŠ è½½çš„åŸºç¡€æ¨¡å‹ä¸º`full_sft_*.pth`ï¼Œå³åŸºäºå¾®è°ƒæ¨¡å‹åšè¿›ä¸€æ­¥çš„è’¸é¦å­¦ä¹ ã€‚
`./dataset/sft_1024.jsonl`ä¸`./dataset/sft_2048.jsonl` å‡æ”¶é›†è‡ªqwen2.5-7/72B-Instructå¤§æ¨¡å‹ï¼Œå¯ç›´æ¥ç”¨äºSFTä»¥è·å–Qwençš„éƒ¨åˆ†è¡Œä¸ºã€‚

```bash
# æ³¨æ„éœ€è¦æ›´æ”¹train_full_sft.pyæ•°æ®é›†è·¯å¾„ï¼Œä»¥åŠmax_seq_len  
torchrun --nproc_per_node 1 train_full_sft.py
# or
python train_full_sft.py
```

> è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”`100æ­¥`åŒæ ·ä¿å­˜ä¸º: `full_sft_*.pth`ï¼ˆ*ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰

æ­¤å¤„åº”å½“ç€é‡ä»‹ç»my_minimindå®ç°çš„ç™½ç›’è’¸é¦ä»£ç `train_distillation.py`ï¼Œç”±äºmy_minimindåŒç³»åˆ—æœ¬èº«å¹¶ä¸å­˜åœ¨å¼ºå¤§çš„æ•™å¸ˆæ¨¡å‹ï¼Œå› æ­¤ç™½ç›’è’¸é¦ä»£ç ä»…ä½œä¸ºå­¦ä¹ å‚è€ƒã€‚

```bash
torchrun --nproc_per_node 1 train_distillation.py
# or
python train_distillation.py
```

### LoRA (Low-Rank Adaptation)

LoRAæ˜¯ä¸€ç§é«˜æ•ˆçš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-Efficient Fine-Tuning, PEFTï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ä½ç§©åˆ†è§£çš„æ–¹å¼å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚
ç›¸æ¯”äºå…¨å‚æ•°å¾®è°ƒï¼ˆFull Fine-Tuningï¼‰ï¼ŒLoRA åªéœ€è¦æ›´æ–°å°‘é‡çš„å‚æ•°ã€‚
LoRA çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šåœ¨æ¨¡å‹çš„æƒé‡çŸ©é˜µä¸­å¼•å…¥ä½ç§©åˆ†è§£ï¼Œä»…å¯¹ä½ç§©éƒ¨åˆ†è¿›è¡Œæ›´æ–°ï¼Œè€Œä¿æŒåŸå§‹é¢„è®­ç»ƒæƒé‡ä¸å˜ã€‚
ä»£ç å¯è§`./model/model_lora.py`å’Œ`train_lora.py`ï¼Œå®Œå…¨ä»0å®ç°LoRAæµç¨‹ï¼Œä¸ä¾èµ–ç¬¬ä¸‰æ–¹åº“çš„å°è£…ã€‚

```bash
torchrun --nproc_per_node 1 train_lora.py
# or
python train_lora.py
```

> è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”`100æ­¥`ä¿å­˜ä¸º: `lora_xxx_*.pth`ï¼ˆ*
> ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰

éå¸¸å¤šçš„äººå›°æƒ‘ï¼Œå¦‚ä½•ä½¿æ¨¡å‹å­¦ä¼šè‡ªå·±ç§æœ‰é¢†åŸŸçš„çŸ¥è¯†ï¼Ÿå¦‚ä½•å‡†å¤‡æ•°æ®é›†ï¼Ÿå¦‚ä½•è¿ç§»é€šç”¨é¢†åŸŸæ¨¡å‹æ‰“é€ å‚åŸŸæ¨¡å‹ï¼Ÿ
è¿™é‡Œä¸¾å‡ ä¸ªä¾‹å­ï¼Œå¯¹äºé€šç”¨æ¨¡å‹ï¼ŒåŒ»å­¦é¢†åŸŸçŸ¥è¯†æ¬ ç¼ºï¼Œå¯ä»¥å°è¯•åœ¨åŸæœ‰æ¨¡å‹åŸºç¡€ä¸ŠåŠ å…¥é¢†åŸŸçŸ¥è¯†ï¼Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚
åŒæ—¶ï¼Œæˆ‘ä»¬é€šå¸¸ä¸å¸Œæœ›å­¦ä¼šé¢†åŸŸçŸ¥è¯†çš„åŒæ—¶æŸå¤±åŸæœ‰åŸºç¡€æ¨¡å‹çš„å…¶å®ƒèƒ½åŠ›ï¼Œæ­¤æ—¶LoRAå¯ä»¥å¾ˆå¥½çš„æ”¹å–„è¿™ä¸ªé—®é¢˜ã€‚
åªéœ€è¦å‡†å¤‡å¦‚ä¸‹æ ¼å¼çš„å¯¹è¯æ•°æ®é›†æ”¾ç½®åˆ°`./dataset/lora_xxx.jsonl`ï¼Œå¯åŠ¨ `python train_lora.py`
è®­ç»ƒå³å¯å¾—åˆ°`./out/lora/lora_xxx.pth`æ–°æ¨¡å‹æƒé‡ã€‚

æ­¤æ—¶ã€åŸºç¡€æ¨¡å‹+LoRAæ¨¡å‹ã€‘å³å¯è·å¾—åŒ»ç–—åœºæ™¯æ¨¡å‹å¢å¼ºçš„èƒ½åŠ›ï¼Œç›¸å½“äºä¸ºåŸºç¡€æ¨¡å‹å¢åŠ äº†LoRAå¤–æŒ‚ï¼Œè¿™ä¸ªè¿‡ç¨‹å¹¶ä¸æŸå¤±åŸºç¡€æ¨¡å‹çš„æœ¬èº«èƒ½åŠ›ã€‚
æˆ‘ä»¬å¯ä»¥é€šè¿‡`eval_model.py`è¿›è¡Œæ¨¡å‹è¯„ä¼°æµ‹è¯•ã€‚

### è®­ç»ƒæ¨ç†æ¨¡å‹ (Reasoning Model)

DeepSeek-R1å®åœ¨å¤ªç«äº†ï¼Œå‡ ä¹é‡æ–°æŒ‡æ˜äº†æœªæ¥LLMçš„æ–°èŒƒå¼ã€‚
è®ºæ–‡æŒ‡å‡º`>3B`çš„æ¨¡å‹ç»å†å¤šæ¬¡åå¤çš„å†·å¯åŠ¨å’ŒRLå¥–åŠ±è®­ç»ƒæ‰èƒ½è·å¾—è‚‰çœ¼å¯è§çš„æ¨ç†èƒ½åŠ›æå‡ã€‚
æœ€å¿«æœ€ç¨³å¦¥æœ€ç»æµçš„åšæ³•ï¼Œä»¥åŠæœ€è¿‘çˆ†å‘çš„å„ç§å„æ ·æ‰€è°“çš„æ¨ç†æ¨¡å‹å‡ ä¹éƒ½æ˜¯ç›´æ¥é¢å‘æ•°æ®è¿›è¡Œè’¸é¦è®­ç»ƒï¼Œ
ä½†ç”±äºç¼ºä¹æŠ€æœ¯å«é‡ï¼Œè’¸é¦æ´¾è¢«RLæ´¾ç§ä¸èµ·ï¼ˆhhhhï¼‰ã€‚
æœ¬äººè¿…é€Ÿå·²ç»åœ¨Qwenç³»åˆ—1.5Bå°æ¨¡å‹ä¸Šè¿›è¡Œäº†å°è¯•ï¼Œå¾ˆå¿«å¤ç°äº†Zeroè¿‡ç¨‹çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚
ç„¶è€Œä¸€ä¸ªé—æ†¾çš„å…±è¯†æ˜¯ï¼šå‚æ•°å¤ªå°çš„æ¨¡å‹ç›´æ¥é€šè¿‡å†·å¯åŠ¨SFT+GRPOå‡ ä¹ä¸å¯èƒ½è·å¾—ä»»ä½•æ¨ç†æ•ˆæœã€‚
my_minimind2ç¬¬ä¸€æ—¶é—´åªèƒ½åšå®šä¸ç§»çš„é€‰æ‹©åšè’¸é¦æ´¾ï¼Œæ—¥ååŸºäº0.1Bæ¨¡å‹çš„RLå¦‚æœåŒæ ·å–å¾—å°å°è¿›å±•ä¼šæ›´æ–°æ­¤éƒ¨åˆ†çš„è®­ç»ƒæ–¹æ¡ˆã€‚

åšè’¸é¦éœ€è¦å‡†å¤‡çš„ä¾ç„¶æ˜¯å’ŒSFTé˜¶æ®µåŒæ ·æ ¼å¼çš„æ•°æ®å³å¯ï¼Œæ•°æ®é›†æ¥æºå·²å¦‚ä¸Šæ–‡ä»‹ç»ã€‚æ•°æ®æ ¼å¼ä¾‹å¦‚ï¼š

```json lines
{
  "conversations": [
    {
      "role": "user",
      "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯å°èŠ³ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ã€‚"
    },
    {
      "role": "assistant",
      "content": "<think>\nä½ å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…ç‹¬ç«‹å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹my_minimind-R1-Lite-Previewï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æœåŠ¡ï¼\n</think>\n<answer>\nä½ å¥½ï¼æˆ‘æ˜¯ç”±ä¸­å›½çš„ä¸ªäººå¼€å‘è€…ç‹¬ç«‹å¼€å‘çš„æ™ºèƒ½åŠ©æ‰‹my_minimind-R1-Lite-Previewï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æä¾›æœåŠ¡ï¼\n</answer>"
    }
  ]
}
```

æ¨ç†æ¨¡å‹R1çš„å›å¤æ¨¡æ¿æ˜¯ï¼š

```text
<think>\næ€è€ƒè¿‡ç¨‹\n</think>\n
<answer>\næœ€ç»ˆå›ç­”\n</answer>
```

è¿™åœ¨GRPOä¸­é€šè¿‡è®¾ç½®è§„åˆ™å¥–åŠ±å‡½æ•°çº¦æŸæ¨¡å‹ç¬¦åˆæ€è€ƒæ ‡ç­¾å’Œå›å¤æ ‡ç­¾ï¼ˆåœ¨å†·å¯åŠ¨é å‰çš„é˜¶æ®µå¥–åŠ±å€¼è®¾ç½®åº”è¯¥æé«˜ä¸€äº›ï¼‰

å¦ä¸€ä¸ªé—®é¢˜æ˜¯è’¸é¦è¿‡ç¨‹è™½ç„¶å’ŒSFTä¸€æ ·ï¼Œä½†å®éªŒç»“æœæ˜¯æ¨¡å‹éš¾ä»¥æ¯æ¬¡éƒ½ç¬¦åˆæ¨¡æ¿è§„èŒƒçš„å›å¤ï¼Œå³è„±ç¦»æ€è€ƒå’Œå›å¤æ ‡ç­¾çº¦æŸã€‚
è¿™é‡Œçš„å°æŠ€å·§æ˜¯å¢åŠ æ ‡è®°ä½ç½®tokençš„æŸå¤±æƒ©ç½šï¼Œè¯¦è§`train_distill_reason.py`:

```text
# åœ¨ sp_ids å¯¹åº”çš„ä½ç½®å¢åŠ é¢å¤–çš„æƒ©ç½š
...
loss_mask[sp_ids] = 10 # æƒ©ç½šç³»æ•°
```

å¦å¦ä¸€ä¸ªtipsæ˜¯ç”±äºæ¨ç†æ•°æ®ç”±äºåªç­›é€‰äº†`<1024`é•¿åº¦çš„æ•°æ®ï¼Œå…¶ä¸­å¤šè½®å¯¹è¯å’Œè‹±æ–‡æ•°æ®åå°‘ï¼Œ
å› æ­¤`r1_mix_1024.jsonl`è¿›è¡Œäº†å¤§çº¦10kæ¡å¤šè½®å¯¹è¯+è‹±æ–‡æ•°æ®çš„æ··åˆï¼Œé˜²æ­¢æ¨¡å‹é—å¿˜ä¸¥é‡ã€‚

è„šæœ¬é»˜è®¤åŸºäºrlhfåçš„åŸºæ¨¡å‹åšæ¨ç†èƒ½åŠ›çš„è’¸é¦å¾®è°ƒï¼Œä¸‹é¢ç›´æ¥å¯åŠ¨è®­ç»ƒå³å¯ï¼š

```bash
torchrun --nproc_per_node 1 train_distill_reason.py
# or
python train_distill_reason.py
```

> è®­ç»ƒåçš„æ¨¡å‹æƒé‡æ–‡ä»¶é»˜è®¤æ¯éš”`100æ­¥`ä¿å­˜ä¸º: `reason_*.pth`ï¼ˆ*ä¸ºæ¨¡å‹å…·ä½“dimensionï¼Œæ¯æ¬¡ä¿å­˜æ—¶æ–°æ–‡ä»¶ä¼šè¦†ç›–æ—§æ–‡ä»¶ï¼‰



## æµ‹è¯•æ¨¡å‹æ•ˆæœ

ç¡®ä¿éœ€è¦æµ‹è¯•çš„æ¨¡å‹`*.pth`æ–‡ä»¶ä½äº`./out/`ç›®å½•ä¸‹ã€‚
ä¹Ÿå¯ä»¥ç›´æ¥å»[æ­¤å¤„](https://www.modelscope.cn/models/gongjy/my_minimind2-PyTorch/files)ä¸‹è½½ä½¿ç”¨æˆ‘è®­ç»ƒçš„`*.pth`æ–‡ä»¶ã€‚

```bash
python eval_model.py --model_mode 1 # é»˜è®¤ä¸º0ï¼šæµ‹è¯•pretrainæ¨¡å‹æ•ˆæœï¼Œè®¾ç½®ä¸º1ï¼šæµ‹è¯•full_sftæ¨¡å‹æ•ˆæœ 0: é¢„è®­ç»ƒæ¨¡å‹ï¼Œ1: SFT-Chatæ¨¡å‹ï¼Œ2: RLHF-Chatæ¨¡å‹ï¼Œ3: Reasonæ¨¡å‹

python eval_vlm.py --model_mode 1 # 0: Pretrainæ¨¡å‹ï¼Œ1: SFTæ¨¡å‹ï¼Œ2: SFT-å¤šå›¾æ¨¡å‹ (betaæ‹“å±•)

```


å¦‚éœ€è¯¦æƒ…ï¼ŒæŸ¥çœ‹`eval_model.py`è„šæœ¬ä»£ç å³å¯ã€‚model_modeåˆ†ä¸º 0: é¢„è®­ç»ƒæ¨¡å‹ï¼Œ1: SFT-Chatæ¨¡å‹ï¼Œ2: RLHF-Chatæ¨¡å‹ï¼Œ3: Reasonæ¨¡å‹

## Tokenizer

./scripts/train_tokenizer.py

```
# ä¸€äº›è‡ªè¨€è‡ªè¯­
> å°½ç®¡my_minimind_tokenizeré•¿åº¦å¾ˆå°ï¼Œç¼–è§£ç æ•ˆç‡å¼±äºqwen2ã€glmç­‰ä¸­æ–‡å‹å¥½å‹åˆ†è¯å™¨ã€‚
> ä½†my_minimindæ¨¡å‹é€‰æ‹©äº†è‡ªå·±è®­ç»ƒçš„my_minimind_tokenizerä½œä¸ºåˆ†è¯å™¨ï¼Œä»¥ä¿æŒæ•´ä½“å‚æ•°è½»é‡ï¼Œé¿å…ç¼–ç å±‚å’Œè®¡ç®—å±‚å æ¯”å¤±è¡¡ï¼Œå¤´é‡è„šè½»ï¼Œå› ä¸ºmy_minimindçš„è¯è¡¨å¤§å°åªæœ‰6400ã€‚
> ä¸”my_minimindåœ¨å®é™…æµ‹è¯•ä¸­æ²¡æœ‰å‡ºç°è¿‡ç”Ÿåƒ»è¯æ±‡è§£ç å¤±è´¥çš„æƒ…å†µï¼Œæ•ˆæœè‰¯å¥½ã€‚
> ç”±äºè‡ªå®šä¹‰è¯è¡¨å‹ç¼©é•¿åº¦åˆ°6400ï¼Œä½¿å¾—LLMæ€»å‚æ•°é‡æœ€ä½åªæœ‰25.8Mã€‚
> è®­ç»ƒæ•°æ®`tokenizer_train.jsonl`å‡æ¥è‡ªäº`åŒ æ•°å¤§æ¨¡å‹æ•°æ®é›†`ï¼Œè¿™éƒ¨åˆ†æ•°æ®ç›¸å¯¹æ¬¡è¦ï¼Œå¦‚éœ€è®­ç»ƒå¯ä»¥è‡ªç”±é€‰æ‹©ã€‚
```

## è®­ç»ƒæ•°æ®

### Pretrainæ•°æ®

å°è¯•æŠŠ[åŒ æ•°å¤§æ¨¡å‹æ•°æ®é›†](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data)çš„ä¸­æ–‡éƒ¨åˆ†æå–å‡ºæ¥ï¼Œæ¸…æ´—å‡ºå­—ç¬¦`<512`é•¿åº¦çš„å¤§çº¦1.6GBçš„è¯­æ–™ç›´æ¥æ‹¼æ¥æˆé¢„è®­ç»ƒæ•°æ® 

æ–‡ä»¶`pretrain_hq.jsonl` (1.6GB) æ•°æ®æ ¼å¼ä¸º

```bash
{"text": "å¦‚ä½•æ‰èƒ½æ‘†è„±æ‹–å»¶ç—‡ï¼Ÿ æ²»æ„ˆæ‹–å»¶ç—‡å¹¶ä¸å®¹æ˜“ï¼Œä½†ä»¥ä¸‹å»ºè®®å¯èƒ½æœ‰æ‰€å¸®åŠ©..."}

{"text": "<s>å¦‚ä½•æ‰èƒ½æ‘†è„±æ‹–å»¶ç—‡ï¼Ÿ æ²»æ„ˆæ‹–å»¶ç—‡å¹¶ä¸å®¹æ˜“ï¼Œä½†ä»¥ä¸‹å»ºè®®å¯èƒ½æœ‰æ‰€å¸®åŠ©...</s>"}
```

### SFTæ•°æ®

`sft_mini_512.jsonl`(~1.2GB)ã€‚

æ‰€æœ‰sftæ–‡ä»¶ `sft_X.jsonl` æ•°æ®æ ¼å¼å‡ä¸º

```text
{
    "conversations": [
        {"role": "user", "content": "ä½ å¥½"},
        {"role": "assistant", "content": "ä½ å¥½ï¼"},
        {"role": "user", "content": "å†è§"},
        {"role": "assistant", "content": "å†è§ï¼"}
    ]
}

# <s>system
# ä½ æ˜¯ MiniMindï¼Œæ˜¯ä¸€ä¸ªæœ‰ç”¨çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚</s>
# <s>user
# è¯·ç”¨ä¸€æ®µè¯æè¿°é˜¿é‡Œå·´å·´é›†å›¢çš„ä¼ä¸šæ–‡åŒ–ã€‚</s>
# <s>assistant
# é˜¿é‡Œå·´å·´é›†å›¢çš„ä¼ä¸šæ–‡åŒ–ä»¥â€œå®¢æˆ·ç¬¬ä¸€ã€å‘˜å·¥ç¬¬äºŒã€è‚¡ä¸œç¬¬ä¸‰â€ä¸ºæ ¸å¿ƒä»·å€¼è§‚ï¼Œå¼ºè°ƒâ€œè®©å¤©ä¸‹æ²¡æœ‰éš¾åšçš„ç”Ÿæ„â€çš„ä½¿å‘½ã€‚</s>
```

### RLHFæ•°æ®

æ–‡ä»¶ `dpo.jsonl` æ•°æ®æ ¼å¼ä¸º

```text
{
  "chosen": [
    {"content": "Q", "role": "user"}, 
    {"content": "good answer", "role": "assistant"}
  ], 
  "rejected": [
    {"content": "Q", "role": "user"}, 
    {"content": "bad answer", "role": "assistant"}
  ]
}



## chosen
<s>system
ä½ æ˜¯ MiniMindï¼Œæ˜¯ä¸€ä¸ªæœ‰ç”¨çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚</s>
<s>user
Q</s>
<s>assistant
good answers>


## rejected
<s>system
ä½ æ˜¯ MiniMindï¼Œæ˜¯ä¸€ä¸ªæœ‰ç”¨çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚</s>
<s>user
Q</s>
<s>assistant
bad answer</s>
```

![image-20250317133142181](../my_minimind/images/image-20250317133142181.png)

https://www.bilibili.com/list/watchlater?oid=1201309534&bvid=BV1GF4m1L7Nt&spm_id_from=333.1365.top_right_bar_window_view_later.content.click

### æ•°æ®é›†ä¸‹è½½

å°†ä¸‹è½½çš„æ•°æ®é›†æ–‡ä»¶æ”¾åˆ°`./dataset/`ç›®å½•ä¸‹ï¼ˆâœ¨ä¸ºæ¨èçš„å¿…é¡»é¡¹ï¼‰

```bash
./dataset/
â”œâ”€â”€ dpo.jsonl (909MB)
â”œâ”€â”€ lora_identity.jsonl (22.8KB)
â”œâ”€â”€ lora_medical.jsonl (34MB)
â”œâ”€â”€ pretrain_hq.jsonl (1.6GB, âœ¨)
â”œâ”€â”€ r1_mix_1024.jsonl (340MB)
â”œâ”€â”€ sft_1024.jsonl (5.6GB)
â”œâ”€â”€ sft_2048.jsonl (9GB)
â”œâ”€â”€ sft_512.jsonl (7.5GB)
â”œâ”€â”€ sft_mini_512.jsonl (1.2GB, âœ¨)
â””â”€â”€ tokenizer_train.jsonl (1GB)
```

<details style="color:rgb(128,128,128)">
<summary>æ³¨ï¼šå„æ•°æ®é›†ç®€ä»‹</summary>



* `dpo.jsonl` --RLHFé˜¶æ®µæ•°æ®é›†
* `lora_identity.jsonl` --è‡ªæˆ‘è®¤çŸ¥æ•°æ®é›†ï¼ˆä¾‹å¦‚ï¼šä½ æ˜¯è°ï¼Ÿæˆ‘æ˜¯my_minimind...ï¼‰ï¼Œæ¨èç”¨äºloraè®­ç»ƒï¼ˆäº¦å¯ç”¨äºå…¨å‚SFTï¼Œå‹¿è¢«åå­—å±€é™ï¼‰
* `lora_medical.jsonl` --åŒ»ç–—é—®ç­”æ•°æ®é›†ï¼Œæ¨èç”¨äºloraè®­ç»ƒï¼ˆäº¦å¯ç”¨äºå…¨å‚SFTï¼Œå‹¿è¢«åå­—å±€é™ï¼‰
* `pretrain_hq.jsonl`âœ¨ --é¢„è®­ç»ƒæ•°æ®é›†ï¼Œæ•´åˆè‡ªjiangshuç§‘æŠ€
* `r1_mix_1024.jsonl` --DeepSeek-R1-1.5Bè’¸é¦æ•°æ®ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º1024ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=1024ï¼‰
* `sft_1024.jsonl` --æ•´åˆè‡ªQwen2.5è’¸é¦æ•°æ®ï¼ˆæ˜¯sft_2048çš„å­é›†ï¼‰ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º1024ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=1024ï¼‰
* `sft_2048.jsonl` --æ•´åˆè‡ªQwen2.5è’¸é¦æ•°æ®ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º2048ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=2048ï¼‰
* `sft_512.jsonl` --æ•´åˆè‡ªåŒ æ•°ç§‘æŠ€SFTæ•°æ®ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º512ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=512ï¼‰
* `sft_mini_512.jsonl`âœ¨ --æç®€æ•´åˆè‡ªåŒ æ•°ç§‘æŠ€SFTæ•°æ®+Qwen2.5è’¸é¦æ•°æ®ï¼ˆç”¨äºå¿«é€Ÿè®­ç»ƒZeroæ¨¡å‹ï¼‰ï¼Œæ¯æ¡æ•°æ®å­—ç¬¦æœ€å¤§é•¿åº¦ä¸º512ï¼ˆå› æ­¤è®­ç»ƒæ—¶è®¾ç½®max_seq_len=512ï¼‰
* `tokenizer_train.jsonl` --å‡æ¥è‡ªäº`åŒ æ•°å¤§æ¨¡å‹æ•°æ®é›†`ï¼Œè¿™éƒ¨åˆ†æ•°æ®ç›¸å¯¹æ¬¡è¦ï¼Œï¼ˆä¸æ¨èè‡ªå·±é‡å¤è®­ç»ƒtokenizerï¼Œç†ç”±å¦‚ä¸Šï¼‰å¦‚éœ€è‡ªå·±è®­ç»ƒtokenizerå¯ä»¥è‡ªç”±é€‰æ‹©æ•°æ®é›†ã€‚

#  Model Structure

## minimind

minimindçš„æ•´ä½“ç»“æ„ä¸€è‡´ï¼Œåªæ˜¯åœ¨RoPEè®¡ç®—ã€æ¨ç†å‡½æ•°å’ŒFFNå±‚çš„ä»£ç ä¸Šåšäº†ä¸€äº›å°è°ƒæ•´ã€‚
å…¶ç»“æ„å¦‚ä¸‹å›¾ï¼ˆé‡ç»˜ç‰ˆï¼‰ï¼š

![structure](../my_minimind/images/LLM-structure.png)
![structure-moe](../my_minimind/images/LLM-structure-moe.png)

## minimind-V

![VLM-structure](pic/VLM-structure.png)

![VLM-structure-moe](pic/VLM-structure-moe.png)

# çŸ¥è¯†ç‚¹

## è¾“å…¥æ•°æ®å’Œloss mask

åœ¨é¢„è®­ç»ƒï¼ˆPre-trainingï¼‰å’Œç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuning, SFTï¼‰é˜¶æ®µï¼Œè¾“å…¥æ•°æ®çš„ç»“æ„ã€å†…å®¹å’Œç›®æ ‡å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚ä»¥ä¸‹æ˜¯ä¸¤è€…çš„å…³é”®åŒºåˆ«ï¼š

---

### **1. é¢„è®­ç»ƒï¼ˆPre-trainingï¼‰çš„è¾“å…¥æ•°æ®**
#### **æ ¸å¿ƒç›®æ ‡**  
å­¦ä¹ é€šç”¨çš„è¯­è¨€æˆ–è·¨æ¨¡æ€è¡¨ç¤ºï¼ˆå¦‚LLMçš„è¯­è¨€è§„åˆ™ã€å¤šæ¨¡æ€å¯¹é½ï¼‰ã€‚  
**æ•°æ®ç‰¹ç‚¹**ï¼š  
- **è§„æ¨¡å¤§**ï¼šæµ·é‡æ— æ ‡æ³¨æˆ–å¼±æ ‡æ³¨æ•°æ®ï¼ˆå¦‚Common Crawlã€ç»´åŸºç™¾ç§‘ã€å¤šæ¨¡æ€æ•°æ®é›†ï¼‰ã€‚  
- **æ— ç›‘ç£/è‡ªç›‘ç£**ï¼šä¾èµ–ä»»åŠ¡è®¾è®¡è‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾ï¼ˆå¦‚Next Token Predictionã€MLMï¼‰ã€‚  

#### **è¾“å…¥æ ¼å¼ç¤ºä¾‹**  
- **çº¯æ–‡æœ¬æ¨¡å‹ï¼ˆå¦‚GPTï¼‰**ï¼š  
  ```text
  è¿ç»­æ–‡æœ¬ï¼ˆå¦‚ï¼š"The cat sat on the mat. It was..."ï¼‰
  ```
  - **å¤„ç†æ–¹å¼**ï¼š  
    - è¾“å…¥ = å…¨æ–‡ï¼ˆæˆ–æˆªæ–­åçš„ç‰‡æ®µï¼‰ã€‚  
    - æ ‡ç­¾ = å‘å³ç§»ä¸€ä½çš„è¾“å…¥ï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªtokenï¼‰ã€‚  
    - **Loss Mask**ï¼šå¿½ç•¥`[PAD]`å’Œå› æœæ©ç ï¼ˆæœªæ¥tokenï¼‰ã€‚  

- **å¤šæ¨¡æ€æ¨¡å‹ï¼ˆå¦‚LLaVAï¼‰**ï¼š  
  ```text
  [IMG_Emb]å›¾åƒç‰¹å¾[æ–‡æœ¬æè¿°ï¼š"A cat on the mat"]
  ```
  - **å¤„ç†æ–¹å¼**ï¼š  
    - è¾“å…¥ = å›¾åƒåµŒå…¥ + æ–‡æœ¬æè¿°ã€‚  
    - æ ‡ç­¾ = æ–‡æœ¬éƒ¨åˆ†ï¼ˆå›¾åƒåµŒå…¥ä¸è®¡ç®—æŸå¤±ï¼‰ã€‚  
    - **Loss Mask**ï¼šæ©ç›–å›¾åƒåµŒå…¥å’Œ`[PAD]`ã€‚  

#### **å…³é”®ç‰¹å¾**  
âœ… æ•°æ®é‡å¤§ã€è¦†ç›–å¹¿ï¼ˆé€šç”¨é¢†åŸŸï¼‰ã€‚  
âœ… è¾“å…¥ä¸ºè¿ç»­æ–‡æœ¬æˆ–åŸå§‹å¤šæ¨¡æ€æ•°æ®ï¼ˆæ— æ˜ç¡®æŒ‡ä»¤ï¼‰ã€‚  
âœ… æ ‡ç­¾é€šè¿‡ä»»åŠ¡è®¾è®¡è‡ªåŠ¨ç”Ÿæˆï¼ˆå¦‚é¢„æµ‹ä¸‹ä¸€ä¸ªtokenï¼‰ã€‚  

---

### **2. ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰çš„è¾“å…¥æ•°æ®**
#### **æ ¸å¿ƒç›®æ ‡**  
ä½¿æ¨¡å‹é€‚åº”ç‰¹å®šä»»åŠ¡ï¼ˆå¦‚æŒ‡ä»¤éµå¾ªã€å¯¹è¯ç”Ÿæˆï¼‰ã€‚  
**æ•°æ®ç‰¹ç‚¹**ï¼š  
- **è§„æ¨¡å°**ï¼šé«˜è´¨é‡äººå·¥æ ‡æ³¨æˆ–åˆæˆçš„ä»»åŠ¡æ•°æ®ï¼ˆå¦‚Alpacaã€ShareGPTï¼‰ã€‚  
- **æœ‰ç›‘ç£**ï¼šè¾“å…¥-è¾“å‡ºå¯¹éœ€æ˜ç¡®å¯¹åº”ï¼ˆå¦‚æŒ‡ä»¤-å›ç­”ï¼‰ã€‚  

#### **è¾“å…¥æ ¼å¼ç¤ºä¾‹**  
- **å•è½®æŒ‡ä»¤ï¼ˆå¦‚Alpacaï¼‰**ï¼š  
  ```text
  [USER]: è§£é‡Šç‰›é¡¿ç¬¬ä¸€å®šå¾‹  
  [ASSISTANT]: ç‰›é¡¿ç¬¬ä¸€å®šå¾‹æŒ‡å‡º...
  ```
  - **å¤„ç†æ–¹å¼**ï¼š  
    - è¾“å…¥ = ç”¨æˆ·æŒ‡ä»¤ + åŠ©æ‰‹å›ç­”å‰ç¼€ï¼ˆ`[ASSISTANT]:`ï¼‰ã€‚  
    - æ ‡ç­¾ = åŠ©æ‰‹çš„å®Œæ•´å›ç­”ï¼ˆä»…è®¡ç®—è¿™éƒ¨åˆ†æŸå¤±ï¼‰ã€‚  
    - **Loss Mask**ï¼šæ©ç›–ç”¨æˆ·æŒ‡ä»¤å’Œ`[PAD]`ã€‚  

- **å¤šæ¨¡æ€å¯¹è¯ï¼ˆå¦‚LLaVA-SFTï¼‰**ï¼š  
  ```text
  [IMG_Emb]å›¾åƒç‰¹å¾[USER]: å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ[ASSISTANT]: ä¸€åªçŒ«
  ```
  - **å¤„ç†æ–¹å¼**ï¼š  
    - è¾“å…¥ = å›¾åƒåµŒå…¥ + ç”¨æˆ·é—®é¢˜ + åŠ©æ‰‹å›ç­”å‰ç¼€ã€‚  
    - æ ‡ç­¾ = åŠ©æ‰‹å›ç­”éƒ¨åˆ†ï¼ˆ`"ä¸€åªçŒ«"`ï¼‰ã€‚  
    - **Loss Mask**ï¼šæ©ç›–å›¾åƒåµŒå…¥ã€ç”¨æˆ·é—®é¢˜å’Œ`[PAD]`ã€‚  

#### **å…³é”®ç‰¹å¾**  
âœ… æ•°æ®é‡å°ä½†è´¨é‡é«˜ï¼ˆä»»åŠ¡ç›¸å…³ï¼‰ã€‚  
âœ… è¾“å…¥ä¸ºç»“æ„åŒ–å¯¹è¯æˆ–æŒ‡ä»¤ï¼ˆæ˜ç¡®åˆ’åˆ†`ç”¨æˆ·/åŠ©æ‰‹`è§’è‰²ï¼‰ã€‚  
âœ… æ ‡ç­¾æ˜¯äººå·¥ç¼–å†™çš„ç›®æ ‡è¾“å‡ºï¼ˆå¦‚ç­”æ¡ˆã€å¯¹è¯å›å¤ï¼‰ã€‚  

---

### **3. æ ¸å¿ƒåŒºåˆ«æ€»ç»“**
| **ç»´åº¦**      | **é¢„è®­ç»ƒï¼ˆPre-trainingï¼‰**        | **ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰**           |
| ------------- | --------------------------------- | ----------------------------- |
| **æ•°æ®è§„æ¨¡**  | æµ·é‡ï¼ˆTBçº§ï¼‰                      | å°‘é‡ï¼ˆGBçº§ï¼‰                  |
| **æ•°æ®æ¥æº**  | æ— æ ‡æ³¨åŸå§‹æ•°æ®                    | äººå·¥æ ‡æ³¨/åˆæˆçš„ä»»åŠ¡æ•°æ®       |
| **è¾“å…¥æ ¼å¼**  | è¿ç»­æ–‡æœ¬æˆ–å¤šæ¨¡æ€åŸå§‹æ•°æ®          | ç»“æ„åŒ–æŒ‡ä»¤/å¯¹è¯ï¼ˆå«è§’è‰²æ ‡è®°ï¼‰ |
| **æ ‡ç­¾ç”Ÿæˆ**  | è‡ªç›‘ç£ï¼ˆå¦‚é¢„æµ‹ä¸‹ä¸€ä¸ªtokenï¼‰       | äººå·¥æ ‡æ³¨çš„ç†æƒ³è¾“å‡º            |
| **Loss Mask** | æ©ç›–å¡«å……ç¬¦ã€æœªæ¥tokenï¼ˆå› æœæ©ç ï¼‰ | æ©ç›–ç”¨æˆ·è¾“å…¥ã€å¡«å……ç¬¦          |
| **ç›®æ ‡**      | å­¦ä¹ é€šç”¨è¡¨ç¤º                      | é€‚åº”ç‰¹å®šä»»åŠ¡è¡Œä¸º              |

---

### **4. å…¸å‹æ¡ˆä¾‹å¯¹æ¯”**
#### **é¢„è®­ç»ƒè¾“å…¥ï¼ˆGPTé£æ ¼ï¼‰**  
```text
è¾“å…¥: "The cat sat on the"
æ ‡ç­¾: " cat sat on the mat"
```
- æ¨¡å‹å­¦ä¹ é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼ˆæ— æ˜ç¡®ä»»åŠ¡ï¼‰ã€‚  

#### **SFTè¾“å…¥ï¼ˆAlpacaé£æ ¼ï¼‰**  
```text
è¾“å…¥: "[USER]: å†™ä¸€é¦–å…³äºçŒ«çš„è¯—\n[ASSISTANT]:"
æ ‡ç­¾: "å°çŒ«è½»è½»è·³ï¼Œé˜³å…‰..."
```
- æ¨¡å‹å­¦ä¹ æ ¹æ®æŒ‡ä»¤ç”Ÿæˆè¯—æ­Œï¼ˆä»»åŠ¡æ˜ç¡®ï¼‰ã€‚  

---



## é¡¹ç›®

### **å‘½ä»¤è¡Œå‚æ•°argparse**

```
import argparse

if __name__=='__main__':
    parser=argparse.ArgumentParser(description='minimind argument')
    parser.add_argument('--model',type=int,default=0)
    parser.add_argument('--dtype',type=str,default='bfloat16')	
    
    # è¿è¡Œè„šæœ¬æ—¶åŠ ä¸Š --use_wandbï¼Œargparse ä¼šå°†ä¸è¯¥å‚æ•°å¯¹åº”çš„å˜é‡å€¼è®¾ç½®ä¸º Trueã€‚
	# é»˜è®¤å€¼ä¸º False: å¦‚æœä½ åœ¨å‘½ä»¤è¡Œä¸­æ²¡æœ‰åŒ…å«è¿™ä¸ªå‚æ•°ï¼Œargparse ä¼šå°†ä¸è¯¥å‚æ•°å¯¹åº”çš„å˜é‡å€¼é»˜è®¤ä¸º False
	parser.add_argument("--use_wandb", action="store_true")
	
	
    args=parser.parse_args()
    print(args.model)
```



## LLaVA æ¶æ„è¯¦ç»†è§£é‡Š

LLaVA çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†ä¸€ä¸ªå¼ºå¤§çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸ä¸€ä¸ªé¢„è®­ç»ƒçš„è§†è§‰ç¼–ç å™¨ç›¸ç»“åˆï¼Œå¹¶é€šè¿‡ä¸€ä¸ªè¿æ¥æ¨¡å—ï¼ˆæŠ•å½±å±‚ï¼‰æ¥å®ç°è·¨æ¨¡æ€çš„å¯¹é½ã€‚å…¶ä¸»è¦ç»„æˆéƒ¨åˆ†åŒ…æ‹¬ï¼š

1. **è§†è§‰ç¼–ç å™¨ (Vision Encoder)**
2. **æŠ•å½±å±‚ (Projection Layer)**
3. **å¤§å‹è¯­è¨€æ¨¡å‹ (Large Language Model)**

ä¸‹é¢æˆ‘ä»¬è¯¦ç»†ä»‹ç»æ¯ä¸ªéƒ¨åˆ†åŠå…¶ä½œç”¨ã€‚

### 1. è§†è§‰ç¼–ç å™¨ (Vision Encoder)

- **ä½œç”¨ï¼š** è§†è§‰ç¼–ç å™¨çš„ä½œç”¨æ˜¯å°†è¾“å…¥çš„å›¾åƒè½¬æ¢æˆä¸€ç³»åˆ—å…·æœ‰ä»£è¡¨æ€§çš„è§†è§‰ç‰¹å¾å‘é‡ã€‚
- **å®ç°ï¼š** LLaVA é€šå¸¸ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„è§†è§‰æ¨¡å‹ä½œä¸ºå…¶è§†è§‰ç¼–ç å™¨ï¼Œä¾‹å¦‚ CLIP (Contrastive Languageâ€“Image Pre-training) çš„ ViT (Vision Transformer) éƒ¨åˆ†ã€‚CLIP åœ¨å¤§é‡çš„å›¾åƒ-æ–‡æœ¬å¯¹ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿå­¦ä¹ åˆ°å›¾åƒå’Œæ–‡æœ¬ä¹‹é—´çš„å…³è”æ€§ï¼Œç”Ÿæˆçš„å›¾åƒç‰¹å¾å¯¹è¯­è¨€ä¿¡æ¯å…·æœ‰å¾ˆå¥½çš„å…¼å®¹æ€§ã€‚
- **å·¥ä½œåŸç†ï¼š** ç»™å®šä¸€å¼ è¾“å…¥å›¾åƒï¼Œè§†è§‰ç¼–ç å™¨ï¼ˆå¦‚ ViTï¼‰ä¼šå°†å›¾åƒåˆ†å‰²æˆä¸€ç³»åˆ—å›¾åƒå—ï¼ˆpatchesï¼‰ï¼Œç„¶åé€šè¿‡å¤šå±‚ Transformer ç»“æ„å¤„ç†è¿™äº›å›¾åƒå—ï¼Œæœ€ç»ˆè¾“å‡ºä¸€ç³»åˆ—è§†è§‰ç‰¹å¾å‘é‡ï¼ˆä¹Ÿç§°ä¸ºå›¾åƒ token æˆ–è§†è§‰ embeddingï¼‰ã€‚è¿™äº›ç‰¹å¾å‘é‡æ•æ‰äº†å›¾åƒä¸­çš„å†…å®¹ã€å¯¹è±¡ã€åœºæ™¯ç­‰ä¿¡æ¯ã€‚
- **è®­ç»ƒçŠ¶æ€ï¼š** åœ¨ LLaVA çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œ**è§†è§‰ç¼–ç å™¨çš„å‚æ•°é€šå¸¸æ˜¯å†»ç»“çš„ï¼Œå³ä¸è¿›è¡Œæ›´æ–°ã€‚è¿™æ˜¯å› ä¸ºé¢„è®­ç»ƒçš„è§†è§‰ç¼–ç å™¨å·²ç»å…·å¤‡äº†å¼ºå¤§çš„å›¾åƒç†è§£èƒ½åŠ›ï¼Œå†»ç»“å®ƒå¯ä»¥ä¿ç•™è¿™äº›èƒ½åŠ›ï¼Œå¹¶å‡å°‘éœ€è¦è®­ç»ƒçš„å‚æ•°æ•°é‡ã€‚**

### 2. æŠ•å½±å±‚ (Projection Layer)

- **ä½œç”¨ï¼š** æŠ•å½±å±‚æ˜¯ LLaVA æ¶æ„ä¸­çš„å…³é”®è¿æ¥æ¨¡å—ï¼Œå®ƒçš„ä½œç”¨æ˜¯å°†è§†è§‰ç¼–ç å™¨è¾“å‡ºçš„è§†è§‰ç‰¹å¾å‘é‡è½¬æ¢åˆ°ä¸å¤§å‹è¯­è¨€æ¨¡å‹è¾“å…¥ embedding ç©ºé—´å…¼å®¹çš„ç»´åº¦å’Œè¡¨ç¤ºå½¢å¼ã€‚
- **å®ç°ï¼š** æŠ•å½±å±‚é€šå¸¸ç”±ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œæ„æˆï¼Œä¾‹å¦‚ä¸€ä¸ªæˆ–å¤šä¸ªçº¿æ€§å±‚ï¼ˆLinear Layerï¼‰æˆ–è€…ä¸€ä¸ª MLP (å¤šå±‚æ„ŸçŸ¥æœº)ã€‚
- **å·¥ä½œåŸç†ï¼š** è§†è§‰ç¼–ç å™¨è¾“å‡ºçš„è§†è§‰ç‰¹å¾å‘é‡çš„ç»´åº¦å’Œè¡¨ç¤ºå½¢å¼å¯èƒ½ä¸å¤§å‹è¯­è¨€æ¨¡å‹æœŸæœ›çš„è¾“å…¥ embedding ä¸åŒã€‚æŠ•å½±å±‚æ¥æ”¶è§†è§‰ç‰¹å¾å‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¹¶é€šè¿‡å­¦ä¹ ä¸€ä¸ªæ˜ å°„å‡½æ•°ï¼Œå°†å…¶è½¬æ¢ä¸ºä¸è¯­è¨€æ¨¡å‹ embedding å…·æœ‰ç›¸åŒç»´åº¦çš„å‘é‡ã€‚è¿™æ ·ï¼Œè§†è§‰ä¿¡æ¯å°±å¯ä»¥è¢«â€œç¿»è¯‘â€æˆè¯­è¨€æ¨¡å‹èƒ½å¤Ÿç†è§£çš„æ ¼å¼ã€‚
- **è®­ç»ƒçŠ¶æ€ï¼š** æŠ•å½±å±‚çš„å‚æ•°æ˜¯**å¯è®­ç»ƒ**çš„ã€‚åœ¨ LLaVA çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒæŠ•å½±å±‚ä¼šå­¦ä¹ å¦‚ä½•æœ‰æ•ˆåœ°å°†è§†è§‰ç‰¹å¾æ˜ å°„åˆ°è¯­è¨€ç©ºé—´ï¼Œä»¥ä¾¿è¯­è¨€æ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨è¿™äº›è§†è§‰ä¿¡æ¯è¿›è¡Œåç»­çš„ä»»åŠ¡ï¼ˆå¦‚ç”Ÿæˆæè¿°ã€å›ç­”é—®é¢˜ç­‰ï¼‰ã€‚

### 3. å¤§å‹è¯­è¨€æ¨¡å‹ (Large Language Model)

- **ä½œç”¨ï¼š** å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯ LLaVA çš„æ ¸å¿ƒå¤„ç†å•å…ƒï¼Œå®ƒè´Ÿè´£ç†è§£è¾“å…¥çš„æ–‡æœ¬æŒ‡ä»¤å’Œè§†è§‰ç‰¹å¾ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„æ–‡æœ¬è¾“å‡ºã€‚

- **å®ç°ï¼š** LLaVA ä½¿ç”¨å¼ºå¤§çš„é¢„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä¾‹å¦‚ LLaMAã€Vicuna ç­‰ã€‚è¿™äº›æ¨¡å‹åœ¨æµ·é‡æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå…·å¤‡å¼ºå¤§çš„è¯­è¨€ç†è§£ã€ç”Ÿæˆå’Œæ¨ç†èƒ½åŠ›ã€‚

- **å·¥ä½œåŸç†ï¼š** å¤§å‹è¯­è¨€æ¨¡å‹æ¥æ”¶ä¸¤ç§ç±»å‹çš„è¾“å…¥ï¼š

  - **æ–‡æœ¬è¾“å…¥ï¼š** ç”¨æˆ·æå‡ºçš„é—®é¢˜æˆ–æŒ‡ä»¤çš„æ–‡æœ¬ embeddingã€‚

  - è§†è§‰è¾“å…¥ï¼š ç»è¿‡æŠ•å½±å±‚è½¬æ¢åçš„è§†è§‰ç‰¹å¾å‘é‡ï¼Œè¿™äº›å‘é‡è¢«è§†ä¸ºç‰¹æ®Šçš„â€œè§†è§‰ tokenâ€ï¼Œä¸æ–‡æœ¬ token ä¸€èµ·è¾“å…¥åˆ°è¯­è¨€æ¨¡å‹ä¸­ã€‚

    è¯­è¨€æ¨¡å‹å°†è¿™äº›æ··åˆçš„ token åºåˆ—ä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡å…¶ Transformer ç»“æ„è¿›è¡Œå¤„ç†ï¼Œç†è§£å›¾åƒå’Œæ–‡æœ¬ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶æ ¹æ®è¾“å…¥ç”Ÿæˆè¿è´¯ã€ç›¸å…³çš„æ–‡æœ¬å“åº”ã€‚

- **è®­ç»ƒçŠ¶æ€ï¼š** åœ¨ LLaVA çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹çš„å‚æ•°å¯ä»¥æ˜¯**å®Œå…¨å†»ç»“**çš„ï¼Œæˆ–è€…è¿›è¡Œ**éƒ¨åˆ†å¾®è°ƒ**ï¼ˆä¾‹å¦‚ä½¿ç”¨ LoRA ç­‰å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯ï¼‰ã€‚å†»ç»“è¯­è¨€æ¨¡å‹å¯ä»¥å¤§å¹…å‡å°‘è®­ç»ƒè®¡ç®—é‡å’Œå†…å­˜éœ€æ±‚ï¼Œä½†å¯èƒ½é™åˆ¶å…¶é€‚åº”æ–°ä»»åŠ¡çš„èƒ½åŠ›ï¼›éƒ¨åˆ†å¾®è°ƒåˆ™å¯ä»¥åœ¨ä¿æŒæ•ˆç‡çš„åŒæ—¶ï¼Œæé«˜æ¨¡å‹åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚LLaVA çš„åŸå§‹ç‰ˆæœ¬é€šå¸¸æ˜¯å†»ç»“è¯­è¨€æ¨¡å‹å¹¶è®­ç»ƒæŠ•å½±å±‚å’Œå°‘é‡å…¶ä»–å‚æ•°ã€‚

### æ•´ä½“å·¥ä½œæµç¨‹

å½“ç”¨æˆ·å‘ LLaVA è¾“å…¥ä¸€å¼ å›¾åƒå’Œä¸€ä¸ªæ–‡æœ¬é—®é¢˜æ—¶ï¼Œæ•´ä¸ªæµç¨‹å¦‚ä¸‹ï¼š

1. **å›¾åƒå¤„ç†ï¼š** è¾“å…¥å›¾åƒé¦–å…ˆç”±**è§†è§‰ç¼–ç å™¨**å¤„ç†ï¼Œç”Ÿæˆä¸€ç³»åˆ—è§†è§‰ç‰¹å¾å‘é‡ã€‚
2. **ç‰¹å¾è½¬æ¢ï¼š** è¿™äº›è§†è§‰ç‰¹å¾å‘é‡é€šè¿‡**æŠ•å½±å±‚**è¿›è¡Œè½¬æ¢ï¼Œä½¿å…¶ä¸è¯­è¨€æ¨¡å‹çš„è¾“å…¥ embedding ç©ºé—´å¯¹é½ã€‚
3. **è¾“å…¥åºåˆ—æ„å»ºï¼š** è½¬æ¢åçš„è§†è§‰ç‰¹å¾å‘é‡ï¼ˆä½œä¸ºè§†è§‰ tokenï¼‰ä¸ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬é—®é¢˜ï¼ˆä½œä¸ºæ–‡æœ¬ token çš„ embeddingï¼‰æ‹¼æ¥èµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªæ··åˆçš„è¾“å…¥åºåˆ—ã€‚
4. **è¯­è¨€æ¨¡å‹å¤„ç†ï¼š** è¿™ä¸ªæ··åˆçš„è¾“å…¥åºåˆ—è¢«é€å…¥**å¤§å‹è¯­è¨€æ¨¡å‹**ã€‚è¯­è¨€æ¨¡å‹æ ¹æ®è¿™ä¸ªåºåˆ—ç†è§£å›¾åƒå†…å®¹å’Œç”¨æˆ·æ„å›¾ã€‚
5. **æ–‡æœ¬ç”Ÿæˆï¼š** å¤§å‹è¯­è¨€æ¨¡å‹æ ¹æ®å…¶ç†è§£ç”Ÿæˆæ–‡æœ¬å“åº”ï¼Œä¾‹å¦‚å›¾åƒæè¿°ã€é—®é¢˜ç­”æ¡ˆç­‰ã€‚

### æ€»ç»“

LLaVA çš„æ¶æ„é€šè¿‡å·§å¦™åœ°ç»“åˆé¢„è®­ç»ƒçš„è§†è§‰ç¼–ç å™¨å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªå¯è®­ç»ƒçš„æŠ•å½±å±‚è¿æ¥å®ƒä»¬ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†å’Œç†è§£å¤šæ¨¡æ€ä¿¡æ¯ã€‚è¿™ç§æ¶æ„è®¾è®¡å……åˆ†åˆ©ç”¨äº†ç°æœ‰é¢„è®­ç»ƒæ¨¡å‹çš„å¼ºå¤§èƒ½åŠ›ï¼Œå¹¶é€šè¿‡å‚æ•°é«˜æ•ˆçš„æ–¹å¼å®ç°äº†è§†è§‰å’Œè¯­è¨€çš„èåˆï¼Œä¸ºæ„å»ºå¼ºå¤§çš„å¤šæ¨¡æ€ AI åŠ©æ‰‹å¥ å®šäº†åŸºç¡€ã€‚

## BERT æ¶æ„è¯¦è§£

BERT (Bidirectional Encoder Representations from Transformers) æ˜¯ä¸€ç§åŸºäº Transformer æ¶æ„çš„é¢„è®­ç»ƒè¯­è¨€è¡¨ç¤ºæ¨¡å‹ã€‚å®ƒé€šè¿‡åœ¨å¤§å‹æ— æ ‡æ³¨æ–‡æœ¬è¯­æ–™åº“ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå­¦ä¹ é€šç”¨çš„è¯­è¨€è¡¨ç¤ºï¼Œç„¶ååœ¨ç‰¹å®šçš„ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒï¼Œå–å¾—äº†æ˜¾è‘—çš„æ•ˆæœã€‚BERT çš„æ ¸å¿ƒåœ¨äºå…¶åŒå‘æ€§å’ŒåŸºäº Transformer çš„æ·±åº¦ç¼–ç å™¨ç»“æ„ã€‚

### 1. æ•´ä½“æ¶æ„

BERT çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªå¤šå±‚çš„åŒå‘ Transformer **ç¼–ç å™¨ (Encoder)** æ ˆã€‚ä¸åŸå§‹ Transformer æ¨¡å‹åŒ…å«ç¼–ç å™¨å’Œè§£ç å™¨ä¸åŒï¼ŒBERT åªä½¿ç”¨äº† Transformer çš„ç¼–ç å™¨éƒ¨åˆ†ã€‚è¿™æ„å‘³ç€ BERT æ—¨åœ¨ç†è§£è¾“å…¥æ–‡æœ¬çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ç”Ÿæˆåºåˆ—ã€‚

- **å¤šå±‚ç»“æ„:** BERT æœ‰ä¸¤ç§ä¸»è¦å°ºå¯¸ï¼š
  - **BERT-Base:** åŒ…å« 12 ä¸ª Transformer ç¼–ç å™¨å±‚ (L=12)ï¼Œéšè—å±‚ç»´åº¦ä¸º 768 (H=768)ï¼Œè‡ªæ³¨æ„åŠ›å¤´æ•°é‡ä¸º 12 (A=12)ï¼Œæ€»å‚æ•°é‡çº¦ 1.1 äº¿ã€‚
  - **BERT-Large:** åŒ…å« 24 ä¸ª Transformer ç¼–ç å™¨å±‚ (L=24)ï¼Œéšè—å±‚ç»´åº¦ä¸º 1024 (H=1024)ï¼Œè‡ªæ³¨æ„åŠ›å¤´æ•°é‡ä¸º 16 (A=16)ï¼Œæ€»å‚æ•°é‡çº¦ 3.4 äº¿ã€‚
- **Transformer ç¼–ç å™¨å±‚:** æ¯ä¸ªç¼–ç å™¨å±‚ç”±ä¸¤ä¸ªå­å±‚ç»„æˆï¼š
  - **å¤šå¤´è‡ªæ³¨æ„åŠ› (Multi-Head Self-Attention):** å…è®¸æ¨¡å‹åœ¨å¤„ç†æ¯ä¸ªè¯æ—¶ï¼ŒåŒæ—¶å…³æ³¨è¾“å…¥åºåˆ—ä¸­æ‰€æœ‰è¯çš„ä¿¡æ¯ï¼Œæ•æ‰è¯ä¸è¯ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚"å¤šå¤´"æœºåˆ¶ä½¿å¾—æ¨¡å‹å¯ä»¥ä»ä¸åŒçš„è¡¨ç¤ºå­ç©ºé—´å­¦ä¹ ä¿¡æ¯ã€‚
  - **å‰é¦ˆç¥ç»ç½‘ç»œ (Feed-Forward Neural Network):** ä¸€ä¸ªç®€å•çš„ã€ä½ç½®ç‹¬ç«‹çš„å…¨è¿æ¥å‰é¦ˆç½‘ç»œï¼Œé€šå¸¸åŒ…å«ä¸¤ä¸ªçº¿æ€§å±‚å’Œä¸€ä¸ªæ¿€æ´»å‡½æ•° (å¦‚ GELU)ã€‚

- **æ®‹å·®è¿æ¥ (Residual Connections):** æ¯ä¸ªå­å±‚çš„è¾“å…¥ä¼šé€šè¿‡æ®‹å·®è¿æ¥ç›´æ¥åŠ åˆ°è¯¥å­å±‚çš„è¾“å‡ºä¸Šï¼Œæœ‰åŠ©äºç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä½¿å¾—è®­ç»ƒæ›´æ·±å±‚çš„ç½‘ç»œæˆä¸ºå¯èƒ½ã€‚
- **å±‚å½’ä¸€åŒ– (Layer Normalization):** åœ¨æ¯ä¸ªå­å±‚çš„è¾“å‡ºä¹‹åè¿›è¡Œå±‚å½’ä¸€åŒ–ï¼Œæœ‰åŠ©äºç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚

### 2. è¾“å…¥è¡¨ç¤º (Input Representation)

BERT çš„è¾“å…¥ä¸ä»…ä»…æ˜¯è¯çš„åµŒå…¥ï¼Œè€Œæ˜¯ç”±ä¸‰ç§åµŒå…¥å‘é‡ç›¸åŠ è€Œæˆï¼Œä»¥æ•æ‰æ›´ä¸°å¯Œçš„ä¿¡æ¯ï¼š

- **è¯åµŒå…¥ (Token Embeddings):** ä½¿ç”¨ WordPiece æˆ–ç±»ä¼¼çš„å­è¯åˆ‡åˆ†æ–¹æ³•å°†è¾“å…¥æ–‡æœ¬åˆ‡åˆ†æˆè¯å…ƒ (tokens)ã€‚æ¯ä¸ªè¯å…ƒä¼šè¢«æ˜ å°„åˆ°ä¸€ä¸ªå›ºå®šç»´åº¦çš„å‘é‡ã€‚BERT ä½¿ç”¨ä¸€ä¸ªåŒ…å«ç‰¹æ®Šè¯å…ƒçš„è¯æ±‡è¡¨ï¼Œä¾‹å¦‚ï¼š
  - `[CLS]`: åŠ åœ¨æ¯ä¸ªè¾“å…¥åºåˆ—çš„å¼€å¤´ã€‚è¿™ä¸ªè¯å…ƒå¯¹åº”çš„æœ€ç»ˆéšè—çŠ¶æ€é€šå¸¸ç”¨äºåˆ†ç±»ä»»åŠ¡ã€‚
  - `[SEP]`: ç”¨äºåˆ†éš”ä¸¤ä¸ªå¥å­ï¼Œä¾‹å¦‚åœ¨å¥å­å¯¹ä»»åŠ¡ (å¦‚é—®ç­”ã€è‡ªç„¶è¯­è¨€æ¨æ–­) ä¸­ã€‚
  - `[MASK]`: ç”¨äº MLM é¢„è®­ç»ƒä»»åŠ¡ï¼Œè¡¨ç¤ºè¢«é®ç›–çš„è¯å…ƒã€‚
- **æ®µåµŒå…¥ (Segment Embeddings):** ç”¨äºåŒºåˆ†è¾“å…¥ä¸­çš„ä¸åŒå¥å­ã€‚ä¾‹å¦‚ï¼Œåœ¨å¥å­å¯¹ä»»åŠ¡ä¸­ï¼Œç¬¬ä¸€ä¸ªå¥å­çš„æ‰€æœ‰è¯å…ƒä¼šåŠ ä¸Šå¥å­ A çš„åµŒå…¥ï¼Œç¬¬äºŒä¸ªå¥å­çš„æ‰€æœ‰è¯å…ƒä¼šåŠ ä¸Šå¥å­ B çš„åµŒå…¥ã€‚å¯¹äºå•å¥è¾“å…¥ï¼Œæ‰€æœ‰è¯å…ƒéƒ½ä½¿ç”¨å¥å­ A çš„åµŒå…¥ã€‚
- **ä½ç½®åµŒå…¥ (Position Embeddings):** ç”±äº Transformer æœ¬èº«ä¸åŒ…å«åºåˆ—é¡ºåºçš„ä¿¡æ¯ (ä¸åƒ RNN)ï¼ŒBERT å¼•å…¥äº†ä½ç½®åµŒå…¥æ¥å­¦ä¹ è¯å…ƒåœ¨åºåˆ—ä¸­çš„ä½ç½®ä¿¡æ¯ã€‚BERT ä½¿ç”¨çš„æ˜¯**å¯å­¦ä¹ çš„**ä½ç½®åµŒå…¥ï¼Œè€Œä¸æ˜¯åŸå§‹ Transformer ä¸­çš„æ­£å¼¦/ä½™å¼¦ä½ç½®ç¼–ç ã€‚æ¯ä¸ªä½ç½® (ä» 0 åˆ°æœ€å¤§åºåˆ—é•¿åº¦) éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„åµŒå…¥å‘é‡ã€‚

æœ€ç»ˆçš„è¾“å…¥è¡¨ç¤ºæ˜¯è¿™ä¸‰ç§åµŒå…¥å‘é‡çš„**é€å…ƒç´ ç›¸åŠ **ã€‚

```
Input Embedding = Token Embedding + Segment Embedding + Position Embedding
```

### 3. é¢„è®­ç»ƒä»»åŠ¡ (Pre-training Tasks)

BERT çš„å¼ºå¤§èƒ½åŠ›å¾ˆå¤§ç¨‹åº¦ä¸Šå½’åŠŸäºå…¶åˆ›æ–°çš„é¢„è®­ç»ƒç­–ç•¥ï¼Œå®ƒé€šè¿‡ä¸¤ä¸ªæ— ç›‘ç£ä»»åŠ¡åœ¨å¤§é‡æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼š

- **é®ç›–è¯­è¨€æ¨¡å‹ (Masked Language Model - MLM):**

  - **åŠ¨æœº:** ä¸ºäº†å®ç°çœŸæ­£çš„åŒå‘è¡¨ç¤ºå­¦ä¹ ã€‚ä¼ ç»Ÿçš„ä»å·¦åˆ°å³æˆ–ä»å³åˆ°å·¦çš„è¯­è¨€æ¨¡å‹åªèƒ½åˆ©ç”¨å•å‘çš„ä¸Šä¸‹æ–‡ã€‚å¦‚æœç®€å•åœ°è®©æ¨¡å‹é¢„æµ‹æ‰€æœ‰è¯ï¼Œæ¨¡å‹å¯ä»¥é€šè¿‡"çœ‹åˆ°è‡ªå·±"æ¥è½»æ˜“é¢„æµ‹ç›®æ ‡è¯ï¼Œæ— æ³•å­¦åˆ°æ·±å±‚ä¸Šä¸‹æ–‡ã€‚

  - **æ–¹æ³•:** éšæœºé®ç›– (Mask) è¾“å…¥åºåˆ—ä¸­ä¸€å®šæ¯”ä¾‹ (é€šå¸¸æ˜¯ 15%) çš„è¯å…ƒï¼Œç„¶åè®©æ¨¡å‹åŸºäº**æ‰€æœ‰**æœªè¢«é®ç›–çš„è¯å…ƒ (å³å·¦å³ä¸Šä¸‹æ–‡) æ¥é¢„æµ‹è¿™äº›è¢«é®ç›–çš„åŸå§‹è¯å…ƒã€‚

  - **ç»†èŠ‚:**

    - 80% çš„æ¦‚ç‡ï¼Œå°†é€‰ä¸­çš„è¯å…ƒæ›¿æ¢ä¸º `[MASK]`ã€‚

    - 10% çš„æ¦‚ç‡ï¼Œå°†é€‰ä¸­çš„è¯å…ƒæ›¿æ¢ä¸º**éšæœº**çš„å…¶ä»–è¯å…ƒã€‚

    - 10% çš„æ¦‚ç‡ï¼Œä¿æŒé€‰ä¸­çš„è¯å…ƒä¸å˜ã€‚

      è¿™æ ·åšæ˜¯ä¸ºäº†å‡å°‘é¢„è®­ç»ƒå’Œå¾®è°ƒä¹‹é—´çš„ä¸åŒ¹é… (å› ä¸ºå¾®è°ƒæ—¶è¾“å…¥ä¸­æ²¡æœ‰ [MASK] æ ‡è®°)ï¼Œå¹¶è¿«ä½¿æ¨¡å‹å­¦ä¹ æ¯ä¸ªè¯å…ƒçš„åˆ†å¸ƒå¼è¡¨ç¤ºã€‚

  - **ç›®æ ‡:** æœ€å°åŒ–æ¨¡å‹é¢„æµ‹çš„è¢«é®ç›–è¯å…ƒä¸åŸå§‹è¯å…ƒä¹‹é—´çš„äº¤å‰ç†µæŸå¤±ã€‚

- **ä¸‹ä¸€å¥é¢„æµ‹ (Next Sentence Prediction - NSP):**

  - **åŠ¨æœº:** è®¸å¤šé‡è¦çš„ä¸‹æ¸¸ä»»åŠ¡ (å¦‚é—®ç­” QA, è‡ªç„¶è¯­è¨€æ¨æ–­ NLI) éœ€è¦ç†è§£å¥å­ä¹‹é—´çš„å…³ç³»ï¼Œè€Œ MLM ä»»åŠ¡æœ¬èº«æ— æ³•ç›´æ¥æ•æ‰è¿™ç§å…³ç³»ã€‚
  - **æ–¹æ³•:** ç»™å®šä¸¤ä¸ªå¥å­ A å’Œ Bï¼Œæ¨¡å‹éœ€è¦é¢„æµ‹å¥å­ B æ˜¯å¦æ˜¯å¥å­ A åœ¨åŸå§‹æ–‡æœ¬ä¸­çš„**å®é™…ä¸‹ä¸€å¥** (IsNext) è¿˜æ˜¯ä¸€ä¸ª**éšæœº**çš„å¥å­ (NotNext)ã€‚
  - **æ„é€ æ ·æœ¬:**
    - 50% çš„æ ·æœ¬ï¼ŒB æ˜¯ A çš„å®é™…ä¸‹ä¸€å¥ã€‚
    - 50% çš„æ ·æœ¬ï¼ŒB æ˜¯ä»è¯­æ–™åº“ä¸­éšæœºé€‰æ‹©çš„å¥å­ã€‚
  - **ç›®æ ‡:** é€šå¸¸ä½¿ç”¨ `[CLS]` è¯å…ƒå¯¹åº”çš„æœ€ç»ˆéšè—çŠ¶æ€ï¼Œé€šè¿‡ä¸€ä¸ªç®€å•çš„åˆ†ç±»å™¨æ¥é¢„æµ‹ `IsNext` æˆ– `NotNext`ï¼Œå¹¶æœ€å°åŒ–äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±ã€‚

BERT çš„é¢„è®­ç»ƒè¿‡ç¨‹åŒæ—¶ä¼˜åŒ– MLM å’Œ NSP ä¸¤ä¸ªä»»åŠ¡çš„è”åˆæŸå¤±ã€‚

### 4. å¾®è°ƒ (Fine-tuning)

ç»è¿‡é¢„è®­ç»ƒåï¼ŒBERT æ¨¡å‹å­¦ä¹ åˆ°äº†é€šç”¨çš„è¯­è¨€è¡¨ç¤ºã€‚ä¸ºäº†å°†å…¶åº”ç”¨äºç‰¹å®šçš„ä¸‹æ¸¸ä»»åŠ¡ï¼Œéœ€è¦è¿›è¡Œå¾®è°ƒï¼š

1. **åŠ è½½é¢„è®­ç»ƒæ¨¡å‹:** ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„ BERT æ¨¡å‹å‚æ•°åˆå§‹åŒ–æ¨¡å‹ã€‚
2. **ä¿®æ”¹è¾“å‡ºå±‚:** æ ¹æ®å…·ä½“ä»»åŠ¡è°ƒæ•´æ¨¡å‹çš„è¾“å‡ºå±‚ã€‚ä¾‹å¦‚ï¼š
   - **åˆ†ç±»ä»»åŠ¡ (å¦‚æƒ…æ„Ÿåˆ†æã€NLI):** åœ¨ `[CLS]` è¯å…ƒå¯¹åº”çš„æœ€ç»ˆéšè—çŠ¶æ€ä¸Šæ·»åŠ ä¸€ä¸ªçº¿æ€§åˆ†ç±»å±‚ã€‚
   - **åºåˆ—æ ‡æ³¨ä»»åŠ¡ (å¦‚å‘½åå®ä½“è¯†åˆ« NER):** åœ¨æ¯ä¸ªè¯å…ƒå¯¹åº”çš„æœ€ç»ˆéšè—çŠ¶æ€ä¸Šæ·»åŠ ä¸€ä¸ªçº¿æ€§åˆ†ç±»å±‚ã€‚
   - **é—®ç­”ä»»åŠ¡ (å¦‚ SQuAD):** é¢„æµ‹ç­”æ¡ˆåœ¨åŸæ–‡ä¸­çš„èµ·å§‹å’Œç»“æŸä½ç½®ï¼Œé€šå¸¸éœ€è¦ä¸¤ä¸ªç‹¬ç«‹çš„çº¿æ€§å±‚åˆ†åˆ«é¢„æµ‹å¼€å§‹å’Œç»“æŸæ¦‚ç‡ã€‚
3. **ç«¯åˆ°ç«¯è®­ç»ƒ:** ä½¿ç”¨ç‰¹å®šä»»åŠ¡çš„æ ‡æ³¨æ•°æ®ï¼Œå¯¹æ•´ä¸ªæ¨¡å‹ (åŒ…æ‹¬ BERT çš„å‚æ•°å’Œæ–°æ·»åŠ çš„è¾“å‡ºå±‚) è¿›è¡Œç«¯åˆ°ç«¯çš„è®­ç»ƒã€‚å¾®è°ƒé€šå¸¸ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼Œå¹¶ä¸”åªéœ€è¦è¾ƒå°‘çš„è®­ç»ƒè½®æ•° (Epochs)ã€‚

### æ€»ç»“

BERT çš„æ¶æ„æ ¸å¿ƒæ˜¯åŸºäº Transformer çš„å¤šå±‚åŒå‘ç¼–ç å™¨ã€‚å…¶åˆ›æ–°çš„è¾“å…¥è¡¨ç¤º (ç»“åˆè¯ã€æ®µã€ä½ç½®åµŒå…¥) å’Œé¢„è®­ç»ƒä»»åŠ¡ (MLM å’Œ NSP) ä½¿å…¶èƒ½å¤Ÿå­¦ä¹ åˆ°æ·±å±‚æ¬¡ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è¯­è¨€è¡¨ç¤ºã€‚é€šè¿‡åœ¨å¤§è§„æ¨¡æ— æ ‡æ³¨æ•°æ®ä¸Šé¢„è®­ç»ƒï¼Œç„¶ååœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒï¼ŒBERT åŠå…¶å˜ç§åœ¨ä¼—å¤šè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸Šå–å¾—äº†çªç ´æ€§çš„è¿›å±•ã€‚

## RMSNorm

![image-20250312163506339](../my_minimind/images/image-20250312163506339.png)

## GQAï¼šGrouped Query Attention

ä¸ºäº†å‡å°‘è®¡ç®—é‡æˆ–å‚æ•°æ•°é‡ï¼Œå¯èƒ½ä¼šå…±äº«é”®å’Œå€¼çš„å¤´ï¼Œå³æ‰€è°“çš„â€œGrouped Query Attentionâ€ï¼ˆGQAï¼‰æˆ–è€…ç±»ä¼¼çš„å˜ä½“ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œé”®å’Œå€¼çš„å¤´æ•°ï¼ˆn_kv_headsï¼‰å¯èƒ½å°‘äºæŸ¥è¯¢çš„å¤´æ•°ï¼ˆn_headsï¼‰ã€‚



my_minimind-Denseï¼ˆå’Œ[Llama3.1](https://ai.meta.com/blog/meta-llama-3-1/)ä¸€æ ·ï¼‰ä½¿ç”¨äº†Transformerçš„Decoder-Onlyç»“æ„ï¼Œè·ŸGPT-3çš„åŒºåˆ«åœ¨äºï¼š

* é‡‡ç”¨äº†GPT-3çš„é¢„æ ‡å‡†åŒ–æ–¹æ³•ï¼Œä¹Ÿå°±æ˜¯åœ¨æ¯ä¸ªTransformerå­å±‚çš„è¾“å…¥ä¸Šè¿›è¡Œå½’ä¸€åŒ–ï¼Œè€Œä¸æ˜¯åœ¨è¾“å‡ºä¸Šã€‚å…·ä½“æ¥è¯´ï¼Œä½¿ç”¨çš„æ˜¯RMSNormå½’ä¸€åŒ–å‡½æ•°ã€‚
* ç”¨SwiGLUæ¿€æ´»å‡½æ•°æ›¿ä»£äº†ReLUï¼Œè¿™æ ·åšæ˜¯ä¸ºäº†æé«˜æ€§èƒ½ã€‚
* åƒGPT-Neoä¸€æ ·ï¼Œå»æ‰äº†ç»å¯¹ä½ç½®åµŒå…¥ï¼Œæ”¹ç”¨äº†æ—‹è½¬ä½ç½®åµŒå…¥ï¼ˆRoPEï¼‰ï¼Œè¿™æ ·åœ¨å¤„ç†è¶…å‡ºè®­ç»ƒé•¿åº¦çš„æ¨ç†æ—¶æ•ˆæœæ›´å¥½ã€‚

---

my_minimind-MoEæ¨¡å‹ï¼Œå®ƒçš„ç»“æ„åŸºäºLlama3å’Œ[Deepseek-V2/3](https://arxiv.org/pdf/2405.04434)ä¸­çš„MixFFNæ··åˆä¸“å®¶æ¨¡å—ã€‚

* DeepSeek-V2åœ¨å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰æ–¹é¢ï¼Œé‡‡ç”¨äº†æ›´ç»†ç²’åº¦çš„ä¸“å®¶åˆ†å‰²å’Œå…±äº«çš„ä¸“å®¶éš”ç¦»æŠ€æœ¯ï¼Œä»¥æé«˜Expertsçš„æ•ˆæœã€‚

---

## PretrainedConfig

åœ¨Hugging Faceçš„Transformersåº“ä¸­ï¼Œ**`PretrainedConfig`** æ˜¯ä¸€ä¸ªæ ¸å¿ƒç±»ï¼Œç”¨äºå­˜å‚¨å’Œç®¡ç†é¢„è®­ç»ƒæ¨¡å‹çš„é…ç½®ä¿¡æ¯ã€‚å®ƒçš„ä¸»è¦ä½œç”¨æ˜¯ä¸ºæ¨¡å‹å®šä¹‰ç»“æ„å‚æ•°å’Œè¶…å‚æ•°ï¼Œç¡®ä¿æ¨¡å‹åœ¨åŠ è½½ã€ä¿å­˜å’Œåˆå§‹åŒ–æ—¶ä¿æŒä¸€è‡´æ€§å’Œå¯å¤ç°æ€§ã€‚

## Moeè´Ÿè½½å‡è¡¡

```
è®¾ N æ˜¯ä¸“å®¶çš„æ€»æ•°ï¼Œå¯¹äºä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼š
f_iè¡¨ç¤ºä¸“å®¶ i æ¥æ”¶åˆ°çš„è¾“å…¥å•å…ƒçš„æ¯”ä¾‹ï¼ˆå æ‰¹æ¬¡ä¸­æ‰€æœ‰è¾“å…¥å•å…ƒçš„æ¯”ä¾‹ï¼‰ã€‚ce
p_iè¡¨ç¤ºé—¨æ§ç½‘ç»œä¸ºä¸“å®¶ i è¾“å‡ºçš„å¹³å‡è·¯ç”±æ¦‚ç‡ï¼ˆå¯¹æ‰¹æ¬¡ä¸­æ‰€æœ‰è¾“å…¥å•å…ƒå–å¹³å‡ï¼‰ã€‚score_mean



åºåˆ—çº§åˆ«è´Ÿè½½å‡è¡¡ (Sequence-Level Load Balancing)
æ—¨åœ¨å°†ä¸€ä¸ªåºåˆ—ä¸­ä¸åŒä½ç½®çš„å…ƒç´ ï¼ˆtokenï¼‰çš„å¤„ç†è´Ÿè½½åˆ†æ•£åˆ°ä¸åŒçš„ä¸“å®¶ä¸Šã€‚

æ ·æœ¬çº§åˆ«è´Ÿè½½å‡è¡¡ (Sample-Level Load Balancing)
æ—¨åœ¨å°†ä¸åŒçš„å®Œæ•´è¾“å…¥æ ·æœ¬åˆ†é…ç»™ä¸åŒçš„ä¸“å®¶è¿›è¡Œå¤„ç†
```

![image-20250312191644634](../my_minimind/images/image-20250312191644634.png)

### self.scatter_add(dim,index,src)

ç´¯åŠ 

![img](../my_minimind/images/v2-e68a940a7be07f7ab08899e357362d5f_1440w.jpg)

![img](../my_minimind/images/v2-e29b96c849bbfaa1fc55ded7f2913442_1440w.jpg)



![image-20250313100147640](../my_minimind/images/image-20250313100147640.png)

## RoPEï¼ˆRotary Position Embeddingï¼‰

### ç®€å•äº†è§£

R(theta)å°±æ˜¯æ—‹è½¬çŸ©é˜µ

![image-20250318110543999](../my_minimind/images/image-20250318110543999.png)

![image-20250318110603931](../my_minimind/images/image-20250318110603931.png)

å¤šç»´

çœ‹ä½œæ˜¯é’Ÿè¡¨ï¼›må’Œnæ˜¯tokençš„ä½ç½®

![image-20250318110639726](../my_minimind/images/image-20250318110639726.png)

### å…·ä½“å…¬å¼

https://www.bilibili.com/video/BV12x42127Pb?spm_id_from=333.788.videopod.sections&vd_source=edb614e9f3e817577f46a2e9deeca011

![image-20250416100708654](pic/image-20250416100708654.png)

![image-20250416100830215](pic/image-20250416100830215.png)

![image-20250416100923520](pic/image-20250416100923520.png)

### è®¾è®¡å…¬å¼éªŒè¯

![image-20250416101224278](pic/image-20250416101224278.png)

![image-20250416101251052](pic/image-20250416101251052.png)

### äºŒç»´åˆ°å¤šç»´

![image-20250416101402998](pic/image-20250416101402998.png)

![image-20250416101649364](pic/image-20250416101649364.png)

#### **ä»£ç å®ç°**

```
ä¸éœ€è¦æŒ‰ç…§ç›¸é‚»ä¸¤ä¸¤ç»„åˆå¥‡å¶ä½ç½®ï¼›å› ä¸ºç¥ç»å…ƒæ˜¯æ— åºçš„ï¼Œä¸ä¾èµ–ç»´åº¦é¡ºåº

chatglmä¸­ä¸ºäº†é«˜æ•ˆåœ°å®ç° RoPEï¼ŒæŠŠå‘é‡åœ¨å†…å­˜ä¸­é‡æ–°æ’åˆ—æˆå‰åä¸¤éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯ä¸¥æ ¼æŒ‰ç…§å¥‡å¶ä½ç½®ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†å……åˆ†åˆ©ç”¨ç¡¬ä»¶çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›ã€‚
```

![image-20250416102436015](pic/image-20250416102436015.png)

## LoRAï¼ˆLow-Rank Adaptation of Large Language Modelsï¼‰

### lora

peft (Parameter-Efficient Fine-Tuning)

 ä»2019å¹´çš„Adapter, åˆ°2021å¹´çš„Prefix-tuningï¼Œåœ¨åˆ°ç°åœ¨2023æœ€å¸¸ç”¨çš„å¾®è°ƒæ–¹æ³•LoRAã€‚

![image-20250329103055851](D:/RL-study/pic/image-20250329103055851.png)

åå‘ä¼ æ’­æ—¶ä»…æ›´æ–°Loraæƒé‡çŸ©é˜µ

æ›´æ–°åLoraçŸ©é˜µåŠ åˆ°åŸå§‹æƒé‡çŸ©é˜µä¸Šå®Œæˆæ›´æ–°

![image-20250318103129964](../my_minimind/images/image-20250318103129964.png)

rè¿œè¿œå°äºM,Nï¼Œå› æ­¤é™ä½äº†å‚æ•°é‡

![image-20250318103544107](../my_minimind/images/image-20250318103544107.png)

$$
h=W_0x+\bigtriangleup W_x=W_0x+BAx
$$

```
å‚æ•°Aåˆå§‹åŒ–ä¸ºrandomé«˜æ–¯åˆ†å¸ƒï¼Œå‚æ•°Båˆå§‹åŒ–ä¸º0ï¼›
å¥½å¤„æ˜¯æ²¡æœ‰åœ¨ä¸€å¼€å§‹å¼•å…¥å™ªå£°
Bç¡®ä¿äº†å¾®è°ƒä»é¢„è®­ç»ƒæ¨¡å‹çš„çŠ¶æ€å¼€å§‹ï¼Œé¿å…äº†åˆå§‹çš„å¹²æ‰°ï¼ŒåŒæ—¶ä¹Ÿä¸ºä½ç§©çŸ©é˜µåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ æœ‰æ•ˆçš„ä»»åŠ¡ç‰¹å®šé€‚åº”æä¾›äº†åŸºç¡€ã€‚
ä½¿ç”¨éšæœºé«˜æ–¯åˆ†å¸ƒåˆå§‹åŒ–çŸ©é˜µ Aï¼Œåˆ™ä¸ºä½ç§©æ›´æ–° (BA) åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ æœ‰æ„ä¹‰çš„å˜åŒ–æä¾›äº†å¿…è¦çš„å¤šæ ·æ€§å’Œéé›¶å€¼
```

### Qlora

QLoRA æ˜¯ä¸€ç§é«˜æ•ˆçš„å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) å¾®è°ƒæŠ€æœ¯ï¼Œå®ƒå»ºç«‹åœ¨ LoRA (Low-Rank Adaptation) çš„åŸºç¡€ä¹‹ä¸Šï¼Œå¹¶é€šè¿‡å¼•å…¥é‡åŒ–è¿›ä¸€æ­¥é™ä½äº†å†…å­˜æ¶ˆè€—ã€‚

QLoRA çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

1. **å°†é¢„è®­ç»ƒçš„åŸºç¡€æ¨¡å‹é‡åŒ–åˆ°ä½ç²¾åº¦**ï¼ˆé€šå¸¸æ˜¯ 4 ä½ï¼Œå¦‚ 4-bit NormalFloatï¼‰ï¼Œä»¥æå¤§å‡å°‘æ¨¡å‹çš„å†…å­˜å ç”¨ã€‚
2. **å¼•å…¥ä½ç§©é€‚é…å™¨ (LoRA Adapters)**ï¼Œè¿™äº›é€‚é…å™¨æ˜¯ä¸€äº›å°çš„ã€å¯è®­ç»ƒçš„çŸ©é˜µï¼Œæ³¨å…¥åˆ°åŸºç¡€æ¨¡å‹çš„ç‰¹å®šå±‚ï¼ˆä¸»è¦æ˜¯çº¿æ€§å±‚ï¼‰ä¸­ã€‚
3. **ä»…è®­ç»ƒè¿™äº› LoRA é€‚é…å™¨**ï¼Œè€ŒåŸºç¡€æ¨¡å‹çš„é‡åŒ–æƒé‡åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ä¿æŒå†»ç»“ä¸å˜ã€‚
4. **åœ¨æ›´é«˜ç²¾åº¦ä¸‹è¿›è¡Œ LoRA é€‚é…å™¨çš„è®¡ç®—å’Œä¼˜åŒ–**ï¼ˆé€šå¸¸æ˜¯ FP16 æˆ– bfloat16ï¼‰ï¼Œä»¥ä¿æŒè®­ç»ƒçš„æ•°å€¼ç¨³å®šæ€§ã€‚

**å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ**

QLoRA çš„å·¥ä½œåŸç†å¯ä»¥åˆ†è§£ä¸ºä»¥ä¸‹å‡ ä¸ªå…³é”®éƒ¨åˆ†ï¼š

1. **åŸºç¡€æ¨¡å‹çš„ 4 ä½é‡åŒ–**: è¿™æ˜¯ QLoRA èŠ‚çœå†…å­˜çš„ä¸»è¦æ‰‹æ®µã€‚é¢„è®­ç»ƒå¥½çš„ LLM çš„æƒé‡è¢«é‡åŒ–åˆ° 4 ä½ç²¾åº¦ã€‚QLoRA æå‡ºäº†ä¸€ç§åä¸º **NormalFloat (NF4)** çš„ 4 ä½æ•°æ®ç±»å‹ï¼Œå®ƒé’ˆå¯¹æƒé‡é€šå¸¸éµå¾ªæ­£æ€åˆ†å¸ƒçš„ç‰¹ç‚¹è¿›è¡Œäº†ä¼˜åŒ–ï¼Œèƒ½åœ¨ 4 ä½ä¸‹æ›´æœ‰æ•ˆåœ°è¡¨ç¤ºæƒé‡å€¼ã€‚é‡åŒ–åçš„æƒé‡å­˜å‚¨åœ¨æ˜¾å­˜ä¸­ã€‚
2. **LoRA é€‚é…å™¨**: ä¸åŸå§‹ LoRA ä¸€æ ·ï¼ŒQLoRA åœ¨åŸºç¡€æ¨¡å‹çš„æ¯ä¸ªè¢«é€‰ä¸­çš„çº¿æ€§å±‚ W0 ä¸­ï¼ŒåŠ å…¥ä¸¤ä¸ªå°çš„çŸ©é˜µ A å’Œ Bã€‚åŸå§‹çš„æƒé‡æ›´æ–° Î”W è¢«çº¦æŸä¸º BAï¼Œå…¶ä¸­ BâˆˆRdÃ—rï¼ŒAâˆˆRrÃ—kï¼Œr æ˜¯è¿œå°äº d å’Œ k çš„ç§©ã€‚åœ¨ QLoRA ä¸­ï¼Œè¿™äº›çŸ©é˜µ A å’Œ B **ä¸è¢«é‡åŒ–**ï¼Œå®ƒä»¬ä»¥æ›´é«˜ç²¾åº¦ï¼ˆå¦‚ FP16 æˆ– bfloat16ï¼‰è¿›è¡Œè®­ç»ƒã€‚
3. **å‰å‘ä¼ æ’­**: åœ¨å‰å‘ä¼ æ’­æ—¶ï¼Œè¾“å…¥æ•°æ®ä¸åŸºç¡€æ¨¡å‹çš„é‡åŒ–æƒé‡çŸ©é˜µç›¸ä¹˜ (QW0Ã—x)ï¼ŒåŒæ—¶ä¸ LoRA é€‚é…å™¨çŸ©é˜µç›¸ä¹˜ ((BA)Ã—x)ã€‚ä¸ºäº†æ‰§è¡Œè®¡ç®—ï¼Œé‡åŒ–æƒé‡ QW0 éœ€è¦åœ¨è®¡ç®—æ—¶åŠ¨æ€åœ°åé‡åŒ–å›æ›´é«˜ç²¾åº¦ï¼ˆä¾‹å¦‚ FP16ï¼‰ã€‚ç„¶åï¼Œåé‡åŒ–åçš„åŸºç¡€æƒé‡ç»“æœä¸ LoRA é€‚é…å™¨çš„è®¡ç®—ç»“æœç›¸åŠ ã€‚æ•´ä¸ªè®¡ç®—æµç¨‹å¤§è‡´æ˜¯ï¼šè¾“å…¥ -> åé‡åŒ– QW0 åˆ° FP16 -> è®¡ç®— FP16 çš„ W0Ã—x -> è®¡ç®— FP16 çš„ (BA)Ã—x -> å°†ä¸¤ä¸ªç»“æœç›¸åŠ  -> è¾“å‡ºï¼ˆå¯èƒ½å†è¢«é‡åŒ–ï¼‰ã€‚
4. **åå‘ä¼ æ’­**: æ¢¯åº¦åªç›¸å¯¹äº LoRA é€‚é…å™¨çŸ©é˜µ A å’Œ B è®¡ç®—ã€‚ç”±äºåŸºç¡€æ¨¡å‹çš„æƒé‡æ˜¯å†»ç»“çš„ï¼Œå®ƒä»¬ä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œè¿™å¤§å¤§å‡å°‘äº†è®¡ç®—é‡å’Œæ˜¾å­˜éœ€æ±‚ã€‚
5. **ä¼˜åŒ–å™¨**: ä¼˜åŒ–å™¨ä»…æ›´æ–° LoRA é€‚é…å™¨çŸ©é˜µ A å’Œ B çš„å‚æ•°ã€‚è¿™äº›å‚æ•°æ•°é‡è¿œå°‘äºåŸºç¡€æ¨¡å‹çš„å‚æ•°æ•°é‡ã€‚

**QLoRA çš„åˆ›æ–°ç‚¹:**

é™¤äº†ç»“åˆé‡åŒ–å’Œ LoRAï¼ŒQLoRA è®ºæ–‡è¿˜æå‡ºäº†å‡ ä¸ªå…³é”®çš„æŠ€æœ¯æ¥ç¡®ä¿åœ¨ä½æ˜¾å­˜ä¸‹çš„è®­ç»ƒå¯è¡Œæ€§å’Œç²¾åº¦ï¼š

- **4-bit NormalFloat (NF4)**: ä¸€ç§æ–°çš„ä¿¡æ¯ç†è®ºä¸Šæœ€ä¼˜çš„ 4 ä½é‡åŒ–æ•°æ®ç±»å‹ï¼Œå°¤å…¶é€‚åˆæ­£æ€åˆ†å¸ƒçš„æƒé‡ã€‚
- **åŒé‡åŒ– (Double Quantization, DQ)**: å¯¹é‡åŒ–å¸¸æ•°ï¼ˆå¦‚ scale å’Œ zero_pointï¼‰æœ¬èº«ä¹Ÿè¿›è¡Œé‡åŒ–ã€‚è™½ç„¶èŠ‚çœçš„å†…å­˜ä¸å¤šï¼Œä½†å®ƒè¿›ä¸€æ­¥å‡å°‘äº†é‡åŒ–ç›¸å…³çš„é¢å¤–å†…å­˜å¼€é”€ã€‚
- **åˆ†é¡µä¼˜åŒ–å™¨ (Paged Optimizers)**: åˆ©ç”¨ NVIDIA Unified Memory çš„ç‰¹æ€§ï¼Œå°†ä¼˜åŒ–å™¨çš„çŠ¶æ€ï¼ˆå¦‚ Adam çš„åŠ¨é‡å’Œæ–¹å·®ï¼‰åˆ†é¡µåˆ° CPU å†…å­˜ï¼Œåªåœ¨éœ€è¦æ—¶åŠ è½½åˆ° GPUï¼Œé¿å…äº†ä¼˜åŒ–å™¨çŠ¶æ€å ç”¨è¿‡å¤š GPU æ˜¾å­˜å¯¼è‡´ OOM (Out of Memory)ã€‚
- **æ¢¯åº¦æ£€æŸ¥ç‚¹ (Gradient Checkpointing)**: ä¸€ç§æ ‡å‡†çš„å†…å­˜ä¼˜åŒ–æŠ€æœ¯ï¼Œé€šè¿‡åœ¨åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—ä¸€éƒ¨åˆ†å‰å‘ä¼ æ’­çš„ç»“æœæ¥èŠ‚çœæ˜¾å­˜ï¼ŒQLoRA æ›´ç§¯æåœ°ä½¿ç”¨äº†å®ƒã€‚

**ä¸ºä»€ä¹ˆ QLoRA èƒ½é«˜æ•ˆå¾®è°ƒå¤§æ¨¡å‹ï¼Ÿ**

- **æä½çš„æ˜¾å­˜å ç”¨**: åŸºç¡€æ¨¡å‹é‡åŒ–åˆ° 4 ä½æ˜¯å†…å­˜æ•ˆç‡çš„å…³é”®ã€‚
- **å‚æ•°é«˜æ•ˆ**: ä»…è®­ç»ƒ LoRA é€‚é…å™¨ï¼Œè®­ç»ƒå‚æ•°é‡æå°‘ã€‚
- **è®¡ç®—é«˜æ•ˆ**: åˆ©ç”¨äº†é«˜åº¦ä¼˜åŒ–çš„ 4 ä½è®¡ç®—æ ¸ï¼ˆå¦‚ `bitsandbytes` æä¾›çš„ CUDA Kernelï¼‰ã€‚
- **ç²¾åº¦ä¿æŒ**: NF4 é‡åŒ–ã€åŒé‡åŒ–å’Œåœ¨æ›´é«˜ç²¾åº¦ä¸‹è®­ç»ƒ LoRA é€‚é…å™¨æœ‰åŠ©äºåœ¨å¤§å¹…é™ä½å†…å­˜çš„åŒæ—¶ä¿æŒå¯æ¥å—çš„ç²¾åº¦ã€‚

### ä»£ç 

å®ç° QLoRA å¾®è°ƒé€šå¸¸éœ€è¦ç»“åˆä½¿ç”¨ä»¥ä¸‹åº“ï¼š

- `transformers`: ç”¨äºåŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œä»¥åŠæä¾› `Trainer` API è¿›è¡Œè®­ç»ƒã€‚
- `peft` (Parameter-Efficient Fine-tuning): æä¾›äº† LoRA ç­‰å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯çš„å®ç°ï¼Œèƒ½å¤Ÿè½»æ¾åœ°å°† LoRA é€‚é…å™¨æ³¨å…¥åˆ°åŸºç¡€æ¨¡å‹ä¸­ã€‚
- `bitsandbytes`: æä¾›äº†é«˜æ•ˆçš„ 8 ä½å’Œ 4 ä½é‡åŒ–åŠŸèƒ½ï¼Œä»¥åŠç›¸åº”çš„ä¼˜åŒ–å™¨å’Œ CUDA Kernelã€‚

```python
# é¦–å…ˆç¡®ä¿å®‰è£…å¿…è¦çš„åº“
# pip install transformers peft bitsandbytes accelerate datasets

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from datasets import load_dataset

# --- é…ç½® ---
# é€‰æ‹©ä½ è¦å¾®è°ƒçš„æ¨¡å‹ï¼Œè¿™é‡Œä»¥ä¸€ä¸ªè¾ƒå°çš„æ¨¡å‹ä¸ºä¾‹ï¼Œå¤§æ¨¡å‹åŸç†ç›¸åŒ
model_name = "facebook/opt-125m" # æ›¿æ¢ä¸ºä½ éœ€è¦å¾®è°ƒçš„æ¨¡å‹åç§°ï¼Œå¦‚ "meta-llama/Llama-2-7b-hf"
dataset_name = "Abirate/english_quotes" # ç¤ºä¾‹æ•°æ®é›†
output_dir = "./qlora-finetuning-demo"
lora_r = 16         # LoRA çš„ç§©
lora_alpha = 32     # LoRA çš„ç¼©æ”¾å› å­
lora_dropout = 0.05 # LoRA å±‚çš„ dropout
# é€šå¸¸éœ€è¦æ ¹æ®æ¨¡å‹ç»“æ„ç¡®å®š target_modulesï¼Œè¿™é‡Œæ˜¯ OPT æ¨¡å‹çš„çº¿æ€§å±‚åç§°
# å¯¹äº Llama æ¨¡å‹ï¼Œé€šå¸¸æ˜¯ ['q_proj', 'k_proj', 'v_proj', 'o_proj'] ç­‰
target_modules = ["q_proj", "v_proj"]

# --- 1. åŠ è½½åˆ†è¯å™¨ ---
tokenizer = AutoTokenizer.from_pretrained(model_name)
# è®¾ç½® padding tokenï¼Œè®¸å¤šæ¨¡å‹æ²¡æœ‰é»˜è®¤çš„ padding tokenï¼Œéœ€è¦æ‰‹åŠ¨è®¾ç½®
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

# --- 2. åŠ è½½åŸºç¡€æ¨¡å‹å¹¶è¿›è¡Œ 4 ä½é‡åŒ– ---
# load_in_4bit=True å‘Šè¯‰ transformers ä½¿ç”¨ bitsandbytes åŠ è½½ 4 ä½é‡åŒ–æ¨¡å‹
# bnb_4bit_compute_dtype æŒ‡å®šè®¡ç®—æ—¶çš„æ•°æ®ç±»å‹ (é€šå¸¸ä¸ FP16 æˆ– BF16 é…åˆ)
# bnb_4bit_quant_type æŒ‡å®š 4 ä½é‡åŒ–ç±»å‹ï¼Œnf4 æ˜¯ bitsandbytes æå‡ºçš„ NormalFloat 4bit
# device_map='auto' è‡ªåŠ¨å°†æ¨¡å‹åŠ è½½åˆ°å¯ç”¨çš„è®¾å¤‡ (GPU)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16, # å¦‚æœ GPU æ”¯æŒ BF16ï¼Œä¼˜å…ˆä½¿ç”¨ï¼›å¦åˆ™ç”¨ torch.float16
    bnb_4bit_quant_type="nf4",
    device_map="auto"
)

# 3. å‡†å¤‡æ¨¡å‹è¿›è¡Œ k-bit (è¿™é‡Œæ˜¯ 4-bit) è®­ç»ƒ
# prepare_model_for_kbit_training å‡½æ•°ä¼šè¿›è¡Œä¸€äº›å¤„ç†ï¼Œä¾‹å¦‚å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ã€å¤„ç† LayerNorm ç­‰
model = prepare_model_for_kbit_training(model)

# --- 4. é…ç½® LoRA ---
lora_config = LoraConfig(
    r=lora_r,
    lora_alpha=lora_alpha,
    lora_dropout=lora_dropout,
    bias="none", # é€šå¸¸å¯¹ bias ä¸ä½¿ç”¨ LoRA
    task_type="CAUSAL_LM", # ä»»åŠ¡ç±»å‹æ˜¯å› æœè¯­è¨€æ¨¡å‹
    target_modules=target_modules # æŒ‡å®šå°† LoRA æ³¨å…¥åˆ°å“ªäº›å±‚
)

# --- 5. å°† LoRA é€‚é…å™¨æ³¨å…¥åˆ°æ¨¡å‹ä¸­ ---
# get_peft_model ä¼šç”¨ LoRA é€‚é…å™¨åŒ…è£…åŸºç¡€æ¨¡å‹ï¼Œå¹¶æ ‡è®° LoRA å‚æ•°ä¸ºå¯è®­ç»ƒ
model = get_peft_model(model, lora_config)

# æ‰“å°æ¨¡å‹çš„å¯è®­ç»ƒå‚æ•°é‡ï¼Œä½ ä¼šå‘ç°ç›¸å¯¹äºæ€»å‚æ•°é‡éå¸¸å°‘
model.print_trainable_parameters()

# --- 6. å‡†å¤‡æ•°æ®é›† ---
dataset = load_dataset(dataset_name, split="train")

# æ•°æ®é¢„å¤„ç†å‡½æ•°
def preprocess_function(examples):
    # å°†æ–‡æœ¬å’Œç»“æŸç¬¦æ‹¼æ¥ï¼Œä½œä¸ºè¯­è¨€æ¨¡å‹çš„è¾“å…¥
    # è¿™é‡Œç®€å•æ‹¼æ¥æ‰€æœ‰ quotesï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›´ç²¾ç»†çš„æ ·æœ¬å¤„ç†
    text = [q + tokenizer.eos_token for q in examples["quote"]]
    # å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯å’Œç¼–ç 
    tokenized_examples = tokenizer(
        text,
        max_length=256, # è®¾ç½®æœ€å¤§åºåˆ—é•¿åº¦
        padding="max_length",
        truncation=True,
        return_attention_mask=False # å¯¹äº causal LM é€šå¸¸ä¸éœ€è¦ attention mask
    )
    # è¯­è¨€æ¨¡å‹çš„æ ‡ç­¾æ˜¯è¾“å…¥çš„ä¸‹ä¸€ä¸ª tokenï¼Œæ‰€ä»¥ç›´æ¥å¤åˆ¶ input_ids
    tokenized_examples["labels"] = tokenized_examples["input_ids"].copy()
    return tokenized_examples

# åº”ç”¨é¢„å¤„ç†
dataset = dataset.map(preprocess_function, batched=True, remove_columns=["quote", "author"])

# --- 7. è®¾ç½®è®­ç»ƒå‚æ•° ---
training_args = TrainingArguments(
    output_dir=output_dir,
    per_device_train_batch_size=4, # æ ¹æ®ä½ çš„æ˜¾å­˜è°ƒæ•´ batch size
    gradient_accumulation_steps=4, # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼Œæ¨¡æ‹Ÿæ›´å¤§çš„ batch size (4 * 4 = 16)
    learning_rate=2e-4,
    num_train_epochs=1, # è®­ç»ƒ epoch æ•°
    logging_steps=10, # æ¯å¤šå°‘æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—
    save_steps=100, # æ¯å¤šå°‘æ­¥ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹ (LoRA é€‚é…å™¨)
    fp16=False,      # å¦‚æœä½ çš„ GPU ä¸æ”¯æŒ BF16ï¼Œå¹¶ä¸” bnb_4bit_compute_dtype è®¾ç½®ä¸º FP16ï¼Œåˆ™è¿™é‡Œè®¾ä¸º True
    bf16=True,       # å¦‚æœä½ çš„ GPU æ”¯æŒ BF16 (å¦‚ Ampere æˆ–æ›´æ–°æ¶æ„)ï¼Œå¹¶ä¸” bnb_4bit_compute_dtype è®¾ç½®ä¸º BF16ï¼Œåˆ™è¿™é‡Œè®¾ä¸º True
    gradient_checkpointing=True, # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œè¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜ï¼ˆä¼šå¢åŠ è®¡ç®—æ—¶é—´ï¼‰
    # optim="paged_adamw_8bit", # QLoRA è®ºæ–‡ä¸­ä½¿ç”¨äº†åˆ†é¡µä¼˜åŒ–å™¨ï¼Œè¿™é‡Œå¯ä»¥é€‰æ‹©
    report_to="none" # ä¸å‘ä»»ä½•åœ°æ–¹æŠ¥å‘Šæ—¥å¿—
)

# --- 8. åˆ›å»º Trainer å¹¶å¼€å§‹è®­ç»ƒ ---
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    tokenizer=tokenizer, # Trainer ä¹Ÿéœ€è¦ tokenizer
    # data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False) # å¦‚æœéœ€è¦ç‰¹æ®Šçš„ collator
)

print("å¼€å§‹è®­ç»ƒ...")
trainer.train()
print("è®­ç»ƒå®Œæˆ.")

# --- 9. ä¿å­˜ LoRA é€‚é…å™¨ ---
# è®­ç»ƒå®Œæˆåï¼Œä¿å­˜çš„åªæœ‰ LoRA é€‚é…å™¨çš„æƒé‡ï¼Œè€Œä¸æ˜¯æ•´ä¸ªæ¨¡å‹
trainer.model.save_pretrained(output_dir)
print(f"LoRA é€‚é…å™¨å·²ä¿å­˜åˆ° {output_dir}")

# --- æ¨ç†ç¤ºä¾‹ (åŠ è½½åŸºç¡€æ¨¡å‹å’Œ LoRA é€‚é…å™¨) ---
print("\nåŠ è½½ LoRA é€‚é…å™¨è¿›è¡Œæ¨ç†...")
# é¦–å…ˆåŠ è½½åŸå§‹çš„ 4 ä½é‡åŒ–åŸºç¡€æ¨¡å‹
base_model = AutoModelForCausalLM.from_pretrained(
    model_name,
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_quant_type="nf4",
    device_map="auto"
)

# ç„¶ååŠ è½½ä¿å­˜çš„ LoRA é€‚é…å™¨åˆ°åŸºç¡€æ¨¡å‹ä¸Š
from peft import PeftModel
model_for_inference = PeftModel.from_pretrained(base_model, output_dir)

# å°†æ¨¡å‹åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
model_for_inference.eval()

# è¿›è¡Œæ¨ç†
prompt = "The meaning of life is"
inputs = tokenizer(prompt, return_tensors="pt").to(model_for_inference.device)

with torch.no_grad():
    outputs = model_for_inference.generate(**inputs, max_new_tokens=50, num_return_sequences=1)

print("\nåŠ è½½é€‚é…å™¨åçš„æ¨¡å‹æ¨ç†ç»“æœ:")
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```



## ViT

https://www.bilibili.com/video/BV15P4y137jb?spm_id_from=333.788.videopod.sections&vd_source=edb614e9f3e817577f46a2e9deeca011

```
å›¾ç‰‡å¤§å°ï¼š224*224*3   w*h*c

å›¾ç‰‡åˆ‡å‰²æˆè®¸å¤šä¸ªpatch 16*16ï¼›æ¯ä¸ªPatchçœ‹ä½œæ˜¯ä¸€ä¸ªtokenï¼›ç»è¿‡çº¿æ€§æŠ•å½±æˆtoken id å³embedingå±‚

N:(224*224)/(16*16)=196ä¸ªpatch
D:16*16*3=768 æ¯ä¸ªpatchçš„å¤§å°
è¾“å…¥æ•°æ®ï¼š196*768
æŠ•å½±çŸ©é˜µEï¼š768*768
æŠ•å½±åï¼š196*768
æ·»åŠ å¼€å§‹æ ‡å¿—[class]ï¼Œåˆ™æœ€åçš„è¾“å…¥ï¼š197*768
```

![image-20250319160756977](../my_minimind/images/image-20250319160756977.png)

## clip **Contrastive Languageâ€“Image Pretraining**ï¼ˆå¯¹æ¯”è¯­è¨€-å›¾åƒé¢„è®­ç»ƒï¼‰

```
zero shot----Â·Â·Â·+-

1 å¯¹æ¯”é¢„è®­ç»ƒ
å›¾ç‰‡I_iå¯¹åº”æ–‡å­—T_i


2 ä»labelåˆ›å»ºæ•°æ®é›†åˆ†ç±»å™¨
labelsä»£è¡¨æ­£æ ·æœ¬ï¼Œå› ä¸ºå¯¹è§’çº¿éƒ½æ˜¯æ­£æ ·æœ¬


3 zero-shot é¢„æµ‹
```

![image-20250319161854468](../my_minimind/images/image-20250319161854468.png)

## æ··åˆç²¾åº¦scaler

### ä¸»è¦é˜¶æ®µ

æ··åˆç²¾åº¦è®­ç»ƒï¼ˆé€šå¸¸æŒ‡ç»“åˆä½¿ç”¨ FP32 å’Œ FP16ï¼‰çš„æ ¸å¿ƒæ€æƒ³æ˜¯åœ¨è®¡ç®—è¿‡ç¨‹ä¸­æ™ºèƒ½åœ°åˆ‡æ¢æ•°æ®ç±»å‹ï¼Œä»¥åˆ©ç”¨ FP16 çš„é«˜é€Ÿå’Œä½æ˜¾å­˜ä¼˜åŠ¿ï¼ŒåŒæ—¶ä¿ç•™ FP32 çš„é«˜ç²¾åº¦å’Œæ•°å€¼ç¨³å®šæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å¯¹æ•°å€¼èŒƒå›´æ•æ„Ÿçš„ç¯èŠ‚ã€‚

è¿™é‡Œä»¥å‰å‘ä¼ æ’­ã€æŸå¤±è®¡ç®—ã€åå‘ä¼ æ’­å’Œæƒé‡æ›´æ–°è¿™å‡ ä¸ªä¸»è¦é˜¶æ®µæ¥æè¿°ç²¾åº¦çš„å˜åŒ–ï¼š

**1. å‰å‘ä¼ æ’­ (Forward Pass)**

- **è¾“å…¥æ•°æ®**: é€šå¸¸ï¼Œè¾“å…¥æ•°æ®æœ€åˆæ˜¯ä»¥ FP32 ç²¾åº¦åŠ è½½çš„ã€‚
- **æ¨¡å‹å±‚å†…éƒ¨è®¡ç®—**: åœ¨ä½¿ç”¨æ”¯æŒæ··åˆç²¾åº¦çš„æ¡†æ¶ï¼ˆå¦‚ PyTorch çš„ `autocast`ï¼‰æ—¶ï¼Œå‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­å¤§éƒ¨åˆ†è®¡ç®—ï¼ˆå¦‚çŸ©é˜µä¹˜æ³•ã€å·ç§¯ç­‰ï¼‰ä¼šåœ¨ **FP16** ç²¾åº¦ä¸‹æ‰§è¡Œã€‚

- **éƒ¨åˆ†ä¿æŒ FP32 çš„è®¡ç®—**: å¹¶ä¸æ˜¯æ‰€æœ‰çš„æ“ä½œéƒ½é€‚åˆç”¨ FP16 è¿›è¡Œã€‚ä¸€äº›å¯¹æ•°å€¼èŒƒå›´æˆ–ç²¾åº¦è¦æ±‚è¾ƒé«˜çš„æ“ä½œï¼ˆä¾‹å¦‚ Softmaxã€Layer Normalizationã€å½’çº¦æ“ä½œ Reduce Sum/Mean ç­‰ï¼‰å¯èƒ½ä¼šè¢«æ¡†æ¶è‡ªåŠ¨ä¿æŒåœ¨ **FP32** ç²¾åº¦è¿›è¡Œè®¡ç®—ï¼Œå³ä½¿å®ƒä»¬ä½äº `autocast` åŒºåŸŸå†…ã€‚è¿™æ˜¯ä¸ºäº†ç¡®ä¿æ•°å€¼ç¨³å®šæ€§ï¼Œé˜²æ­¢æº¢å‡ºæˆ–ç²¾åº¦æŸå¤±è¿‡å¤§ã€‚
- **ä¸­é—´ç»“æœ**: åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¸­é—´å¼ é‡ä¼šæ ¹æ®æ‰§è¡Œçš„æ“ä½œç±»å‹ï¼Œä»¥ FP16 æˆ– FP32 çš„ç²¾åº¦å­˜å‚¨ã€‚
- **æ¨¡å‹è¾“å‡º**: æ¨¡å‹æœ€ç»ˆçš„è¾“å‡ºé€šå¸¸ä¼šè¢«è½¬æ¢å› **FP32** ç²¾åº¦ï¼Œä»¥ä¾¿è¿›è¡Œåç»­çš„æŸå¤±è®¡ç®—ï¼Œå› ä¸ºæŸå¤±å‡½æ•°å¯¹è¾“å…¥ç²¾åº¦é€šå¸¸æ¯”è¾ƒæ•æ„Ÿã€‚

**æ€»ç»“å‰å‘ä¼ æ’­ï¼š** è¾“å…¥ FP32 -> å¤§éƒ¨åˆ†æ ¸å¿ƒè®¡ç®—åœ¨ FP16 (æœ‰è‡ªåŠ¨ç±»å‹è½¬æ¢) -> éƒ¨åˆ†ç¨³å®šæ•æ„Ÿæ“ä½œåœ¨ FP32 -> ä¸­é—´ç»“æœ FP16/FP32 æ··æ‚ -> æ¨¡å‹è¾“å‡º FP32ã€‚

**2. æŸå¤±è®¡ç®— (Loss Calculation)**

- æŸå¤±å‡½æ•°é€šå¸¸æ¥æ”¶ FP32 æ ¼å¼çš„æ¨¡å‹è¾“å‡ºå’Œæ ‡ç­¾ã€‚
- æŸå¤±å€¼æœ¬èº«é€šå¸¸åœ¨ **FP32** ç²¾åº¦ä¸‹è®¡ç®—å’Œå­˜å‚¨ã€‚è¿™æ˜¯ä¸ºäº†ä¿æŒæŸå¤±å€¼çš„ç²¾åº¦ï¼Œå°¤å…¶æ˜¯å½“æŸå¤±å€¼å¾ˆå°æ—¶ï¼ŒFP32 èƒ½æä¾›æ›´å¤§çš„åŠ¨æ€èŒƒå›´ï¼Œé¿å…ä¸‹æº¢ã€‚

**æ€»ç»“æŸå¤±è®¡ç®—ï¼š** ä½¿ç”¨ FP32 æ¨¡å‹è¾“å‡ºå’Œ FP32 æ ‡ç­¾ -> è®¡ç®—å¾—åˆ° FP32 çš„æŸå¤±å€¼ã€‚

**3. åå‘ä¼ æ’­ (Backward Pass)**

- **æ¢¯åº¦ç¼©æ”¾ (Gradient Scaling)**: åœ¨åå‘ä¼ æ’­å¼€å§‹ä¹‹å‰ï¼Œæ··åˆç²¾åº¦è®­ç»ƒä¼šå¼•å…¥æ¢¯åº¦ç¼©æ”¾ã€‚FP32 çš„æŸå¤±å€¼ä¼šä¹˜ä»¥ä¸€ä¸ªè¾ƒå¤§çš„**æ ‡é‡ç¼©æ”¾å› å­**ï¼ˆé€šå¸¸ç”¨ `GradScaler` ç®¡ç†ï¼‰ã€‚
- **è®¡ç®—ç¼©æ”¾åçš„æ¢¯åº¦**: åå‘ä¼ æ’­ä»è¿™ä¸ª**ç¼©æ”¾åçš„æŸå¤±**å¼€å§‹è®¡ç®—æ¢¯åº¦ã€‚æ ¹æ®é“¾å¼æ³•åˆ™ï¼Œè®¡ç®—å¾—åˆ°çš„æ¯ä¸ªæ¢¯åº¦éƒ½ä¼šè¢«è¿™ä¸ªç¼©æ”¾å› å­æ”¾å¤§ã€‚
- **æ¢¯åº¦è®¡ç®—ç²¾åº¦**: å¤§éƒ¨åˆ†æ¢¯åº¦çš„è®¡ç®—ä¼šæ²¿ç”¨å‰å‘ä¼ æ’­æ—¶çš„ç²¾åº¦ï¼Œå³åœ¨ **FP16** ç²¾åº¦ä¸‹è¿›è¡Œè®¡ç®—ï¼Œå› ä¸ºæ¢¯åº¦ä¹Ÿè¢«æ”¾å¤§äº†ï¼Œä¸å®¹æ˜“å‘ç”Ÿä¸‹æº¢ã€‚
- **æ¢¯åº¦ç´¯ç§¯ (å¦‚æœä½¿ç”¨)**: å¦‚æœä½¿ç”¨äº†æ¢¯åº¦ç´¯ç§¯ï¼Œç´¯ç§¯çš„æ¢¯åº¦é€šå¸¸ä¼šåœ¨ **FP32** ç²¾åº¦ä¸‹è¿›è¡Œç´¯åŠ ï¼Œä»¥ä¿è¯ç´¯åŠ è¿‡ç¨‹çš„ç²¾åº¦ã€‚
- **åç¼©æ”¾ (Unscaling)**: åœ¨å°†æ¢¯åº¦ç”¨äºæ›´æ–°æ¨¡å‹æƒé‡ä¹‹å‰ï¼Œç´¯ç§¯çš„ã€**ç¼©æ”¾åçš„æ¢¯åº¦**éœ€è¦è¢«é™¤ä»¥ç›¸åŒçš„ç¼©æ”¾å› å­ï¼Œä»¥æ¢å¤å…¶åŸå§‹çš„æ•°å€¼èŒƒå›´ã€‚è¿™ä¸€æ­¥é€šå¸¸åœ¨ **FP32** ç²¾åº¦ä¸‹è¿›è¡Œï¼Œå¾—åˆ°**æœªç¼©æ”¾çš„æ¢¯åº¦**ã€‚

**æ€»ç»“åå‘ä¼ æ’­ï¼š** FP32 æŸå¤± -> FP32 æŸå¤±ä¹˜ä»¥ç¼©æ”¾å› å­ -> åå‘è®¡ç®—å¾—åˆ°**ç¼©æ”¾å**çš„æ¢¯åº¦ï¼ˆä¸»è¦åœ¨ FP16 è®¡ç®—ï¼‰-> ç´¯ç§¯æ¢¯åº¦ï¼ˆé€šå¸¸åœ¨ FP32ï¼‰-> **åç¼©æ”¾**å¾—åˆ°**æœªç¼©æ”¾çš„æ¢¯åº¦**ï¼ˆåœ¨ FP32ï¼‰

**4. æƒé‡æ›´æ–° (Weight Update)**

- ä¸ºäº†ä¿æŒæ¨¡å‹çš„é•¿æœŸç¨³å®šæ€§å’Œç²¾åº¦ï¼Œæ¨¡å‹çš„ä¸»æƒé‡é€šå¸¸ä¼šä»¥ **FP32** ç²¾åº¦å­˜å‚¨å’Œç»´æŠ¤ã€‚
- ä¼˜åŒ–å™¨ä¼šä½¿ç”¨**æœªç¼©æ”¾çš„ FP32 æ¢¯åº¦**ï¼ˆå¯èƒ½ç»è¿‡æ¢¯åº¦è£å‰ªï¼‰æ¥æ›´æ–°è¿™äº› **FP32 ä¸»æƒé‡**ã€‚æƒé‡çš„æ›´æ–°è®¡ç®—ï¼ˆä¾‹å¦‚ SGD çš„ `weight = weight - learning_rate * gradient`ï¼‰ä¹Ÿåœ¨ FP32 ç²¾åº¦ä¸‹æ‰§è¡Œã€‚
- åœ¨æ›´æ–°å®Œ FP32 ä¸»æƒé‡åï¼Œé€šå¸¸ä¼šå°†è¿™äº›æ›´æ–°åçš„ FP32 æƒé‡å¤åˆ¶å¹¶è½¬æ¢ä¸º **FP16** æ ¼å¼ï¼Œç”¨äºä¸‹ä¸€è½®å‰å‘ä¼ æ’­æ—¶çš„å¿«é€Ÿè®¡ç®—ï¼ˆå³æ‰€è°“çš„ FP16 å·¥ä½œæƒé‡ï¼‰ã€‚

**æ€»ç»“æƒé‡æ›´æ–°ï¼š** ä½¿ç”¨ FP32 æ¢¯åº¦æ›´æ–° FP32 ä¸»æƒé‡ -> å°†æ›´æ–°åçš„ FP32 æƒé‡è½¬æ¢ä¸º FP16 å·¥ä½œæƒé‡ç”¨äºä¸‹ä¸€è½®å‰å‘ã€‚



**æ€»çš„æ¥è¯´ï¼Œæ··åˆç²¾åº¦è®­ç»ƒä¸­çš„ç²¾åº¦å˜åŒ–æ˜¯ä¸€ä¸ªåŠ¨æ€å’Œæ··åˆçš„è¿‡ç¨‹ï¼š**

- æ ¸å¿ƒè®¡ç®—ï¼ˆå‰å‘å’Œåå‘ä¼ æ’­ä¸­çš„å¤§éƒ¨åˆ†ï¼‰åˆ©ç”¨ **FP16** åŠ é€Ÿã€‚
- æ•°å€¼æ•æ„Ÿçš„æ“ä½œå’ŒæŸå¤±è®¡ç®—ä¿æŒ **FP32** ç¨³å®šæ€§ã€‚
- é€šè¿‡**æ¢¯åº¦ç¼©æ”¾**ï¼Œæ”¾å¤§ FP16 çš„æ¢¯åº¦ï¼Œé˜²æ­¢ä¸‹æº¢ã€‚
- **FP32 ä¸»æƒé‡**ç”¨äºä¿æŒæ¨¡å‹çš„ç²¾ç¡®çŠ¶æ€ï¼Œå¹¶åœ¨æ›´æ–°æ—¶ä½¿ç”¨ **FP32 æ¢¯åº¦**ã€‚
- **FP16 å·¥ä½œæƒé‡**ç”¨äºå‰å‘ä¼ æ’­æ—¶çš„ FP16 è®¡ç®—ã€‚

### å›¾è§£

![image-20250319192044309](../my_minimind/images/image-20250319192044309.png)

lossè®¡ç®—æ—¶ï¼Œæ¢¯åº¦ä¸€èˆ¬å¾ˆå°ï¼Œè¶…è¿‡FP16çš„èŒƒå›´ï¼Œå› æ­¤é‡‡ç”¨scaleç¼©æ”¾

![image-20250319192106215](../my_minimind/images/image-20250319192106215.png)

scaler.update()æ›´æ–°scaleæ¯”ä¾‹

![image-20250319191755309](../my_minimind/images/image-20250319191755309.png)

### åŸç†å’Œä»£ç 

```
ä¸ºä»€ä¹ˆéœ€è¦æ¢¯åº¦ç¼©æ”¾å’Œè¿™ä¸ªâ€œscalarâ€ï¼Ÿ

ä½¿ç”¨ FP16 è¿›è¡Œè®¡ç®—å¯ä»¥å¸¦æ¥æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä½† FP16 çš„æ•°å€¼è¡¨ç¤ºèŒƒå›´æ¯” FP32 å°ã€‚åœ¨æ·±åº¦å­¦ä¹ è®­ç»ƒçš„åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œè®¡ç®—å¾—åˆ°çš„æ¢¯åº¦å€¼å¯èƒ½ä¼šéå¸¸å°ã€‚å¦‚æœç›´æ¥ä½¿ç”¨ FP16 æ¥å­˜å‚¨å’Œå¤„ç†è¿™äº›å°æ¢¯åº¦çš„å€¼ï¼Œå®ƒä»¬å¯èƒ½ä¼šå› ä¸ºæ•°å€¼å¤ªå°è€Œå˜æˆé›¶ï¼ˆå³å‘ç”Ÿ ä¸‹æº¢ (underflow)ï¼‰ï¼Œå¯¼è‡´æ¨¡å‹æ— æ³•æ­£ç¡®åœ°æ›´æ–°æƒé‡ï¼Œä»è€Œå½±å“æ¨¡å‹çš„æ”¶æ•›å’Œæœ€ç»ˆçš„ç²¾åº¦ã€‚

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ¢¯åº¦ç¼©æ”¾è¢«å¼•å…¥ã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯åœ¨åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦ä¹‹å‰ï¼Œå…ˆå°†æŸå¤± (loss) ä¹˜ä»¥ä¸€ä¸ªè¾ƒå¤§çš„ç¼©æ”¾å› å­ï¼ˆä¸€ä¸ªæ ‡é‡ï¼‰ã€‚æ ¹æ®é“¾å¼æ³•åˆ™ï¼Œä¹˜ä»¥æŸå¤±çš„ç¼©æ”¾å› å­ä¼šè‡ªåŠ¨å°†æ‰€æœ‰çš„æ¢¯åº¦ä¹ŸæŒ‰ç›¸åŒçš„æ¯”ä¾‹æ”¾å¤§ã€‚è¿™æ ·ï¼ŒåŸæ¥éå¸¸å°çš„æ¢¯åº¦å€¼åœ¨æ”¾å¤§åå°±è½åœ¨äº† FP16 å¯ä»¥æœ‰æ•ˆè¡¨ç¤ºçš„èŒƒå›´å†…ï¼Œé¿å…äº†ä¸‹æº¢ã€‚

åœ¨ä¼˜åŒ–å™¨æ›´æ–°æ¨¡å‹æƒé‡æ—¶ï¼Œå†å°†è¿™äº›æ”¾å¤§åçš„æ¢¯åº¦é™¤ä»¥ç›¸åŒçš„ç¼©æ”¾å› å­ï¼Œæ¢å¤å…¶åŸå§‹å¤§å°ï¼Œç”¨äºæ›´æ–° FP32 ç²¾åº¦çš„æ¨¡å‹æƒé‡å‰¯æœ¬ï¼ˆä¸ºäº†ä¿æŒæƒé‡çš„ç²¾ç¡®æ€§ï¼Œé€šå¸¸ä¼šç»´æŠ¤ä¸€ä»½ FP32 çš„ä¸»æƒé‡ï¼‰ã€‚

æ‰€ä»¥ï¼Œâ€œæ··åˆç²¾åº¦ scalarâ€å®é™…ä¸Šæ˜¯æŒ‡ç”¨äºæ¢¯åº¦ç¼©æ”¾çš„é‚£ä¸ªæ ‡é‡ç¼©æ”¾å› å­ã€‚
```

ç°ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶æä¾›äº†è‡ªåŠ¨æ··åˆç²¾åº¦ (Automatic Mixed Precision, AMP) çš„åŠŸèƒ½ï¼Œæå¤§åœ°ç®€åŒ–äº†åœ¨ä»£ç ä¸­ä½¿ç”¨æ··åˆç²¾åº¦å’Œæ¢¯åº¦ç¼©æ”¾çš„è¿‡ç¨‹ã€‚åœ¨ PyTorch ä¸­ï¼Œä¸»è¦ä½¿ç”¨ `torch.cuda.amp.autocast` å’Œ `torch.cuda.amp.GradScaler`

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.cuda.amp import autocast, GradScaler

# 1. å®šä¹‰æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
model = nn.Linear(10, 1).cuda() # å°†æ¨¡å‹æ”¾åˆ°æ”¯æŒFP16è®¡ç®—çš„è®¾å¤‡ä¸Šï¼Œå¦‚GPU
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

# 2. åˆ›å»º GradScaler å®ä¾‹
# GradScaler è´Ÿè´£ç®¡ç†ç¼©æ”¾å› å­ï¼Œå¹¶åœ¨åå‘ä¼ æ’­å’Œä¼˜åŒ–å™¨æ­¥éª¤ä¸­åº”ç”¨ç¼©æ”¾å’Œåç¼©æ”¾
scaler = GradScaler()

# å‡è®¾æœ‰ä¸€äº›è¾“å…¥æ•°æ®å’Œæ ‡ç­¾
input_data = torch.randn(64, 10).cuda()
labels = torch.randn(64, 1).cuda()

# è®­ç»ƒå¾ªç¯
for epoch in range(num_epochs):
    optimizer.zero_grad()

    # 3. åœ¨éœ€è¦ä½¿ç”¨æ··åˆç²¾åº¦çš„å‰å‘ä¼ æ’­éƒ¨åˆ†ä½¿ç”¨ autocast ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    # åœ¨ autocast åŒºåŸŸå†…ï¼ŒPyTorchä¼šè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ç²¾åº¦ï¼ˆFP16æˆ–FP32ï¼‰è¿›è¡Œè®¡ç®—
    with autocast():
        outputs = model(input_data)
        loss = criterion(outputs, labels)

    # 4. ä½¿ç”¨ scaler.scale() æ¥ç¼©æ”¾æŸå¤±
    # è¿™ä¸€æ­¥ä¼šå°†æŸå¤±å€¼ä¹˜ä»¥å½“å‰çš„ç¼©æ”¾å› å­
    scaler.scale(loss).backward()

    # 5. ä½¿ç”¨ scaler.step() æ¥æ›´æ–°ä¼˜åŒ–å™¨å‚æ•°
    # åœ¨è°ƒç”¨ optimizer.step() ä¹‹å‰ï¼Œscaler ä¼šå…ˆæ£€æŸ¥æ¢¯åº¦æ˜¯å¦åŒ…å« inf æˆ– NaNï¼ˆæº¢å‡ºæˆ–æ— æ•ˆå€¼ï¼‰
    # å¦‚æœæ²¡æœ‰ï¼Œscaler ä¼šå°†ç¼©æ”¾åçš„æ¢¯åº¦åç¼©æ”¾å›åŸå§‹å¤§å°ï¼Œç„¶åè°ƒç”¨ optimizer.step() è¿›è¡Œå‚æ•°æ›´æ–°
    # å¦‚æœæœ‰ inf æˆ– NaNï¼Œscaler ä¼šè·³è¿‡å½“å‰çš„ optimizer.step()ï¼Œå¹¶è°ƒæ•´ç¼©æ”¾å› å­ä»¥å°è¯•é¿å…æœªæ¥çš„æº¢å‡º
    scaler.step(optimizer)

    # 6. ä½¿ç”¨ scaler.update() æ¥æ›´æ–°ç¼©æ”¾å› å­
    # scaler ä¼šæ ¹æ®ä¹‹å‰çš„æ¢¯åº¦æ£€æŸ¥ç»“æœæ¥åŠ¨æ€è°ƒæ•´ç¼©æ”¾å› å­ï¼Œä»¥ä¾¿åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­ä½¿ç”¨
    scaler.update()

    print(f'Epoch {epoch+1}, Loss: {loss.item()}')
```

### minimindçš„scalar

```python
with ctx:  # ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    res = model(X)  # å‰å‘ä¼ æ’­
    loss = loss_fct(
        res.logits.view(-1, res.logits.size(-1)),
        Y.view(-1)
    ).view(Y.size())
    loss = (loss * loss_mask).sum() / loss_mask.sum()  # è®¡ç®—æ©ç æŸå¤±
    loss += res.aux_loss  # æ·»åŠ è¾…åŠ©æŸå¤±ï¼ˆå¦‚æœæœ‰ï¼‰
    loss = loss / args.accumulation_steps  # æ¢¯åº¦ç´¯ç§¯

scaler.scale(loss).backward()  # åå‘ä¼ æ’­ï¼ˆå¸¦æ¢¯åº¦ç¼©æ”¾ï¼‰

# æ¢¯åº¦ç´¯ç§¯å®Œæˆåæ›´æ–°æ¨¡å‹å‚æ•°
if (step + 1) % args.accumulation_steps == 0:
    scaler.unscale_(optimizer) # åç¼©æ”¾
    torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)  # æ¢¯åº¦è£å‰ªé€šå¸¸åº”è¯¥åº”ç”¨äºæœªç¼©æ”¾çš„æ¢¯åº¦
    scaler.step(optimizer)  # æ›´æ–°å‚æ•°ï¼›ç”±äºå‰é¢å¯¹æ¢¯åº¦è¿›è¡Œäº†æ“ä½œï¼Œæ‰€ä»¥ä¸å†å¯¹æ¢¯åº¦åç¼©æ”¾
    scaler.update()  # æ›´æ–°æ¢¯åº¦ç¼©æ”¾å™¨
    optimizer.zero_grad(set_to_none=True)  # æ¸…ç©ºæ¢¯åº¦

    
# å½“ä½ éœ€è¦åœ¨è°ƒç”¨ scaler.step(optimizer) ä¹‹å‰å¯¹æ¢¯åº¦è¿›è¡Œæ“ä½œï¼ˆä¾‹å¦‚æ¢¯åº¦è£å‰ªã€æ‰‹åŠ¨ä¿®æ”¹æ¢¯åº¦ç­‰ï¼‰ï¼Œå¹¶ä¸”è¿™äº›æ“ä½œè¦æ±‚æ¢¯åº¦æ˜¯æœªç¼©æ”¾çš„ï¼Œä½ å°±éœ€è¦æ˜¾å¼åœ°è°ƒç”¨ scaler.unscale_(optimizer) æ¥æå‰å®Œæˆåç¼©æ”¾ã€‚
# å½“ä½ è®¡ç®—å®Œç¼©æ”¾åçš„æ¢¯åº¦åï¼Œæ²¡æœ‰ä»»ä½•éœ€è¦æœªç¼©æ”¾æ¢¯åº¦çš„ä¸­é—´æ“ä½œï¼Œç›´æ¥è¿›è¡Œä¼˜åŒ–å™¨æ­¥è¿›ï¼Œé‚£ä¹ˆ scaler.step(optimizer) ä¼šè´Ÿè´£åœ¨å†…éƒ¨å®Œæˆåç¼©æ”¾å’Œæ›´æ–°å‚æ•°çš„æ•´ä¸ªæµç¨‹ã€‚
```

è¿™æ®µä»£ç ç‰‡æ®µå±•ç¤ºäº†åœ¨æ·±åº¦å­¦ä¹ è®­ç»ƒä¸­åŒæ—¶ä½¿ç”¨äº†**æ··åˆç²¾åº¦è®­ç»ƒ (Mixed Precision Training)**ã€**æ¢¯åº¦ç¼©æ”¾ (Gradient Scaling)**ã€**æ¢¯åº¦ç´¯ç§¯ (Gradient Accumulation)** å’Œ**æ¢¯åº¦è£å‰ª (Gradient Clipping)**ã€‚

åœ¨ `accumulation_steps` æ­¥åæ‰æ›´æ–°å‚æ•°çš„åŸå› ä¸»è¦åœ¨äº**æ¢¯åº¦ç´¯ç§¯**ã€‚

è¿™é‡Œè§£é‡Šä¸€ä¸‹å„ä¸ªéƒ¨åˆ†çš„ååŒå·¥ä½œï¼š

1. **æ¢¯åº¦ç´¯ç§¯ (`accumulation_steps`)**:

   - æ¢¯åº¦ç´¯ç§¯æ˜¯ä¸€ç§åœ¨ä¸å¢åŠ ç¡¬ä»¶æ˜¾å­˜å ç”¨çš„æƒ…å†µä¸‹ï¼Œæ¨¡æ‹Ÿæ›´å¤§ batch size è®­ç»ƒçš„æŠ€æœ¯ã€‚
   - å®ƒé€šè¿‡åœ¨å¤šä¸ªå°çš„ forward/backward æ­¥éª¤ä¸­ç´¯ç§¯æ¢¯åº¦ï¼Œè€Œä¸æ˜¯åœ¨æ¯ä¸€æ­¥éƒ½æ›´æ–°æ¨¡å‹æƒé‡ã€‚
   - ç´¯ç§¯ `accumulation_steps` æ­¥çš„æ¢¯åº¦ï¼Œç›¸å½“äºä½¿ç”¨äº† `batch_size * accumulation_steps` çš„æœ‰æ•ˆ batch sizeã€‚

2. **æ··åˆç²¾åº¦ä¸æ¢¯åº¦ç¼©æ”¾ (`scaler.scale(loss).backward()`, `GradScaler`)**:

   - å¦‚å‰æ‰€è¿°ï¼Œæ··åˆç²¾åº¦è®­ç»ƒä½¿ç”¨ FP16 è®¡ç®—åŠ é€Ÿï¼Œä½†å¯èƒ½å¯¼è‡´å°æ¢¯åº¦ä¸‹æº¢ã€‚
   - `GradScaler` å’Œ `scaler.scale(loss)` æ˜¯ä¸ºäº†è§£å†³ FP16 ä¸‹æº¢é—®é¢˜è€Œå¼•å…¥çš„æ¢¯åº¦ç¼©æ”¾æœºåˆ¶ã€‚å®ƒå°†æŸå¤±æ”¾å¤§ï¼Œä»è€Œæ”¾å¤§æ¢¯åº¦ï¼Œä½¿å…¶åœ¨ FP16 çš„èŒƒå›´å†…ã€‚
   - `scaler.scale(loss).backward()` è®¡ç®—çš„æ˜¯**ç¼©æ”¾åçš„æ¢¯åº¦**ã€‚è¿™äº›ç¼©æ”¾åçš„æ¢¯åº¦ä¼šåœ¨æ¯ä¸ªå°æ­¥éª¤ä¸­ç´¯ç§¯èµ·æ¥ã€‚

3. **å‚æ•°æ›´æ–° (`scaler.step(optimizer)`)**:

   - ä¼˜åŒ–å™¨çš„ `step()` æ–¹æ³•æ˜¯æ ¹æ®å½“å‰ç´¯ç§¯çš„æ¢¯åº¦æ¥æ›´æ–°æ¨¡å‹æƒé‡çš„å…³é”®æ­¥éª¤ã€‚

   - åœ¨ä½¿ç”¨ `GradScaler` æ—¶ï¼Œéœ€è¦è°ƒç”¨ `scaler.step(optimizer)` æ¥ä»£æ›¿æ ‡å‡†çš„ `optimizer.step()`ã€‚

   - ```
     scaler.step(optimizer)
     ```

      åœ¨å†…éƒ¨ä¼šæ‰§è¡Œå‡ ä¸ªé‡è¦æ“ä½œï¼š

     - **åç¼©æ”¾ (Unscaling)**: åœ¨æ›´æ–°æƒé‡ä¹‹å‰ï¼Œ`scaler` ä¼šæ£€æŸ¥ç´¯ç§¯çš„æ¢¯åº¦æ˜¯å¦æœ‰ `inf` æˆ– `NaN` å€¼ã€‚å¦‚æœæ²¡æœ‰ï¼Œå®ƒä¼šå°†ç´¯ç§¯çš„**ç¼©æ”¾åçš„æ¢¯åº¦**é™¤ä»¥å½“å‰çš„ç¼©æ”¾å› å­ï¼Œå¾—åˆ°**åŸå§‹å°ºåº¦çš„æ¢¯åº¦**ã€‚
     - **åº”ç”¨æ¢¯åº¦**: ä½¿ç”¨åç¼©æ”¾åçš„æ¢¯åº¦æ¥æ›´æ–°æ¨¡å‹çš„ FP32 ä¸»æƒé‡ã€‚
     - **å¤„ç†æº¢å‡º**: å¦‚æœæ£€æµ‹åˆ° `inf` æˆ– `NaN`ï¼Œè¯´æ˜å½“å‰çš„ç¼©æ”¾å› å­å¯èƒ½å¤ªé«˜å¯¼è‡´æº¢å‡ºï¼Œ`scaler.step` ä¼šè·³è¿‡è¿™æ¬¡æƒé‡æ›´æ–°ï¼Œå¹¶é€šçŸ¥ `scaler.update()` è°ƒæ•´ç¼©æ”¾å› å­ã€‚

4. **æ›´æ–°æ¢¯åº¦ç¼©æ”¾å™¨ (`scaler.update()`)**:

   - `scaler.update()` ä¼šæ ¹æ®å‰ä¸€æ­¥ `scaler.step()` çš„ç»“æœæ¥è°ƒæ•´ç¼©æ”¾å› å­ã€‚å¦‚æœä¹‹å‰æ²¡æœ‰æº¢å‡ºï¼Œç¼©æ”¾å› å­å¯èƒ½ä¼šå¢å¤§ï¼›å¦‚æœå‘ç”Ÿäº†æº¢å‡ºï¼Œç¼©æ”¾å› å­ä¼šå‡å°ã€‚è¿™æ˜¯ä¸ºäº†åŠ¨æ€åœ°æ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„ç¼©æ”¾å› å­ã€‚

5. **æ¢¯åº¦è£å‰ª (`torch.nn.utils.clip_grad_norm_`)**:

   - æ¢¯åº¦è£å‰ªç”¨äºé™åˆ¶æ¢¯åº¦çš„æœ€å¤§èŒƒæ•°ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ã€‚
   - **é‡è¦çš„ä¸€ç‚¹æ˜¯ï¼Œæ¢¯åº¦è£å‰ªé€šå¸¸åº”è¯¥åº”ç”¨äºæœªç¼©æ”¾çš„æ¢¯åº¦ã€‚**

**ä¸ºä»€ä¹ˆåœ¨ `accumulation_steps` åæ›´æ–°å‚æ•°ï¼Ÿ**

ç»“åˆä»¥ä¸Šå‡ ç‚¹ï¼ŒåŸå› å°±å¾ˆæ¸…æ¥šäº†ï¼š

- **`scaler.step(optimizer)` éœ€è¦æ“ä½œçš„æ˜¯ç´¯ç§¯å®Œæˆçš„æ€»æ¢¯åº¦ã€‚** å®ƒè´Ÿè´£å¯¹ç´¯ç§¯äº†å¤šä¸ªå°æ‰¹é‡æ¢¯åº¦çš„ç»“æœè¿›è¡Œåç¼©æ”¾å’Œåº”ç”¨åˆ°æƒé‡ä¸Šã€‚å¦‚æœåœ¨æ¯ä¸ªå°æ­¥éª¤éƒ½è°ƒç”¨ `scaler.step`ï¼Œé‚£ä¹ˆæ¯æ¬¡éƒ½åªç”¨åˆ°äº†ä¸€ä¸ªå°æ‰¹é‡çš„æ¢¯åº¦ï¼Œè¿™è¿èƒŒäº†æ¢¯åº¦ç´¯ç§¯çš„åˆè¡·ï¼Œä¹Ÿæ— æ³•æ­£ç¡®åœ°è¿›è¡Œç¼©æ”¾å’Œåç¼©æ”¾ã€‚
- **`scaler.update()` çš„ç¼©æ”¾å› å­è°ƒæ•´æ˜¯åŸºäºç´¯ç§¯äº†ä¸€å®šæ­¥æ•°ï¼ˆå³ä¸€ä¸ªæœ‰æ•ˆ batch sizeï¼‰åçš„æ¢¯åº¦æƒ…å†µã€‚** åœ¨æ¯ä¸ªå°æ­¥éª¤åæ›´æ–°ç¼©æ”¾å› å­æ˜¯ä¸å‡†ç¡®çš„ã€‚
- **æ¢¯åº¦è£å‰ª (`clip_grad_norm_`) å¿…é¡»åœ¨ `scaler.unscale_(optimizer)` ä¹‹åè¿›è¡Œã€‚** å› ä¸ºæ¢¯åº¦è£å‰ªçš„é˜ˆå€¼æ˜¯é’ˆå¯¹æœªç¼©æ”¾çš„æ¢¯åº¦è®¾å®šçš„ã€‚åœ¨ç´¯ç§¯ `accumulation_steps` æ­¥åï¼Œæˆ‘ä»¬é¦–å…ˆé€šè¿‡ `scaler.unscale_(optimizer)` è·å–æœªç¼©æ”¾çš„ç´¯ç§¯æ¢¯åº¦ï¼Œç„¶åè¿›è¡Œè£å‰ªï¼Œæœ€åå†ç”± `scaler.step(optimizer)` åº”ç”¨è¿™äº›è£å‰ªåçš„ã€å·²ç»å¤„ç†äº†ç¼©æ”¾é—®é¢˜çš„æ¢¯åº¦ã€‚

**ä»£ç ä¸­çš„æµç¨‹æ€»ç»“ï¼š**

åœ¨ä»£ç ä¸­ï¼Œ`scaler.scale(loss).backward()` åœ¨æ¯ä¸ªå°æ­¥éƒ½ä¼šæ‰§è¡Œï¼Œè®¡ç®—å¹¶ç´¯åŠ ç¼©æ”¾åçš„æ¢¯åº¦ã€‚

æ¯å½“ç´¯ç§¯æ»¡ `args.accumulation_steps` æ­¥åï¼Œæ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„ä¼˜åŒ–æ­¥éª¤ï¼š

1. `scaler.unscale_(optimizer)`: å°†å½“å‰ç´¯ç§¯çš„ç¼©æ”¾åçš„æ¢¯åº¦åç¼©æ”¾å›åŸå§‹å¤§å°ã€‚**è¿™ä¸€æ­¥æ˜¯è¿›è¡Œæ¢¯åº¦è£å‰ªå‰å¿…é¡»çš„ã€‚**
2. `torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)`: å¯¹åç¼©æ”¾åçš„ç´¯ç§¯æ¢¯åº¦è¿›è¡Œè£å‰ªã€‚
3. `scaler.step(optimizer)`: ä½¿ç”¨è£å‰ªåçš„æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œå¹¶å†…éƒ¨å¤„ç† FP16 æº¢å‡ºæ£€æµ‹ã€‚
4. `scaler.update()`: æ ¹æ® `scaler.step` çš„ç»“æœè°ƒæ•´ç¼©æ”¾å› å­ã€‚
5. `optimizer.zero_grad(set_to_none=True)`: æ¸…ç©ºç´¯ç§¯çš„æ¢¯åº¦ï¼Œä¸ºä¸‹ä¸€è½®æ¢¯åº¦ç´¯ç§¯åšå‡†å¤‡ã€‚

å› æ­¤ï¼Œå°†å‚æ•°æ›´æ–°æ”¾åœ¨ `accumulation_steps` åæ˜¯ä¸ºäº†ç¡®ä¿ä¼˜åŒ–å™¨æ“ä½œçš„æ˜¯ç»è¿‡å®Œæ•´ç´¯ç§¯ã€æ­£ç¡®ç¼©æ”¾å’Œå¤„ç†åçš„æ¢¯åº¦ï¼Œä»è€Œå®ç°æ¨¡æ‹Ÿå¤§ batch size è®­ç»ƒã€åˆ©ç”¨æ··åˆç²¾åº¦åŠ é€Ÿå¹¶ä¿æŒè®­ç»ƒç¨³å®šã€‚

## æ˜¾å­˜å ç”¨ï¼ˆæ··åˆç²¾åº¦ï¼ŒFP16å’ŒFP32ï¼‰

### æ¨¡å‹å‚æ•°

### ä¼˜åŒ–å™¨

ä¸ºä»€ä¹ˆä¸ç”¨fp16ï¼Œå› ä¸ºå­˜åœ¨å¤§é‡çš„å°å€¼æ“ä½œï¼ˆæ¢¯åº¦è®¡ç®—åä¹˜ä»¥ä¸€ä¸ªå¾ˆå°çš„å­¦ä¹ ç‡ï¼‰ï¼Œå¯èƒ½ä¼šä¸¢å¤±ç²¾åº¦

![image-20250319183417425](../my_minimind/images/image-20250319183417425.png)

adamä¼˜åŒ–å™¨

![image-20250319183329645](../my_minimind/images/image-20250319183329645.png)

### æ¢¯åº¦å€¼

![image-20250319184506157](../my_minimind/images/image-20250319184506157.png)

### æ¿€æ´»å€¼

https://zhuanlan.zhihu.com/p/673916177

**æ¿€æ´»å€¼ï¼šéœ€è¦åœ¨å‰å‘ä¼ æ’­æ—¶ä¿å­˜ä¸­é—´å€¼ï¼Œä¾¿äºåå‘ä¼ æ’­è®¡ç®—**

![image-20250319184302628](../my_minimind/images/image-20250319184302628.png)

![image-20250319184416752](../my_minimind/images/image-20250319184416752.png)

![image-20250319185604434](../my_minimind/images/image-20250319185604434.png)



### æ€»å ç”¨

![image-20250319184636424](../my_minimind/images/image-20250319184636424.png)

## Adamå’ŒAdamW

https://www.bilibili.com/video/BV1NZ421s75D/?spm_id_from=333.1387.upload.video_card.click&vd_source=edb614e9f3e817577f46a2e9deeca011

![image-20250319193214757](../my_minimind/images/image-20250319193214757.png)

![image-20250319193355233](../my_minimind/images/image-20250319193355233.png)

![image-20250319193931216](../my_minimind/images/image-20250319193931216.png)

-wï¼Œweight decayæƒé‡è¡°å‡ï¼Œé˜²æ­¢å‚æ•°è¿‡å¤§ï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›

![image-20250319194454645](../my_minimind/images/image-20250319194454645.png)

**L2æ­£åˆ™å’Œæƒé‡è¡°å‡ä¸åŒ**

![image-20250319194046711](../my_minimind/images/image-20250319194046711.png)

ä¿å­˜æ¢¯åº¦æŒ‡æ•°å¹³æ»‘å€¼Vå’Œä¿å­˜æ¢¯åº¦å¹³æ–¹æŒ‡æ•°å¹³æ»‘å€¼Sä¸¤ä¸ªå‚æ•°ï¼Œfloat32å­˜å‚¨ï¼Œå› æ­¤æ˜¯åŸå‚æ•°çš„4è¢«

![image-20250319194718141](../my_minimind/images/image-20250319194718141.png)

## é‡åŒ–

å‡å°æ¨¡å‹å¤§å°å’Œæ˜¾å­˜å ç”¨

æµ®ç‚¹æ•°è½¬ä¸ºæ•´æ•°å‹è®¡ç®—

### å›¾è§£

#### é‡åŒ–å’Œåé‡åŒ–ï¼šå¯¹ç§°é‡åŒ–å’Œéå¯¹ç§°é‡åŒ–

![image-20250319201402966](../my_minimind/images/image-20250319201402966.png)

![image-20250319201722534](../my_minimind/images/image-20250319201722534.png)

#### ç¥ç»ç½‘ç»œé‡åŒ–

![image-20250319202219301](../my_minimind/images/image-20250319202219301.png)

#### åŠ¨æ€é‡åŒ–

é‡åŒ–å‚æ•°ï¼šzero_pointï¼Œscale

è¾“å…¥fp32ï¼Œè¾“å‡ºfp32ï¼Œæ¯å±‚åŠ¨æ€ä¿å­˜int8æƒé‡ï¼›**æ¯æ¬¡è¾“å‡ºfp32**

![image-20250319204420378](../my_minimind/images/image-20250319204420378.png)

#### é™æ€é‡åŒ–

æ¯å±‚è¾“å‡ºint8ï¼Œåˆ©ç”¨ä»£è¡¨æ€§æ•°æ®å¾—åˆ°æ¯å±‚çš„é‡åŒ–å‚æ•°ï¼Œä»¥åæ¯å±‚å°±å›ºå®šä½¿ç”¨è¿™äº›å‚æ•°ï¼›**æœ‰è¯¯å·®**

![image-20250319204400829](../my_minimind/images/image-20250319204400829.png)

#### é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ

![image-20250319205245822](../my_minimind/images/image-20250319205245822.png)

#### LLM.int8

![image-20250319210306174](../my_minimind/images/image-20250319210306174.png)

```
# hugging face æ¨¡å‹é‡åŒ–æ­¥éª¤
bnb_config=BitsAndBytesConfig(load_in_8bit=True)
model=AutoModelForCausalLM.from_pretrained(model_id,device_map='auto',quantization_config=bnb_config)
```

#### QLoRA 4bit é‡åŒ– NormalFloat4 é‡åŒ–

4bitæ€»å…±æœ‰16ç±»

![image-20250319211516594](../my_minimind/images/image-20250319211516594.png)

![image-20250319211626597](../my_minimind/images/image-20250319211626597.png)

æŸ¥è¡¨ï¼Œå’Œå“ªä¸ªå€¼æœ€æ¥è¿‘å¾—åˆ°ç´¢å¼•

![image-20250319212318899](../my_minimind/images/image-20250319212318899.png)

åˆ†å—é‡åŒ–ï¼šQLoRAæ¯64ä¸ªå€¼ä½œä¸ºä¸€ä¸ªå—è¿›è¡ŒNF4 4-bité‡åŒ–

![image-20250319213148921](../my_minimind/images/image-20250319213148921.png)

**NF4é‡åŒ–åä¸èƒ½ç›´æ¥è®¡ç®—ï¼Œåªèƒ½åé‡åŒ–ä¸ºæµ®ç‚¹å‹è¿›è¡Œè®¡ç®—**

![image-20250319211429968](../my_minimind/images/image-20250319211429968.png)

### åŸç†

é‡åŒ–æ˜¯æŒ‡å°†æ¨¡å‹çš„æƒé‡ï¼ˆWeightsï¼‰å’Œ/æˆ–æ¿€æ´»å€¼ï¼ˆActivationsï¼‰ä»é«˜ç²¾åº¦æµ®ç‚¹æ ¼å¼ï¼ˆå¦‚ FP32ï¼Œ32ä½æµ®ç‚¹æ•°ï¼›æˆ– FP16ï¼Œ16ä½åŠç²¾åº¦æµ®ç‚¹æ•°ï¼‰è½¬æ¢ä¸ºä½ç²¾åº¦å®šç‚¹æˆ–æ•´æ•°æ ¼å¼ï¼ˆå¦‚ INT8ï¼Œ8ä½æ•´æ•°ï¼›INT4ï¼Œ4ä½æ•´æ•°ï¼›ç”šè‡³æ›´ä½ï¼‰ã€‚

**å‡å°æ¨¡å‹ä½“ç§¯**

**åŠ é€Ÿæ¨ç†**

**é™ä½èƒ½è€—**

**é‡åŒ–çš„æ ¸å¿ƒæ€æƒ³:**

é‡åŒ–çš„åŸºæœ¬æ€æƒ³æ˜¯å°†ä¸€ä¸ªèŒƒå›´å†…çš„æµ®ç‚¹æ•°å€¼ï¼Œæ˜ å°„åˆ°å¦ä¸€ä¸ªèŒƒå›´å†…çš„æ•´æ•°æ•°å€¼ã€‚è¿™ä¸ªæ˜ å°„å…³ç³»é€šå¸¸é€šè¿‡**ç¼©æ”¾å› å­ (scale)** å’Œ**é›¶ç‚¹ (zero_point)** æ¥å®šä¹‰ã€‚

æœ€å¸¸è§çš„é‡åŒ–æ–¹æ³•æ˜¯**ä»¿å°„é‡åŒ– (Affine Quantization)**ï¼Œå…¶å…¬å¼ä¸ºï¼š

â€‹														Q=round(R/scale)+zero_point

å…¶ä¸­ï¼š

- R: åŸå§‹çš„æµ®ç‚¹æ•° (Real value)ã€‚
- Q: é‡åŒ–åçš„æ•´æ•° (Quantized value)ã€‚
- scale: ç¼©æ”¾å› å­ï¼Œå†³å®šäº†æµ®ç‚¹èŒƒå›´å¦‚ä½•æ˜ å°„åˆ°æ•´æ•°èŒƒå›´ã€‚
- zero_point: é›¶ç‚¹ï¼Œä¸€ä¸ªæ•´æ•°åç§»ï¼Œç¡®ä¿æµ®ç‚¹æ•° 0.0 èƒ½å¤Ÿç²¾ç¡®åœ°æ˜ å°„åˆ°ä¸€ä¸ªæ•´æ•°å€¼ï¼Œè¿™å¯¹äºä¿ç•™æ¿€æ´»å€¼ä¸­çš„é›¶éå¸¸é‡è¦ï¼ˆé›¶æ¿€æ´»åœ¨ç¥ç»ç½‘ç»œä¸­å¾ˆå¸¸è§ï¼‰ã€‚
- round(): å–æ•´å‡½æ•°ï¼Œå°†ç»“æœè½¬æ¢ä¸ºæ•´æ•°ã€‚

![image-20250423232815868](pic/image-20250423232815868.png)

**é‡åŒ–çš„ç±»å‹ï¼ˆæŒ‰ä½•æ—¶è¿›è¡Œï¼‰ï¼š**

1. **è®­ç»ƒåé‡åŒ– (Post-Training Quantization, PTQ)**: åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆåè¿›è¡Œã€‚ç›¸å¯¹ç®€å•å¿«é€Ÿï¼Œä¸éœ€è¦é‡æ–°è®­ç»ƒã€‚é€šå¸¸éœ€è¦å°‘é‡æ ¡å‡†æ•°æ®æ¥ç¡®å®š scale å’Œ zero_pointã€‚å¯èƒ½ä¼šæœ‰ä¸€å®šçš„ç²¾åº¦æŸå¤±ã€‚
2. **é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ (Quantization-Aware Training, QAT)**: åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡æ‹Ÿé‡åŒ–çš„å½±å“ã€‚åœ¨æ¨¡å‹ä¸­æ’å…¥æ¨¡æ‹Ÿé‡åŒ–å’Œåé‡åŒ–çš„èŠ‚ç‚¹ï¼Œè®©æ¨¡å‹åœ¨è®­ç»ƒæ—¶å°±é€‚åº”é‡åŒ–å¸¦æ¥çš„æ•°å€¼è¯¯å·®ã€‚é€šå¸¸èƒ½è·å¾—æ¯” PTQ æ›´å¥½çš„ç²¾åº¦ï¼Œä½†éœ€è¦ä¿®æ”¹è®­ç»ƒæµç¨‹ã€‚

å¤§æ¨¡å‹ä¸­ PTQ æ›´å¸¸ç”¨ï¼Œå› ä¸ºå®ƒä¸éœ€è¦å·¨å¤§çš„è®¡ç®—èµ„æºé‡æ–°è®­ç»ƒï¼Œä¸”é…åˆä¸€äº›å…ˆè¿›çš„ PTQ æŠ€æœ¯ï¼ˆå¦‚ AWQ, GPTQï¼‰ä¹Ÿèƒ½è¾¾åˆ°å¾ˆå¥½çš„æ•ˆæœã€‚

**å¤§æ¨¡å‹ä¸­çš„åé‡åŒ– (Dequantization)**

åé‡åŒ–æ˜¯å°†é‡åŒ–åçš„ä½ç²¾åº¦æ•´æ•°å€¼ï¼Œè½¬æ¢å›åŸå§‹çš„é«˜ç²¾åº¦æµ®ç‚¹æ ¼å¼çš„è¿‡ç¨‹

### ä»£ç 

**ä½¿ç”¨é’ˆå¯¹å¤§æ¨¡å‹çš„é‡åŒ–åº“ (å¦‚ `bitsandbytes`)**

å¯¹äº LLMsï¼Œç”±äºå…¶è§„æ¨¡å’Œç‰¹æ€§ï¼ˆå¦‚å¤§é‡çš„çº¿æ€§å±‚ï¼‰ï¼Œå¸¸å¸¸ä½¿ç”¨ä¸“é—¨çš„é‡åŒ–åº“ã€‚`bitsandbytes` æ˜¯ä¸€ä¸ªéå¸¸æµè¡Œçš„åº“ï¼Œæä¾›äº† 8 ä½å’Œ 4 ä½é‡åŒ–åŠŸèƒ½ï¼Œå¹¶ä¸”ä¼˜åŒ–äº†ç›¸åº”çš„ CUDA Kernel ä»¥åŠ é€Ÿè®¡ç®—ã€‚

```python
# éœ€è¦å…ˆå®‰è£… bitsandbytes å’Œ accelerate
# pip install bitsandbytes accelerate transformers

from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# æ¨¡å‹åç§° (ä¾‹å¦‚ Llama-2-7b)
model_name = "meta-llama/Llama-2-7b-hf" # æ›¿æ¢ä¸ºä½ æƒ³åŠ è½½çš„æ¨¡å‹

# ä»¥ 8 ä½ç²¾åº¦åŠ è½½æ¨¡å‹
# load_in_8bit=True ä¼šä½¿ç”¨ bitsandbytes è¿›è¡Œ 8 ä½é‡åŒ–åŠ è½½
# device_map='auto' ä¼šè‡ªåŠ¨å°†æ¨¡å‹åŠ è½½åˆ°å¯ç”¨çš„è®¾å¤‡ä¸Š (å¦‚ GPU)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    load_in_8bit=True, # æ ¸å¿ƒå‚æ•°ï¼šå¯ç”¨ 8 ä½åŠ è½½
    device_map='auto',
    torch_dtype=torch.float16 # é€šå¸¸ä¸ FP16 æˆ– BF16 é…åˆä½¿ç”¨
)

tokenizer = AutoTokenizer.from_pretrained(model_name)

print(f"æ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨äº† 8 ä½é‡åŒ–: {model_name}")
print("æ¨¡å‹å‚æ•°ç±»å‹ç¤ºä¾‹:", model.lm_head.weight.dtype) # å¯èƒ½ä¼šæ˜¾ç¤º BitsAndBytes 8-bit ç±»å‹

# ç°åœ¨å¯ä»¥ç›´æ¥ä½¿ç”¨ model è¿›è¡Œæ¨ç†ï¼Œè®¡ç®—ä¼šåœ¨ 8 ä½è¿›è¡Œ (é€šè¿‡ bitsandbytes çš„ kernel)
# è¾“å…¥å’Œè¾“å‡ºå¤„ç†é€šå¸¸ä»ç„¶æ¶‰åŠ FP16/FP32 çš„è½¬æ¢ï¼Œç”± bitsandbytes åœ¨åº•å±‚å¤„ç†åé‡åŒ–å’Œé‡åŒ–

# ç¤ºä¾‹æ¨ç†
prompt = "è¯·å†™ä¸€ä¸ªå…³äºäººå·¥æ™ºèƒ½çš„çŸ­æ•…äº‹ï¼š"
inputs = tokenizer(prompt, return_tensors="pt").to(model.device) # å°†è¾“å…¥æ”¾åˆ°æ¨¡å‹æ‰€åœ¨çš„è®¾å¤‡ä¸Š

with torch.no_grad():
    outputs = model.generate(**inputs, max_new_tokens=100)

response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print("\næ¨¡å‹ç”Ÿæˆç»“æœ:")
print(response)

# ä½¿ç”¨ 4 ä½é‡åŒ–ç±»ä¼¼ï¼Œåªéœ€å°† load_in_8bit=True æ”¹ä¸º load_in_4bit=True
# model_4bit = AutoModelForCausalLM.from_pretrained(
#     model_name,
#     load_in_4bit=True, # å¯ç”¨ 4 ä½åŠ è½½
#     device_map='auto',
#     torch_dtype=torch.float16
# )
```

è¿™é‡Œçš„é‡åŒ–å’Œåé‡åŒ–ç»†èŠ‚ä¸»è¦ç”± `bitsandbytes` åº“åœ¨åº•å±‚å¤„ç†ï¼ŒåŒ…æ‹¬æƒé‡çš„åŠ è½½ã€å­˜å‚¨å’Œè®¡ç®—æ—¶çš„åŠ¨æ€åé‡åŒ–ï¼ˆæˆ–ç›´æ¥ä½¿ç”¨é‡åŒ– Kernelï¼‰ã€‚

## å¤§æ¨¡å‹åˆ†å¸ƒå¼DP

### åŸç†

**ä¸ºä»€ä¹ˆéœ€è¦å¤§æ¨¡å‹åˆ†å¸ƒå¼ï¼Ÿ**

ä¸»è¦åŸå› æœ‰ä¸‰ä¸ªï¼š

1. **å†…å­˜é™åˆ¶ (Memory Limit):**
   - **æ¨¡å‹å‚æ•° (Model Parameters):** å¤§æ¨¡å‹çš„å‚æ•°é‡å·¨å¤§ï¼Œå³ä½¿ä½¿ç”¨è¾ƒä½ç²¾åº¦ï¼ˆå¦‚ FP16ï¼‰ï¼Œå…¶å­˜å‚¨æ‰€éœ€çš„å†…å­˜ä¹Ÿå¯èƒ½è¶…è¿‡å•ä¸ª GPU çš„æ˜¾å­˜ã€‚
   - **æ¢¯åº¦ (Gradients):** è®­ç»ƒæ—¶éœ€è¦å­˜å‚¨ä¸å‚æ•°é‡ç›¸åŒçš„æ¢¯åº¦ã€‚
   - **ä¼˜åŒ–å™¨çŠ¶æ€ (Optimizer States):** Adam ç­‰ä¼˜åŒ–å™¨éœ€è¦å­˜å‚¨é¢å¤–çš„çŠ¶æ€ï¼ˆå¦‚åŠ¨é‡ã€æ–¹å·®ï¼‰ï¼Œé€šå¸¸æ˜¯å‚æ•°é‡çš„ 2-4 å€ã€‚
   - **ä¸­é—´æ¿€æ´»å€¼ (Intermediate Activations):** å‰å‘è®¡ç®—æ—¶äº§ç”Ÿçš„ä¸­é—´ç»“æœï¼Œåå‘ä¼ æ’­æ—¶éœ€è¦ç”¨åˆ°ï¼Œä¹Ÿéå¸¸å ç”¨å†…å­˜ã€‚
   - **æ•°æ®æ‰¹æ¬¡ (Batch Data):** è¾“å…¥æ•°æ®æœ¬èº«ä¹Ÿéœ€è¦å ç”¨æ˜¾å­˜ã€‚ å½“è¿™äº›æ€»å’Œè¶…è¿‡å•ä¸ªè®¾å¤‡çš„æœ€å¤§å†…å­˜æ—¶ï¼Œå°±å¿…é¡»è¿›è¡Œåˆ†å¸ƒå¼å¤„ç†ã€‚
2. **è®¡ç®—é™åˆ¶ (Compute Limit):**
   - å³ä½¿æ¨¡å‹èƒ½å‹‰å¼ºæ”¾å…¥å•ä¸ªè®¾å¤‡çš„å†…å­˜ï¼Œè®­ç»ƒæˆ–æ¨ç†æ‰€éœ€çš„è®¡ç®—é‡ä¹Ÿæå…¶åºå¤§ï¼Œå¯¼è‡´è€—æ—¶è¿‡é•¿ã€‚åˆ†å¸ƒå¼å¯ä»¥å°†è®¡ç®—ä»»åŠ¡å¹¶è¡ŒåŒ–ï¼Œæ˜¾è‘—ç¼©çŸ­æ—¶é—´ã€‚
3. **æ•°æ®é™åˆ¶ (Data Limit):**
   - è®­ç»ƒå¤§æ¨¡å‹é€šå¸¸éœ€è¦æµ·é‡æ•°æ®ã€‚å°†æ•°æ®åˆ†å¸ƒåˆ°ä¸åŒçš„æœºå™¨ä¸Šï¼Œå¯ä»¥æé«˜æ•°æ®åŠ è½½å’Œå¤„ç†çš„æ•ˆç‡ã€‚

**DP:data parallelæ•°æ®å¹¶è¡Œ**

**æ¨¡å‹å¹¶è¡Œ (Model Parallelism, MP):**

- **åŸç†:** å°†**æ¨¡å‹æœ¬èº«**ï¼ˆå±‚ã€æ¨¡å—æˆ–ç”šè‡³å±‚å†…çš„å¼ é‡ï¼‰åˆ†å‰²åˆ°ä¸åŒçš„è®¾å¤‡ä¸Šã€‚æ•°æ®åœ¨è¿™äº›è®¾å¤‡ä¹‹é—´æµåŠ¨ï¼ŒæŒ‰é¡ºåºé€šè¿‡æ¨¡å‹çš„ä¸åŒéƒ¨åˆ†ã€‚
- ä¸»è¦ç±»å‹:
  - **å¼ é‡å¹¶è¡Œ (Tensor Parallelism, TP):** å°†å±‚å†…çš„**å¼ é‡**ï¼ˆå¦‚æƒé‡çŸ©é˜µï¼‰åˆ†å‰²åˆ°å¤šä¸ªè®¾å¤‡ä¸Šã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªå¤§çš„æƒé‡çŸ©é˜µå¯ä»¥æŒ‰åˆ—æˆ–æŒ‰è¡Œåˆ†å‰²ï¼ŒçŸ©é˜µä¹˜æ³•æ“ä½œä¹Ÿéšä¹‹åˆ†è§£å¹¶æ¶‰åŠè®¾å¤‡é—´çš„é€šä¿¡ã€‚è¿™è§£å†³äº†å•ä¸ªå±‚è®¡ç®—æˆ–å­˜å‚¨éœ€æ±‚è¿‡å¤§çš„é—®é¢˜ã€‚
  - **æµæ°´çº¿å¹¶è¡Œ (Pipeline Parallelism, PP):** å°†æ¨¡å‹çš„**ä¸åŒå±‚æˆ–è¿ç»­çš„å‡ å±‚**åˆ†é…åˆ°ä¸åŒçš„è®¾å¤‡ä¸Šï¼Œå½¢æˆä¸€ä¸ªå¤„ç†æ•°æ®çš„æµæ°´çº¿ã€‚æ•°æ®æ‰¹æ¬¡è¢«è¿›ä¸€æ­¥åˆ†æˆæ›´å°çš„â€œå¾®æ‰¹æ¬¡â€ï¼ˆmicro-batchesï¼‰ã€‚å½“ç¬¬ä¸€ä¸ªå¾®æ‰¹æ¬¡å®Œæˆç¬¬ä¸€é˜¶æ®µçš„è®¡ç®—å¹¶ä¼ é€’ç»™ç¬¬äºŒé˜¶æ®µæ—¶ï¼Œç¬¬ä¸€é˜¶æ®µå°±å¯ä»¥å¼€å§‹å¤„ç†ç¬¬äºŒä¸ªå¾®æ‰¹æ¬¡ï¼Œä»è€Œé‡å è®¡ç®—å’Œé€šä¿¡ã€‚
- å·¥ä½œæµç¨‹ (ä»¥ PP ä¸ºä¾‹):
  1. å°†æ¨¡å‹å±‚åˆ†ç»„ï¼Œåˆ†é…åˆ°ä¸åŒçš„è®¾å¤‡ï¼ˆé˜¶æ®µï¼‰ã€‚
  2. å°†ä¸€ä¸ª mini-batch æ•°æ®åˆ†æˆå¤šä¸ª micro-batchesã€‚
  3. micro-batches ä¾æ¬¡è¿›å…¥æµæ°´çº¿çš„ç¬¬ä¸€ä¸ªé˜¶æ®µè®¾å¤‡ï¼Œè®¡ç®—å®Œæˆåä¼ é€’ç»™ä¸‹ä¸€ä¸ªé˜¶æ®µè®¾å¤‡ã€‚
  4. ä¸åŒé˜¶æ®µçš„è®¾å¤‡å¯ä»¥åŒæ—¶å¤„ç†ä¸åŒçš„ micro-batchï¼Œå½¢æˆæµæ°´çº¿æ•ˆåº”ã€‚
  5. åå‘ä¼ æ’­ä¹Ÿæ²¿ç€æµæ°´çº¿åå‘è¿›è¡Œã€‚
- **ä¼˜ç‚¹:** å¯ä»¥è®­ç»ƒæ¨¡å‹æœ¬èº«å¤§äºå•ä¸ªè®¾å¤‡å†…å­˜çš„æ¨¡å‹ã€‚
- ç¼ºç‚¹:
  - **å®ç°å¤æ‚:** éœ€è¦ä»”ç»†åˆ‡åˆ†æ¨¡å‹å’Œç®¡ç†æ•°æ®æµã€‚
  - **æµæ°´çº¿æ°”æ³¡ (Pipeline Bubble):** åœ¨æµæ°´çº¿å¯åŠ¨å’Œå…³é—­æ—¶ï¼Œéƒ¨åˆ†è®¾å¤‡å¯èƒ½ä¼šç©ºé—²ï¼Œæ•ˆç‡ä¸é«˜ã€‚
  - **è®¡ç®—/é€šä¿¡å¹³è¡¡:** éœ€è¦å¹³è¡¡å„é˜¶æ®µçš„è®¡ç®—è´Ÿè½½å’Œè®¾å¤‡é—´çš„é€šä¿¡å¼€é”€ã€‚

**ä¸“å®¶å¹¶è¡Œ (Expert Parallelism, EP):**

- **åŸç†:** ä¸»è¦ç”¨äº Mixture-of-Experts (MoE) æ¨¡å‹ã€‚MoE æ¨¡å‹åŒ…å«å¤šä¸ªç‹¬ç«‹çš„â€œä¸“å®¶â€ç½‘ç»œã€‚ä¸åŒçš„æ•°æ®è¾“å…¥ä¼šé€šè¿‡ä¸€ä¸ªâ€œé—¨æ§ç½‘ç»œâ€ï¼ˆgating networkï¼‰è¢«è·¯ç”±åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªç‰¹å®šçš„ä¸“å®¶è¿›è¡Œå¤„ç†ã€‚ä¸“å®¶å¹¶è¡Œæ˜¯å°†è¿™äº›ä¸åŒçš„ä¸“å®¶åˆ†æ•£åˆ°ä¸åŒçš„è®¾å¤‡ä¸Šã€‚
- **ä¼˜ç‚¹:** å¯ä»¥æ˜¾è‘—å¢åŠ æ¨¡å‹çš„æ€»å‚æ•°é‡ï¼Œä½†æ¯ä¸ªæ•°æ®ç‚¹åªæ¿€æ´»å…¶ä¸­ä¸€éƒ¨åˆ†ä¸“å®¶ï¼Œè®¡ç®—æ•ˆç‡ç›¸å¯¹è¾ƒé«˜ã€‚
- **ç¼ºç‚¹:** å®ç°å¤æ‚ï¼Œè´Ÿè½½å‡è¡¡æ˜¯æŒ‘æˆ˜ï¼ˆç¡®ä¿ä¸“å®¶è¢«å‡åŒ€è®¿é—®ï¼‰

### DP:data parallelæ•°æ®å¹¶è¡Œ

```
åŸç†ï¼š
å°†ç›¸åŒå®Œæ•´çš„æ¨¡å‹å‰¯æœ¬å¤åˆ¶åˆ°ä¸åŒçš„è®¾å¤‡ä¸Šã€‚
é€šè¿‡ä¸€ä¸ªcpuè¿›ç¨‹å°†batchæ•°æ®åˆ†å‰²æˆå¤šä¸ªmini-batch
æ¯ä¸ªè®¾å¤‡æ¥æ”¶ä¸åŒæ‰¹æ¬¡çš„æ•°æ®mini-batchè¿›è¡Œå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ï¼Œè®¡ç®—å‡ºå„è‡ªçš„æ¢¯åº¦ã€‚
ç„¶åï¼Œé€šè¿‡é€šä¿¡æ“ä½œå°†æ‰€æœ‰è®¾å¤‡çš„æ¢¯åº¦è¿›è¡Œå¹³å‡æˆ–æ±‚å’Œï¼Œå†ç”¨è¿™ä¸ªå¹³å‡æ¢¯åº¦æ›´æ–°æ‰€æœ‰è®¾å¤‡ä¸Šçš„æ¨¡å‹å‚æ•°ï¼Œä¿æŒæ¨¡å‹å‰¯æœ¬çš„ä¸€è‡´æ€§ã€‚
ï¼ˆå…·ä½“æ“ä½œæ˜¯æ‰€æœ‰æ¢¯åº¦é›†ä¸­åˆ°gpu0ä¸Šæ“ä½œï¼Œæ“ä½œå®Œåå°†æ›´æ–°çš„æ¢¯åº¦å¹¿æ’­ç»™å…¶ä»–çš„gpuï¼‰

ä½¿ç”¨All-Reduceç­‰é€šä¿¡æ“ä½œï¼ŒåŒæ­¥æ‰€æœ‰è®¾å¤‡çš„æ¢¯åº¦ï¼ˆä¾‹å¦‚ï¼Œæ±‚å’Œæˆ–å¹³å‡ï¼‰ã€‚

ä¸è¶³ï¼š
é€šä¿¡é‡å¤§
æ¯ä¸ªgpuéœ€è¦ä¿å­˜å®Œæ•´çš„æ¨¡å‹å‰¯æœ¬
å•è¿›ç¨‹ï¼Œå¤šçº¿ç¨‹ï¼Œåªèƒ½åˆ©ç”¨ä¸€ä¸ªcpuï¼ˆé€‚ç”¨äºä¸€æœºcpuå¤šå¡gpuï¼‰
GPU0é€šä¿¡é‡å¤§
```

![image-20250319220151303](../my_minimind/images/image-20250319220151303.png)

### DDP:distributed data parallel åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ

#### é›†ç¾¤é€šä¿¡æ–¹å¼ring_allreduce

```
ring_allreduceç¬¬ä¸€é˜¶æ®µ: scatter-reduceï¼ˆæœ‰ä¸€ä¸ªæ•°æ®å¦‚a,b,cæ»¡äº†å°±ç»“æŸè¿™ä¸€é˜¶æ®µï¼‰ 
```

![image-20250319221019146](../my_minimind/images/image-20250319221019146.png)



```
ring_allreduceç¬¬äºŒé˜¶æ®µ: allgatherï¼ˆå°†æ»¡çš„æ•°æ®å‘é€ç»™ä¸‹ä¸€ä¸ªgpuï¼Œç›´è‡³æ‰€æœ‰gpuçš„æ¢¯åº¦å…¨éƒ¨å¤„ç†ï¼‰
```

![image-20250319221051513](../my_minimind/images/image-20250319221051513.png)

#### è¿‡ç¨‹

```
ddpå¤šè¿›ç¨‹

åŸç†ï¼š
å°†ç›¸åŒå®Œæ•´çš„æ¨¡å‹å‰¯æœ¬å¤åˆ¶åˆ°ä¸åŒçš„è®¾å¤‡ä¸Šã€‚
é€šè¿‡ä¸€ä¸ªcpuè¿›ç¨‹å°†batchæ•°æ®åˆ†å‰²æˆå¤šä¸ªmini-batch
æ¯ä¸ªè®¾å¤‡æ¥æ”¶ä¸åŒæ‰¹æ¬¡çš„æ•°æ®mini-batchè¿›è¡Œå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ï¼Œè®¡ç®—å‡ºå„è‡ªçš„æ¢¯åº¦ã€‚
ç„¶åï¼Œé€šè¿‡é€šä¿¡æ“ä½œring-reduceåŒæ­¥å„ä¸ªgpuçš„æ¢¯åº¦ï¼Œä½¿å¾—æ¢¯åº¦ä¿æŒä¸€è‡´ï¼Œä¿æŒæ¨¡å‹å‰¯æœ¬çš„ä¸€è‡´æ€§ã€‚
ï¼ˆå…·ä½“æ“ä½œæ˜¯æ‰€æœ‰æ¢¯åº¦é›†ä¸­åˆ°gpu0ä¸Šæ“ä½œï¼Œæ“ä½œå®Œåå°†æ›´æ–°çš„æ¢¯åº¦å¹¿æ’­ç»™å…¶ä»–çš„gpuï¼‰

ä½¿ç”¨All-Reduceç­‰é€šä¿¡æ“ä½œï¼ŒåŒæ­¥æ‰€æœ‰è®¾å¤‡çš„æ¢¯åº¦ï¼ˆä¾‹å¦‚ï¼Œæ±‚å’Œæˆ–å¹³å‡ï¼‰ã€‚

ä¸è¶³:
æ¯ä¸ªgpuéœ€è¦å­˜å‚¨å®Œæ•´çš„ä¼˜åŒ–å™¨ï¼Œæ˜¾å­˜å¯èƒ½ä¸è¶³ã€‚deepspeedå¯ä»¥è§£å†³
```

![image-20250319220654786](../my_minimind/images/image-20250319220654786.png)

```
å…·ä½“ç»†èŠ‚ï¼š
å„ä¸ªgpuçš„æ¢¯åº¦ç”¨æ¡¶åå‘ä¿å­˜ï¼Œå› ä¸ºè¾“å‡ºå±‚çš„æ¢¯åº¦æœ€å…ˆè®¡ç®—ï¼Œè¿™æ ·å°±èƒ½è¾¹ä¼ è¾“è¾¹è®¡ç®—ã€‚
æ¯æ»¡ä¸€ä¸ªæ¡¶å°±è¿›è¡Œring allreduce
```

![image-20250424101943190](pic/image-20250424101943190.png)

![image-20250319221259577](../my_minimind/images/image-20250319221259577.png)

#### ä»£ç 

```python
import os
import torch
import torch.nn as nn
import torch.optim as optim
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.distributed import DistributedSampler

# 1. å®šä¹‰ä¸€ä¸ªç®€å•çš„æ¨¡å‹
class SimpleModel(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(SimpleModel, self).__init__()
        self.fc = nn.Linear(input_dim, output_dim)

    def forward(self, x):
        return self.fc(x)

# 2. å®šä¹‰ä¸€ä¸ªç®€å•çš„æ¨¡æ‹Ÿæ•°æ®é›†
class DummyDataset(Dataset):
    def __init__(self, num_samples, input_dim, output_dim):
        self.num_samples = num_samples
        self.input_dim = input_dim
        self.output_dim = output_dim
        # ç”Ÿæˆéšæœºæ•°æ®å’Œæ ‡ç­¾
        self.inputs = torch.randn(num_samples, input_dim)
        self.labels = torch.randn(num_samples, output_dim)

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.inputs[idx], self.labels[idx]

# 3. åˆ†å¸ƒå¼è®­ç»ƒå‡½æ•°
def train(rank, world_size, model, train_loader, optimizer, criterion, epoch):
    # è®¾ç½®å½“å‰è¿›ç¨‹ä½¿ç”¨çš„GPU
    torch.cuda.set_device(rank)
    model.cuda(rank)

    # ä½¿ç”¨ DDP åŒ…è£…æ¨¡å‹
    # find_unused_parameters=True might be needed if not all parameters receive gradients
    # (e.g., when using gradient checkpointing or freezing layers)
    model = DDP(model, device_ids=[rank], find_unused_parameters=False)

    # è®¾ç½® epoch é‡‡æ ·å™¨ï¼Œç¡®ä¿æ¯ä¸ª epoch çš„æ•°æ®é¡ºåºä¸åŒ
    train_loader.sampler.set_epoch(epoch)

    model.train()
    running_loss = 0.0
    for i, data in enumerate(train_loader):
        inputs, labels = data
        inputs, labels = inputs.cuda(rank), labels.cuda(rank)

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, labels)

        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # æ¯éš”ä¸€æ®µæ—¶é—´æ‰“å°æŸå¤±
        if i % 10 == 9 and rank == 0: # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
            print(f"Epoch {epoch+1}, Rank {rank}, Step {i+1}, Loss: {running_loss / 10:.4f}")
            running_loss = 0.0

# 4. ä¸»å‡½æ•°ï¼Œè´Ÿè´£åˆ†å¸ƒå¼ç¯å¢ƒåˆå§‹åŒ–å’Œå¯åŠ¨è®­ç»ƒ
def main():
    # è·å–å½“å‰è¿›ç¨‹çš„å…¨å±€ rank (è¿›ç¨‹ç¼–å·) å’Œæ€»è¿›ç¨‹æ•°
    rank = int(os.environ["RANK"])
    world_size = int(os.environ["WORLD_SIZE"])

    print(f"Rank {rank}/{world_size} is initializing...")

    # åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
    # backend: ä½¿ç”¨çš„é€šä¿¡åç«¯ (nccl for GPUs, gloo for CPUs)
    # init_method: åˆå§‹åŒ–æ–¹å¼ (env:// è¡¨ç¤ºä»ç¯å¢ƒå˜é‡è·å– master_addr å’Œ master_port)
    dist.init_process_group(backend="nccl", init_method="env://", rank=rank, world_size=world_size)

    print(f"Rank {rank}/{world_size} initialization done.")

    # è®¾ç½®å‚æ•°
    input_dim = 10
    output_dim = 2
    num_samples_per_rank = 100 # æ¯ä¸ªè¿›ç¨‹å¤„ç†çš„æ•°æ®é‡
    total_samples = num_samples_per_rank * world_size
    batch_size = 16
    epochs = 5
    learning_rate = 0.01

    # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    # æ³¨æ„ï¼šDistributedSampler ä¼šç¡®ä¿æ¯ä¸ªè¿›ç¨‹åªåŠ è½½æ€»æ•°æ®çš„ä¸€éƒ¨åˆ†
    dataset = DummyDataset(total_samples, input_dim, output_dim)
    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)
    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=sampler, num_workers=2) # num_workers å¯ä»¥æ ¹æ®éœ€è¦è®¾ç½®

    # åˆ›å»ºæ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    model = SimpleModel(input_dim, output_dim)
    criterion = nn.MSELoss()
    optimizer = optim.SGD(model.parameters(), lr=learning_rate)

    # å¼€å§‹è®­ç»ƒ
    print(f"Rank {rank}/{world_size} starting training...")
    for epoch in range(epochs):
        train(rank, world_size, model, train_loader, optimizer, criterion, epoch)

    print(f"Rank {rank}/{world_size} training finished.")

    # æ¸…ç†åˆ†å¸ƒå¼ç¯å¢ƒ
    dist.destroy_process_group()
    print(f"Rank {rank}/{world_size} destroyed process group.")

if __name__ == "__main__":
    # å¦‚ä½•è¿è¡Œè¿™ä¸ªè„šæœ¬:
    # å‡è®¾ä½ æƒ³åœ¨ä¸¤å— GPU ä¸Šè¿è¡Œ (world_size=2)
    # ä½¿ç”¨ torchrun å‘½ä»¤ (æ¨èï¼ŒPyTorch 1.9+):
    # torchrun --nproc_per_node=2 your_script_name.py
    # æˆ–è€…ä½¿ç”¨æ—§çš„ torch.distributed.launch:
    # python -m torch.distributed.launch --nproc_per_node=2 your_script_name.py

    # æ³¨æ„: è¿™ä¸ªè„šæœ¬éœ€è¦åœ¨æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒçš„ç¯å¢ƒä¸­è¿è¡Œ (å¤šå—GPUæˆ–å¤šå°æœºå™¨)
    # å¦‚æœåœ¨å• GPU ç¯å¢ƒè¿è¡Œ torchrun --nproc_per_node=1 your_script_name.py ä¹Ÿå¯ä»¥å·¥ä½œ
    # ä½†è¦è¿è¡Œåœ¨å¤š GPU ç¯å¢ƒï¼Œç¡®ä¿ä½ çš„æœºå™¨æœ‰å¤šå— GPU å¹¶ä¸”æ­£ç¡®é…ç½®äº†é©±åŠ¨ã€‚
    # å®é™…è¿è¡Œæ—¶ï¼Œtorchrun ä¼šè®¾ç½® RANK, WORLD_SIZE, MASTER_ADDR, MASTER_PORT ç­‰ç¯å¢ƒå˜é‡
    # è¿™äº›ç¯å¢ƒå˜é‡ä¼šè¢« dist.init_process_group è¯»å–ã€‚
    main()
```



### DeepSpeed ZeRO-1 (zero redundancy optimizer é›¶å†—ä½™ä¼˜åŒ–å™¨)

åå‘ä¼ æ’­å‚æ•°ï¼š1

æ¢¯åº¦æ”¶é›†ï¼š1

**å¹¿æ’­æ¢¯åº¦-->æ›´æ–°å‚æ•°**

å¤§å¤§å‡å°‘äº†æ˜¾å­˜ï¼šä»…å‘é€ç»™å•ä¸€GPU

```
ç½‘ç»œå‚æ•°å’Œæ¢¯åº¦ FP16
ä¼˜åŒ–å™¨æ¢¯åº¦ï¼Œä¸€é˜¶ï¼ŒäºŒé˜¶ï¼Œå‚æ•°ï¼ˆmain weightï¼‰ FP32

ç”±äºå ç”¨æœ€å¤§çš„æ˜¯ä¼˜åŒ–å™¨ï¼Œå› æ­¤æ¯ä¸ªGPUä¿å­˜å¯¹åº”ç½‘ç»œå±‚çš„ä¼˜åŒ–å™¨Adamï¼ˆFP32æ•°æ®ï¼‰

è¿‡ç¨‹ï¼š
å‰å‘ä¼ æ’­
åå‘ä¼ æ’­ï¼š
é¦–å…ˆæ¯ä¸ªgpuè®¡ç®—æ‰€æœ‰çš„æ¢¯åº¦fp16ï¼Œå°†æ¢¯åº¦fp16é›†ä¸­å‘ç»™å¯¹åº”å¤„ç†è¿™å±‚çš„gpuæ›´æ–°æ¢¯åº¦ï¼›
è¿™æ ·æ¯ä¸ªgpuå°±æœ‰è‡ªå·±è´Ÿè´£çš„ç½‘ç»œå±‚æœ€æ–°çš„æ¢¯åº¦fp16ï¼Œä¹Ÿæœ‰è‡ªå·±è´Ÿè´£çš„ç½‘ç»œå±‚çš„ä¼˜åŒ–å™¨
å°†æ¢¯åº¦fp16ç¼©æ”¾è‡³fp32ï¼Œå¾—åˆ°ä¸€é˜¶äºŒé˜¶åŠ¨é‡ï¼Œæ›´æ–°ä¼˜åŒ–å™¨å¾—åˆ°æœ€æ–°çš„fp32å‚æ•°
æ›´æ–°å„è‡ªä¼˜åŒ–å™¨å¯¹åº”çš„ç½‘ç»œå‚æ•°fp16ï¼Œå¹¿æ’­ç»™å…¶ä»–gpu


å¤§å¤§å‡å°‘äº†æ˜¾å­˜å ç”¨é‡ï¼Œä½†æ˜¯æ²¡æœ‰å‡å°‘é€šè®¯é‡
```

![image-20250319222321451](../my_minimind/images/image-20250319222321451.png)

![image-20250319222303536](../my_minimind/images/image-20250319222303536.png)

### DeepSpeed ZeRO-2

åå‘ä¼ æ’­å‚æ•°ï¼š1

æ¢¯åº¦æ”¶é›†ï¼š1

```
æ¯ä¸ªgpuè´Ÿè´£æ›´æ–°å„è‡ªçš„ç½‘ç»œå±‚çš„å‚æ•°ï¼Œå› æ­¤åªéœ€è¦ä¿å­˜å„è‡ªç½‘ç»œå±‚çš„æ¢¯åº¦

è¿‡ç¨‹ï¼š
å‰å‘ä¼ æ’­
åå‘ä¼ æ’­ï¼š
é¦–å…ˆæ¯ä¸ªgpuè®¡ç®—æ‰€æœ‰çš„æ¢¯åº¦fp16ï¼Œå°†æ¢¯åº¦fp16é›†ä¸­å‘ç»™å¯¹åº”å¤„ç†è¿™å±‚çš„gpuæ›´æ–°æ¢¯åº¦ï¼›
ä¸å¤„ç†è¿™å±‚çš„gpuå‘é€å®Œæ¢¯åº¦fp16åç«‹å³é‡Šæ”¾ï¼ˆä¸å ç”¨æ˜¾å­˜ï¼‰
è¿™æ ·æ¯ä¸ªgpuå°±æœ‰è‡ªå·±è´Ÿè´£çš„ç½‘ç»œå±‚æœ€æ–°çš„æ¢¯åº¦fp16ï¼Œä¹Ÿæœ‰è‡ªå·±è´Ÿè´£çš„ç½‘ç»œå±‚çš„ä¼˜åŒ–å™¨
å°†æ¢¯åº¦fp16ç¼©æ”¾è‡³fp32ï¼Œå¾—åˆ°ä¸€é˜¶äºŒé˜¶åŠ¨é‡ï¼Œæ›´æ–°ä¼˜åŒ–å™¨å¾—åˆ°æœ€æ–°çš„fp32å‚æ•°
æ›´æ–°å„è‡ªä¼˜åŒ–å™¨å¯¹åº”çš„ç½‘ç»œå‚æ•°fp16ï¼Œå¹¿æ’­ç»™å…¶ä»–gpu


å¤§å¤§å‡å°‘äº†æ˜¾å­˜å ç”¨é‡ï¼Œä½†æ˜¯æ²¡æœ‰å‡å°‘é€šè®¯é‡
```

![image-20250319224601012](../my_minimind/images/image-20250319224601012.png)

#### ä»£ç 

**æ­¥éª¤ï¼š**

1. **åˆ›å»º DeepSpeed é…ç½® JSON æ–‡ä»¶**
2. **åˆ›å»º Python è®­ç»ƒè„šæœ¬**
3. **ä½¿ç”¨ DeepSpeed å‘½ä»¤è¿è¡Œè„šæœ¬**

```python
import os
import torch
import torch.nn as nn
import torch.optim as optim
import deepspeed
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.distributed import DistributedSampler # DeepSpeed handles sampler for you

# 1. å®šä¹‰ä¸€ä¸ªç®€å•çš„æ¨¡æ‹Ÿæ¨¡å‹ (å¯ä»¥æ¢æˆä½ çš„å¤§æ¨¡å‹)
class SimpleModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(SimpleModel, self).__init__()
        self.layer1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU()
        self.layer2 = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        x = self.layer1(x)
        x = self.relu(x)
        x = self.layer2(x)
        return x

# 2. å®šä¹‰ä¸€ä¸ªç®€å•çš„æ¨¡æ‹Ÿæ•°æ®é›†
class DummyDataset(Dataset):
    def __init__(self, num_samples, input_dim, output_dim):
        self.num_samples = num_samples
        self.input_dim = input_dim
        self.output_dim = output_dim
        # ç”Ÿæˆéšæœºæ•°æ®å’Œæ ‡ç­¾
        self.inputs = torch.randn(num_samples, input_dim)
        self.labels = torch.randn(num_samples, output_dim)

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.inputs[idx], self.labels[idx]

# 3. ä¸»è®­ç»ƒå‡½æ•°
def main():
    # åˆå§‹åŒ– DeepSpeed ç¯å¢ƒ
    # æ³¨æ„: DeepSpeed ä¼šè‡ªåŠ¨å¤„ç† PyTorch åˆ†å¸ƒå¼ç¯å¢ƒçš„åˆå§‹åŒ–
    # å‘½ä»¤è¡Œå‚æ•° --local_rank ä¼šç”± deepspeed å¯åŠ¨å‘½ä»¤ä¼ å…¥
    deepspeed.init_distributed()

    # è·å–å½“å‰çš„ rank (è¿›ç¨‹ç¼–å·) å’Œ world_size (æ€»è¿›ç¨‹æ•°)
    rank = torch.distributed.get_rank()
    world_size = torch.distributed.get_world_size()

    print(f"Rank {rank}/{world_size} is initializing...")

    # è®¾ç½®å‚æ•°
    input_dim = 10
    hidden_dim = 256 # å¯ä»¥å¢å¤§ä»¥æ¨¡æ‹Ÿæ›´å¤§çš„æ¨¡å‹
    output_dim = 2
    num_samples_per_rank = 100 # æ¯ä¸ªè¿›ç¨‹å¤„ç†çš„æ•°æ®é‡
    total_samples = num_samples_per_rank * world_size
    # batch_size å’Œ accumulation_steps ä¼šä» JSON æ–‡ä»¶åŠ è½½æˆ– auto æ¨æ–­
    epochs = 5
    learning_rate = 0.001 # æ³¨æ„: å®é™…å­¦ä¹ ç‡å¯èƒ½ä¼šå› ä¸ºä¼˜åŒ–å™¨é…ç½®å’Œ global_batch_size å˜åŒ–

    # åˆ›å»ºæ¨¡å‹
    model = SimpleModel(input_dim, hidden_dim, output_dim)

    # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    # DeepSpeed çš„ initialize å‡½æ•°ä¼šè¿”å›åŒ…è£…å¥½çš„ dataloaderï¼Œ
    # å®ƒå†…éƒ¨ä¼šä½¿ç”¨ DistributedSampler
    dataset = DummyDataset(total_samples, input_dim, output_dim)

    # æŸå¤±å‡½æ•°
    criterion = nn.MSELoss()

    # === DeepSpeed åˆå§‹åŒ– ===
    # ä¼ å…¥æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€æ•°æ®åŠ è½½å™¨ã€æŸå¤±å‡½æ•°ä»¥åŠé…ç½®æ–‡ä»¶è·¯å¾„
    # deepspeed.initialize ä¼šè¿”å› engine, optimizer, data_loader, lr_scheduler
    # DeepSpeed ä¼šæ ¹æ® JSON é…ç½®è‡ªåŠ¨åŒ…è£…æ¨¡å‹ã€ä¼˜åŒ–å™¨å’Œæ•°æ®åŠ è½½å™¨
    # è¿™é‡Œæˆ‘ä»¬å…ˆåˆ›å»ºæ ‡å‡†çš„ optimizerï¼ŒDeepSpeed å†…éƒ¨ä¼šç”¨å®ƒçš„ fused ä¼˜åŒ–å™¨ä»£æ›¿
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)

    # model: PyTorch æ¨¡å‹
    # optimizer: æ ‡å‡† PyTorch ä¼˜åŒ–å™¨ (DeepSpeed ä¼šåŒ…è£…å®ƒ)
    # args: å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œæˆ–å­—å…¸ä¼ å…¥çš„é¢å¤–å‚æ•°ï¼Œè¿™é‡Œç”¨ config= ä¼ å…¥ JSON è·¯å¾„
    # lr_scheduler: (å¯é€‰) æ ‡å‡† PyTorch å­¦ä¹ ç‡è°ƒåº¦å™¨
    # dist_init_required: DeepSpeed >= 0.4.0 é»˜è®¤æ˜¯ Trueï¼Œä¼šè‡ªåŠ¨åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
    engine, optimizer, train_loader, lr_scheduler = deepspeed.initialize(
        model=model,
        optimizer=optimizer,
        args=None, # å¯ä»¥é€šè¿‡ args ä¼ å…¥å‘½ä»¤è¡Œå‚æ•°ï¼Œè¿™é‡Œç”¨ config= æŒ‡å®š JSON
        config="ds_config.json",
        training_data=dataset, # DeepSpeed å¯ä»¥ç›´æ¥ä» dataset åˆ›å»º dataloader
        # training_dataloader=train_loader, # ä¹Ÿå¯ä»¥ä¼ å…¥å·²æœ‰çš„ dataloader
        lr_scheduler=None,
        dist_init_required=True # DeepSpeed >= 0.4.0 é»˜è®¤ True
    )

    print(f"Rank {rank}/{world_size} DeepSpeed engine initialized.")

    # === è®­ç»ƒå¾ªç¯ ===
    print(f"Rank {rank}/{world_size} starting training...")
    for epoch in range(epochs):
        # DeepSpeed çš„ train_loader å†…éƒ¨ä½¿ç”¨äº† DistributedSamplerï¼Œ
        # æ‰€ä»¥éœ€è¦åƒ PyTorch DDP ä¸€æ ·è®¾ç½® epoch
        if hasattr(train_loader.sampler, 'set_epoch'):
             train_loader.sampler.set_epoch(epoch)

        engine.train() # DeepSpeed engine è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼

        total_loss = 0.0
        step_count = 0

        for i, data in enumerate(train_loader):
            inputs, labels = data
            # æ•°æ®ä¼šè‡ªåŠ¨ç§»åŠ¨åˆ°å¯¹åº”çš„ GPU ä¸Š
            inputs, labels = inputs.to(engine.device), labels.to(engine.device)

            # å‰å‘ä¼ æ’­
            outputs = engine(inputs)

            # è®¡ç®—æŸå¤±
            loss = criterion(outputs, labels)

            # åå‘ä¼ æ’­ (ä½¿ç”¨ engine.backward)
            # DeepSpeed ä¼šæ ¹æ® ZeRO é…ç½®å¤„ç†æ¢¯åº¦è®¡ç®—å’ŒåŒæ­¥
            engine.backward(loss)

            # ä¼˜åŒ–å™¨æ­¥è¿› (ä½¿ç”¨ engine.step)
            # DeepSpeed ä¼šæ ¹æ® ZeRO é…ç½®å¤„ç†å‚æ•°æ›´æ–°å’Œåˆ†ç‰‡
            engine.step()

            total_loss += loss.item() * inputs.size(0) # ç´¯åŠ æ ·æœ¬æŸå¤±
            step_count += inputs.size(0) # ç´¯åŠ æ ·æœ¬æ•°

            # æ¯éš”ä¸€æ®µæ—¶é—´æ‰“å°æŸå¤± (åªåœ¨ä¸»è¿›ç¨‹æ‰“å°)
            if (i + 1) % 10 == 0 and rank == 0:
                 print(f"Epoch {epoch+1}, Rank {rank}, Step {i+1}, Loss: {total_loss / step_count:.4f}")
                 total_loss = 0.0
                 step_count = 0


    print(f"Rank {rank}/{world_size} training finished.")

    # === ä¿å­˜å’ŒåŠ è½½æ£€æŸ¥ç‚¹ (å¯é€‰) ===
    # DeepSpeed çš„æ£€æŸ¥ç‚¹ä¼šä¿å­˜æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡è°ƒåº¦å™¨å’Œ ZeRO çŠ¶æ€
    checkpoint_dir = "./deepspeed_checkpoint"
    # åªåœ¨ä¸»è¿›ç¨‹ä¿å­˜
    if rank == 0:
        print(f"Saving checkpoint to {checkpoint_dir}")
        engine.save_checkpoint(checkpoint_dir)

    # åœ¨æ‰€æœ‰è¿›ç¨‹åŒæ­¥ï¼Œç¡®ä¿ä¿å­˜å®Œæˆåå†ç»§ç»­ (å¯é€‰ï¼Œä½†æ¨è)
    torch.distributed.barrier()

    # åŠ è½½æ£€æŸ¥ç‚¹ (åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šè¿›è¡Œ)
    # print(f"Loading checkpoint from {checkpoint_dir}")
    # # tag æ˜¯æ£€æŸ¥ç‚¹çš„åç§°ï¼Œé»˜è®¤ä¸º global step
    # # load_module_strict=False å¦‚æœæ¨¡å‹ç»“æ„æœ‰å¾®å°å˜åŒ–ï¼Œå¯ä»¥è®¾ç½®ä¸º False
    # engine.load_checkpoint(checkpoint_dir, load_module_strict=True)
    # print(f"Rank {rank}/{world_size} checkpoint loaded.")


if __name__ == "__main__":
    main()
```

**Step 3: ä½¿ç”¨ DeepSpeed å‘½ä»¤è¿è¡Œè„šæœ¬**

åœ¨ç»ˆç«¯ä¸­ï¼Œä½¿ç”¨ `deepspeed` å‘½ä»¤æ¥å¯åŠ¨è®­ç»ƒã€‚å‡è®¾ä½ çš„è„šæœ¬åä¸º `train_ds.py`ï¼Œé…ç½®æ–‡ä»¶åä¸º `ds_config.json`ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³åœ¨ä¸¤å— GPU ä¸Šè¿è¡Œï¼š

Bash

```
deepspeed --num_gpus=2 train_ds.py --deepspeed_config ds_config.json
```

**å‘½ä»¤è§£é‡Š:**

- `deepspeed`: DeepSpeed æä¾›çš„å¯åŠ¨å‘½ä»¤ã€‚
- `--num_gpus=2`: æŒ‡å®šä½¿ç”¨ä¸¤å— GPUã€‚DeepSpeed ä¼šå¯åŠ¨ä¸¤ä¸ªè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹ç»‘å®šä¸€ä¸ª GPUã€‚ä½ å¯ä»¥æ ¹æ®ä½ çš„æœºå™¨æ‹¥æœ‰çš„ GPU æ•°é‡ä¿®æ”¹è¿™ä¸ªå‚æ•°ã€‚
- `train_ds.py`: ä½ è¦è¿è¡Œçš„ Python è®­ç»ƒè„šæœ¬ã€‚
- `--deepspeed_config ds_config.json`: æŒ‡å®š DeepSpeed é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚

å¦‚æœä½ æƒ³åœ¨å¤šå°æœºå™¨ä¸Šè¿è¡Œï¼Œå¯åŠ¨å‘½ä»¤ä¼šæ›´å¤æ‚ï¼Œé€šå¸¸æ¶‰åŠ `--num_nodes`ã€`--node_rank`ã€`--master_addr` å’Œ `--master_port` å‚æ•°ï¼Œå¹¶ä¸”éœ€è¦åœ¨æ‰€æœ‰æœºå™¨ä¸Šæ‰§è¡Œç›¸åº”çš„å‘½ä»¤ã€‚

### DeepSpeed ZeRO-3

ç”±äºæ¯ä¸ªGPUç‹¬å ä¸€å±‚parameterï¼Œå› æ­¤å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­æ—¶éœ€è¦å¯¹åº”GPUå¹¿æ’­å¯¹åº”å‚æ•°ï¼š2æ¬¡

æ¢¯åº¦æ”¶é›†ï¼š1

```
æ¯ä¸ªgpuè´Ÿè´£æ›´æ–°å„è‡ªçš„ç½‘ç»œå±‚çš„å‚æ•°ï¼Œå› æ­¤åªéœ€è¦ä¿å­˜å„è‡ªç½‘ç»œå±‚çš„æ¢¯åº¦ï¼›åŒæ—¶åªä¿å­˜å„è‡ªç½‘ç»œå±‚çš„å‚æ•°

è¿‡ç¨‹ï¼š

å‰å‘ä¼ æ’­ï¼š
ç”±äºgpuåªä¿å­˜ä¸€éƒ¨åˆ†ç½‘ç»œå‚æ•°ï¼Œéœ€è¦å¹¿æ’­ï¼›å…¶ä»–gpuæ”¶åˆ°å‚æ•°å¹¶è®¡ç®—åç«‹å³é‡Šæ”¾ç½‘ç»œå‚æ•°ï¼ˆä¸å ç”¨æ˜¾å­˜ï¼‰
åå‘ä¼ æ’­ï¼š
åŒæ ·éœ€è¦ç½‘ç»œå‚æ•°å¹¿æ’­ï¼›å…¶ä»–gpuæ”¶åˆ°å‚æ•°å¹¶è®¡ç®—åç«‹å³é‡Šæ”¾ç½‘ç»œå‚æ•°ï¼ˆä¸å ç”¨æ˜¾å­˜ï¼‰
æ¯ä¸ªgpuè®¡ç®—æ‰€æœ‰çš„æ¢¯åº¦fp16ï¼Œå°†æ¢¯åº¦fp16é›†ä¸­å‘ç»™å¯¹åº”å¤„ç†è¿™å±‚çš„gpuæ›´æ–°æ¢¯åº¦ï¼›
ä¸å¤„ç†è¿™å±‚çš„gpuå‘é€å®Œæ¢¯åº¦fp16åç«‹å³é‡Šæ”¾ï¼ˆä¸å ç”¨æ˜¾å­˜ï¼‰
è¿™æ ·æ¯ä¸ªgpuå°±æœ‰è‡ªå·±è´Ÿè´£çš„ç½‘ç»œå±‚æœ€æ–°çš„æ¢¯åº¦fp16ï¼Œä¹Ÿæœ‰è‡ªå·±è´Ÿè´£çš„ç½‘ç»œå±‚çš„ä¼˜åŒ–å™¨
å°†æ¢¯åº¦fp16ç¼©æ”¾è‡³fp32ï¼Œå¾—åˆ°ä¸€é˜¶äºŒé˜¶åŠ¨é‡ï¼Œæ›´æ–°ä¼˜åŒ–å™¨å¾—åˆ°æœ€æ–°çš„fp32å‚æ•°
æ›´æ–°å„è‡ªä¼˜åŒ–å™¨å¯¹åº”çš„ç½‘ç»œå‚æ•°fp16ï¼Œå¹¿æ’­ç»™å…¶ä»–gpu


å¤§å¤§å‡å°‘äº†æ˜¾å­˜å ç”¨é‡ï¼Œä½†æ˜¯é€šè®¯é‡å˜æˆ1.5å€
```

![image-20250424105044052](pic/image-20250424105044052.png)

![image-20250319224314692](../my_minimind/images/image-20250319224314692.png)

### æ˜¾å­˜èŠ‚çœåˆ†æ

osï¼šzero1

os+gï¼šzero2   å…±äº«gradient

os+g+pï¼šzero3   å…±äº«gradientï¼Œparameter

![image-20250319224347437](../my_minimind/images/image-20250319224347437.png)

### Accelerateä½¿ç”¨

ä½¿ç”¨Accelerateé›†æˆdeepspeedï¼Œé‡‡ç”¨å•æœºå¤šå¡çš„å½¢å¼è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ

```
Accelerateä½¿ç”¨æ­¥éª¤
åˆå§‹åŒ–accelerateå¯¹è±¡accelerator = Accelerator()
è°ƒç”¨prepareæ–¹æ³•å¯¹modelã€dataloaderã€optimizerã€lr_schedluerè¿›è¡Œé¢„å¤„ç†
åˆ é™¤æ‰ä»£ç ä¸­å…³äºgpuçš„æ“ä½œï¼Œæ¯”å¦‚.cuda()ã€.to(device)ç­‰ï¼Œè®©accelerateè‡ªè¡Œåˆ¤æ–­ç¡¬ä»¶è®¾å¤‡çš„åˆ†é…
å°†loss.backbard()æ›¿æ¢ä¸ºaccelerate.backward(loss)
å½“ä½¿ç”¨è¶…è¿‡1ç‰‡GPUè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œåœ¨ä¸»è¿›ç¨‹ä¸­ä½¿ç”¨gatheræ–¹æ³•æ”¶é›†å…¶ä»–å‡ ä¸ªè¿›ç¨‹çš„æ•°æ®ï¼Œç„¶ååœ¨è®¡ç®—å‡†ç¡®ç‡ç­‰æŒ‡æ ‡

ä¹‹åï¼Œåªéœ€è¦é…ç½®ä¸‹accelerateçš„configæ–‡ä»¶ï¼Œä½¿ç”¨accelerate launch --config_file default_config.yaml train.pyå¯åŠ¨è„šæœ¬å¼€å§‹è®­ç»ƒå•¦ï¼


Accelerateï¼šåœ¨æ— éœ€å¤§å¹…ä¿®æ”¹ä»£ç çš„æƒ…å†µä¸‹å®Œæˆå¹¶è¡ŒåŒ–ã€‚åŒæ—¶è¿˜æ”¯æŒDeepSpeedçš„å¤šç§ZeROç­–ç•¥ï¼Œç®€ç›´ä¸è¦å¤ªçˆ½ã€‚

ä»£ç æ•ˆç‡é«˜ï¼Œæ”¯æŒæ— è®ºæ˜¯å•æœºå•å¡è¿˜æ˜¯å¤šæœºå¤šå¡é€‚é…åŒä¸€å¥—ä»£ç ã€‚
å…è®¸åœ¨å•ä¸ªå®ä¾‹ä¸Šè®­ç»ƒæ›´å¤§çš„æ•°æ®é›†ï¼šAccelerate è¿˜å¯ä»¥ä½¿ DataLoaders æ›´é«˜æ•ˆã€‚è¿™æ˜¯é€šè¿‡è‡ªå®šä¹‰é‡‡æ ·å™¨å®ç°çš„ï¼Œå®ƒå¯ä»¥åœ¨è®­ç»ƒæœŸé—´è‡ªåŠ¨å°†éƒ¨åˆ†æ‰¹æ¬¡å‘é€åˆ°ä¸åŒçš„è®¾å¤‡ï¼Œä»è€Œå…è®¸æ¯ä¸ªè®¾å¤‡åªéœ€è¦å‚¨å­˜æ•°æ®çš„ä¸€éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡å°†æ•°æ®å¤åˆ¶å››ä»½å­˜å…¥å†…å­˜ã€‚
æ”¯æŒDeepSpeedï¼šæ— éœ€æ›´æ”¹ä»£ç ï¼Œåªç”¨é…ç½®æ–‡ä»¶å³å¯å¯¹DeepSpeedå¼€ç®±å³ç”¨
```



## æ¢¯åº¦æ£€æŸ¥ç‚¹gradient checkpoint/æ¿€æ´»å€¼æ£€æŸ¥ç‚¹activation checkpoint  

èŠ‚çœæ˜¾å­˜

åå‘ä¼ æ’­æ—¶ç¥ç»ç½‘ç»œé»˜è®¤ä¿å­˜æ‰€æœ‰æ¢¯åº¦ï¼Œgradient checkpointå¯ä»¥é€‰æ‹©æ€§ä¿å­˜ä¸€äº›æ¢¯åº¦æ¥èŠ‚çœæ˜¾å­˜ï¼Œæœªä¿å­˜çš„æ¢¯åº¦å¯ä»¥è®¡ç®—å¾—åˆ°

![image-20250319231033758](../my_minimind/images/image-20250319231033758.png)

## VLLMï¼ˆ**Very Large Language Model Inference Framework**ï¼‰

**é«˜æ•ˆå¤§è¯­è¨€æ¨¡å‹æ¨ç†æ¡†æ¶**

è§£å†³KV cacheæµªè´¹æ˜¾å­˜çš„é—®é¢˜

### PagedAttentionï¼šé”®å€¼ç¼“å­˜çš„åˆ†é¡µç®¡ç†**

ç±»ä¼¼æ“ä½œç³»ç»Ÿ

![image-20250320110026574](../my_minimind/images/image-20250320110026574.png)

![image-20250320110128888](../my_minimind/images/image-20250320110128888.png)

- **é—®é¢˜èƒŒæ™¯**ï¼šä¼ ç»Ÿæ³¨æ„åŠ›æœºåˆ¶åœ¨å¤„ç†é•¿åºåˆ—æ—¶ï¼Œé”®å€¼ï¼ˆKVï¼‰ç¼“å­˜éœ€é¢„åˆ†é…è¿ç»­æ˜¾å­˜ï¼Œå¯¼è‡´æ˜¾å­˜ç¢ç‰‡åŒ–ï¼Œé™åˆ¶å¹¶å‘è¯·æ±‚æ•°å’Œååé‡ã€‚
- è§£å†³æ–¹æ¡ˆ
  - **åˆ†é¡µæœºåˆ¶**ï¼šå°† KV ç¼“å­˜åˆ’åˆ†ä¸ºå›ºå®šå¤§å°çš„â€œå—â€ï¼ˆç±»ä¼¼æ“ä½œç³»ç»Ÿå†…å­˜åˆ†é¡µï¼‰ï¼ŒæŒ‰éœ€åŠ¨æ€åˆ†é…ç‰©ç†å—ï¼Œæ¶ˆé™¤æ˜¾å­˜ç¢ç‰‡ã€‚
  - **é€»è¾‘å—æ˜ å°„è¡¨**ï¼šè®°å½•åºåˆ—ä¸­æ¯ä¸ª token å¯¹åº”çš„ç‰©ç†å—åœ°å€ï¼Œæ”¯æŒéè¿ç»­æ˜¾å­˜çš„é«˜æ•ˆè®¿é—®ã€‚
- **æ•ˆæœ**ï¼šæ˜¾å­˜åˆ©ç”¨ç‡æå‡ **4-5 å€**ï¼Œæ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡ï¼ˆå¦‚ 16K tokensï¼‰å’Œæ›´é«˜å¹¶å‘è¯·æ±‚ã€‚

### sharing kv cache

vLLMçš„SamplingParameteré‡Œæœ‰ä¸ªå‚æ•°nï¼Œ n: Number of output sequences to return for the given prompt. ä¸šåŠ¡åœºæ™¯ï¼šæˆ‘åœ¨ç”Ÿæˆè®­ç»ƒæ•°æ®æ—¶ç»å¸¸ç”¨ï¼Œæ¯”å¦‚Promptæ˜¯é’ˆå¯¹ç»™å®šæ–‡æœ¬ï¼Œæå‡ºä¸€ä¸ªé—®é¢˜ã€‚nè®¾ç½®ä¸º2ã€‚vLLMä¼šç»™ä½ è¿”å›ä¸¤ä¸ªoutputã€‚

ä¾‹å¦‚ä¸‹é¢ç»™å‡ºç¿»è¯‘çš„ä¸¤ç§è¾“å‡º

![image-20250320110742116](../my_minimind/images/image-20250320110742116.png)

### **è¿ç»­æ‰¹å¤„ç†ï¼ˆContinuous Batchingï¼‰**

- **åŠ¨æ€è¯·æ±‚è°ƒåº¦**ï¼šå°†å¤šä¸ªç”¨æˆ·è¯·æ±‚çš„ tokens æ‰“åŒ…ä¸ºç»Ÿä¸€æ‰¹æ¬¡ï¼Œå®æ—¶åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼Œé¿å…ä¼ ç»Ÿé™æ€æ‰¹å¤„ç†çš„ç­‰å¾…å»¶è¿Ÿã€‚
- **ä¼˜åŠ¿**ï¼šGPU åˆ©ç”¨ç‡æå‡ **5-10 å€**ï¼Œå°¤å…¶é€‚åˆæµå¼è¾“å‡ºåœºæ™¯ã€‚

![image-20250319232758455](../my_minimind/images/image-20250319232758455.png)

## Flash Attention

HBM æ˜¯ **High Bandwidth Memory** çš„ç¼©å†™ï¼Œä¸­æ–‡ç§°ä¸º**é«˜å¸¦å®½å†…å­˜**ã€‚å®ƒæ˜¯ä¸€ç§ç”¨äºé«˜æ€§èƒ½è®¡ç®—å’Œå›¾å½¢å¤„ç†çš„é«˜æ€§èƒ½å†…å­˜æŠ€æœ¯ï¼Œä¸»è¦ç”¨äº GPUï¼ˆå›¾å½¢å¤„ç†å™¨ï¼‰ã€AI åŠ é€Ÿå™¨å’Œæ•°æ®ä¸­å¿ƒç­‰é¢†åŸŸã€‚HBM é€šè¿‡å°†å†…å­˜èŠ¯ç‰‡å †å åœ¨ä¸€èµ·ï¼Œå¹¶ä¸å¤„ç†å™¨é€šè¿‡é«˜å¯†åº¦äº’è¿æŠ€æœ¯ç›´æ¥è¿æ¥ï¼Œæ˜¾è‘—æé«˜äº†å†…å­˜å¸¦å®½å’Œèƒ½æ•ˆã€‚

![image-20250320150459317](../my_minimind/images/image-20250320150459317.png)

![image-20250320150630354](../my_minimind/images/image-20250320150630354.png)

1. **åˆ†å—ï¼ˆTilingï¼‰**
   å°†è¾“å…¥åºåˆ—åˆ†ä¸ºå¤šä¸ªå°å—ï¼ˆä¾‹å¦‚æ¯å— 64-128 ä¸ª tokenï¼‰ï¼Œæ¯æ¬¡ä»…å¤„ç†ä¸€å°å—ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½æ•´ä¸ª QKáµ€ çŸ©é˜µã€‚
2. **åœ¨çº¿ Softmax ä¿®æ­£**
   åœ¨åˆ†å—è®¡ç®— Softmax æ—¶ï¼ŒåŠ¨æ€è°ƒæ•´æ¯å—çš„ç»Ÿè®¡é‡ï¼ˆå¦‚æœ€å¤§å€¼å’Œæ±‚å’Œé¡¹ï¼‰ï¼Œç¡®ä¿å…¨å±€ç»“æœçš„æ•°å€¼ç¨³å®šæ€§ã€‚
3. **é‡è®¡ç®—ï¼ˆRecomputationï¼‰**
   åå‘ä¼ æ’­æ—¶ï¼Œé€šè¿‡å­˜å‚¨å°‘é‡å…ƒæ•°æ®ï¼ˆå¦‚éšæœºæ•°ç§å­ï¼‰é‡æ–°ç”Ÿæˆä¸­é—´ç»“æœï¼Œé¿å…æ˜¾å­˜å ç”¨ã€‚

![image-20250320152939108](../my_minimind/images/image-20250320152939108.png)



![image-20250320152958609](../my_minimind/images/image-20250320152958609.png)

![image-20250320163729777](../my_minimind/images/image-20250320163729777.png)

 ![image-20250320163644708](../my_minimind/images/image-20250320163644708.png)

![image-20250320153020336](../my_minimind/images/image-20250320153020336.png)

```
ç®—æ³•æµç¨‹ï¼š
Qi  Br,d
Ki,Vi  Bc,d

m_ijï¼šå­˜å‚¨ç¬¬iè¡Œç¬¬jåˆ—çš„å°å—æ¯ä¸€è¡Œçš„æœ€å¤§å€¼
P_ijï¼šå­˜å‚¨ç¬¬iè¡Œç¬¬jåˆ—çš„å°å—æ¯ä¸€è¡Œçš„exp
l_ijï¼šå­˜å‚¨ç¬¬iè¡Œç¬¬jåˆ—çš„å°å—æ¯ä¸€è¡Œçš„expæ€»å’Œ
O_iï¼šå­˜å‚¨ç¬¬iè¡Œçš„Output
m_i_newï¼šå­˜å‚¨ç¬¬iè¡Œ0åˆ°jåˆ—æ¯ä¸€è¡Œçš„æœ€å¤§å€¼
l_i_newï¼šå­˜å‚¨ç¬¬iè¡Œ0åˆ°jåˆ—æ¯ä¸€è¡Œçš„æ€»å’Œï¼ˆ-m_i_newå› ä¸ºæŒ‡æ•°å‡½æ•°ç»“æœå¾ˆå¤§ï¼Œä¸ºäº†ç¼©å°æ•°æ®ï¼‰

ç¬¬åäºŒè¡Œä»£ç ï¼šç¬¬äºŒä¸ªæ‹¬å·çš„ç¬¬ä¸€éƒ¨åˆ†è®¡ç®—çš„æ˜¯ä»¥å‰çš„Oçš„æ€»å’Œï¼Œç¬¬äºŒéƒ¨åˆ†è®¡ç®—çš„çš„å½“å‰æ–°ç®—å‡ºæ¥çš„Oï¼Œä¹˜ä»¥å¤–é¢çš„é€†çŸ©é˜µç›¸å½“äºé™¤ä»¥sum
```

# é¡¹ç›®æ–‡ä»¶è¯´æ˜

## train_dpo.py

```
å¾—åˆ°modelå’Œref_model
ä¸¤ä¸ªæ“ä½œä¸€è‡´ï¼Œéƒ½æ˜¯ä»sft_modelåŠ è½½å¾—åˆ°
ä½†æ˜¯ref_modeléœ€è¦require_grad=Falseå¹¶ä¸”eval()

# é€‰å‡ºmodel è¾“å‡ºå¯¹åº”yçš„æ¦‚ç‡
æ¨¡å‹çš„è¾“å‡º æ˜¯logits shape: (batch_size, seq_len, vocab_size)
yæ˜¯labels shape: (batch_size, seq_len)
å–å‡ºå¯¹åº”yçš„ä½ç½®çš„logitsçš„å€¼probs shape: (batch_size, seq_len)ï¼›å°±æ˜¯ç­–ç•¥é€‰æ‹©çš„æ¦‚ç‡

# é€‰å‡ºref_modelå¯¹åº”yçš„æ¦‚ç‡
# é€‰å‡ºactor_modelå¯¹åº”yçš„æ¦‚ç‡

# å¸¦å…¥dpo losså…¬å¼è®¡ç®—loss
```

## train_distill_reason.py

```
# sp_idsæ˜¯ä¸€ä¸ªä¸Y.view(-1)å½¢çŠ¶ç›¸åŒçš„boolå½¢çŠ¶çš„å¼ é‡ï¼Œè¡¨ç¤ºYä¸­æ¯ä¸ªå…ƒç´ æ˜¯å¦åœ¨åç»­çš„åˆ—è¡¨ä¸­
sp_ids = torch.isin(Y.view(-1),torch.tensor(start_of_think_ids + end_of_think_ids+ start_of_answer_ids + end_of_answer_ids).to(args.device)) 

# <think></think><answer></answer>è¿™äº›token idçš„lossè®¾ç½®ä¸º10                                           
loss_mask[sp_ids] = 10      
```

## è§†è§‰æ¨¡å‹

```
ä¸ºäº†å¾—åˆ°MiniMind-Vï¼Œæˆ‘ä»¬åªéœ€è¦å®Œæˆè¿™2ä»¶äº‹å³å¯ï¼š

å€ŸåŠ©æ“…é•¿ç¿»è¯‘å›¾ç‰‡çš„ "å¤–è¯­è¯å…¸" ï¼ŒæŠŠå›¾ç‰‡ä» "å¤–å›½è¯­è¨€" ç¿»è¯‘ä¸ºæ¨¡å‹ä¾¿äºç†è§£çš„ "LLMè¯­è¨€"
è®­ç»ƒå¾®è°ƒLLMï¼Œä½¿å…¶å’Œ "å¤–è¯­è¯å…¸" åº¦è¿‡ç£¨åˆæœŸï¼Œä»è€Œæ›´å¥½çš„ç†è§£å›¾ç‰‡
"å¤–è¯­è¯å…¸" ç§°ä¹‹ä¸ºVisual Encoderæ¨¡å‹ã€‚ å’ŒLlaVAã€Qwen-VLç­‰è§†è§‰è¯­è¨€æ¨¡å‹ç±»ä¼¼ï¼ŒMiniMind-VåŒæ ·é€‰ç”¨å¼€æºClipç³»åˆ—æ¨¡å‹ä½œä¸ºVisual Encoderã€‚ 
å…·ä½“ä½¿ç”¨clip-vit-base-patch16ï¼Œ ä¸€ç§åŸºäº ViT-B/16 æ¶æ„çš„ç»å…¸Visual Encoderç”¨äºæè¿°å›¾åƒæ–‡æœ¬ä¿¡æ¯ã€‚ 
è¾“å…¥çš„å›¾åƒå°ºå¯¸ä¸º224x224ï¼Œå› ä¸ºåˆ’åˆ†çš„Patchæ˜¯16Ã—16ï¼Œæ‰€ä»¥ä¼šäº§ç”Ÿ14*14=196ä¸ªtokenä½œä¸ºencoderç¼–ç å±‚çš„è¾“å…¥ï¼Œ æœ€ç»ˆäº§ç”Ÿ1Ã—768ç»´çš„åµŒå…¥å‘é‡ç”¨äºå’Œæ–‡æœ¬å¯¹è®¡ç®—è¯¯å·®ã€‚ 
æˆ‘ä»¬å¹¶ä¸éœ€è¦æœ€ç»ˆåµŒå…¥è¡¨ç¤ºï¼Œå› æ­¤åªå–encoderå±‚çš„è¾“å‡ºï¼Œä¹Ÿå°±æ˜¯VITæ ¸å¿ƒä¸»å¹²çš„è¾“å‡ºç‰¹å¾å³å¯ã€‚ 
å®ƒæ‹¿åˆ°å‰ä¸€å±‚ç»´åº¦196Ã—768å¤§å°çš„ç‰¹å¾ï¼Œæˆ‘ä»¬æŠŠå®ƒä½œä¸º196ä¸ªvisual tokenè¾“å…¥MiniMind-Vã€‚ 
ä¸LLMçš„ç»“åˆåœ¨è·å–å›¾åƒencoderç‰¹å¾åï¼Œä¸€æ–¹é¢éœ€è¦æŠŠ768ç»´åº¦çš„visual tokenå¯¹é½åˆ°LLMçš„æ–‡æœ¬tokenï¼Œ 
å¦ä¸€æ–¹é¢ï¼Œè¦å°†å›¾åƒç‰¹å¾æ˜ å°„åˆ°ä¸æ–‡æœ¬embeddingç›¸åŒçš„ç©ºé—´ï¼Œå³æ–‡æœ¬tokenå’ŒåŸç”Ÿçš„è§†è§‰tokenéœ€è¦ç£¨åˆå¹¶ä¸èƒ½ç›´æ¥åœ°ä¸€è§†åŒä»ï¼Œ å¯ä»¥ç§°ä¹‹ä¸ºè·¨æ¨¡æ€çš„ç‰¹å¾å¯¹é½ã€‚
LlaVA-1ä½¿ç”¨ç®€å•çš„æ— åçº¿æ€§å˜æ¢å®Œæˆäº†è¿™ä¸€æ“ä½œï¼Œæ•ˆæœå¾ˆä¸é”™ï¼ŒMiniMind-VåŒæ ·å¦‚æ­¤ã€‚





ä¸‹é¢ï¼Œæˆ‘ä»¬ç®€å•è®¨è®ºMiniMind-Vçš„å¤–éƒ¨è¾“å…¥è¾“å‡ºçš„å˜åŒ–ã€‚

VLMçš„è¾“å…¥ä¾ç„¶æ˜¯ä¸€æ®µæ–‡æœ¬ï¼Œå…¶ä¸­åŒ…å«ç‰¹æ®Šçš„å ä½ç¬¦ã€‚ åœ¨è®¡ç®—æ–‡æœ¬åµŒå…¥åï¼Œå¯ä»¥å°†å›¾åƒç¼–ç å™¨ç”Ÿæˆçš„å‘é‡æŠ•å½±åˆ°è¯¥å ä½ç¬¦å¯¹åº”çš„åµŒå…¥éƒ¨åˆ†ï¼Œæ›¿æ¢æ‰åŸå…ˆçš„å ä½ç¬¦embeddingã€‚ ä¾‹å¦‚ï¼š

<image>\nè¿™ä¸ªå›¾åƒä¸­æœ‰ä»€ä¹ˆå†…å®¹ï¼Ÿ
åœ¨minimind-vä¸­ï¼Œä½¿ç”¨196ä¸ªå­—ç¬¦ç»„æˆçš„ @@@...@@@ å ä½ç¬¦ä»£æ›¿å›¾åƒï¼Œä¹‹æ‰€ä»¥æ˜¯196ä¸ªå­—ç¬¦ï¼Œå‰é¢æœ‰æ‰€æåŠï¼š ä»»ä½•å›¾åƒéƒ½è¢«clipæ¨¡å‹encoderä¸º196Ã—768ç»´çš„tokenï¼Œ å› æ­¤minimind-vçš„promptä¸ºï¼š

@@@......@@@\nè¿™ä¸ªå›¾ç‰‡æè¿°çš„æ˜¯ä»€ä¹ˆå†…å®¹ï¼Ÿ
è®¡ç®—å®Œembeddingå’Œprojectionï¼Œå¹¶å¯¹å›¾åƒéƒ¨åˆ†tokenæ›¿æ¢åæ•´ä¸ªè®¡ç®—è¿‡ç¨‹åˆ°è¾“å‡ºåˆ™å’ŒLLMéƒ¨åˆ†æ²¡æœ‰ä»»ä½•åŒºåˆ«ã€‚
```

![minimind-v-input](pic/minimind-v-input.png)

![llava-structure](pic/llava-structure.png)

## VLMDataset

```
è¾“å…¥ï¼šå›¾åƒå†…å®¹\n<image>
chat templateï¼šæ›¿æ¢<image>ä¸ºæ ‡è®°çš„ç‰¹æ®Šå­—ç¬¦ä¸²ï¼ˆ196ä¸ª'@'å¯¹åº”ViTçš„196ä¸ªå›¾åƒå—,è¿™äº›ä½ç½®æ˜¯æ¨¡å‹çš„è¾“å‡ºï¼‰
å›¾åƒå†…å®¹\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@(196ä¸ª'@)

```

## model_vlm.py

```
VisionProjç±»å°†è§†è§‰ç¼–ç å™¨è¾“å‡ºç»´åº¦æŠ•å½±åˆ°è¯­è¨€æ¨¡å‹éšå±‚ç»´åº¦


æŸ¥æ‰¾æ›¿æ¢ä½ç½® (find_indices)
ä½¿ç”¨ unfold åˆ›å»ºæ»‘åŠ¨çª—å£ï¼Œæ£€æµ‹æ–‡æœ¬ä¸­è¿ç»­ image_ids çš„ä½ç½®ï¼ˆå¦‚ @@@@...ï¼‰ã€‚

æŠ•å½±å›¾åƒåµŒå…¥
é€šè¿‡ self.vision_proj å°†è§†è§‰ç‰¹å¾ï¼ˆå¦‚ CLIP çš„ 768 ç»´ï¼‰æŠ•å½±åˆ°è¯­è¨€æ¨¡å‹ç»´åº¦ï¼ˆå¦‚ 512 ç»´ï¼‰ã€‚

åµŒå…¥æ›¿æ¢
å¯¹æ¯ä¸ªæ‰¹æ¬¡çš„åµŒå…¥ï¼Œæ ¹æ® image_indices æ‰¾åˆ°çš„ä½ç½®ï¼Œç”¨å›¾åƒåµŒå…¥æ›¿æ¢æ–‡æœ¬ä¸­çš„ç‰¹æ®Šæ ‡è®°ã€‚
```

## train_pretrain_vlm.py

```
# å†»ç»“é™¤ vision_proj å¤–çš„æ‰€æœ‰å‚æ•°
è§†è§‰ç¼–ç å™¨çš„å‚æ•°é€šå¸¸æ˜¯å†»ç»“çš„ï¼Œå³ä¸è¿›è¡Œæ›´æ–°ã€‚è¿™æ˜¯å› ä¸ºé¢„è®­ç»ƒçš„è§†è§‰ç¼–ç å™¨å·²ç»å…·å¤‡äº†å¼ºå¤§çš„å›¾åƒç†è§£èƒ½åŠ›ï¼Œå†»ç»“å®ƒå¯ä»¥ä¿ç•™è¿™äº›èƒ½åŠ›ï¼Œå¹¶å‡å°‘éœ€è¦è®­ç»ƒçš„å‚æ•°æ•°é‡ã€‚

# è§£å†»æœ€åä¸¤å±‚transformers blockçš„å‚æ•°
LLaVA çš„åŸå§‹ç‰ˆæœ¬é€šå¸¸æ˜¯å†»ç»“è¯­è¨€æ¨¡å‹å¹¶è®­ç»ƒæŠ•å½±å±‚å’Œå°‘é‡å…¶ä»–å‚æ•°ã€‚
```

# LLM-book

## è®­ç»ƒè¿‡ç¨‹

å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹å¯ä»¥åˆ†ä¸º**å¤§è§„æ¨¡é¢„è®­ç»ƒ**å’Œ**æŒ‡ä»¤å¾®è°ƒä¸äººç±»å¯¹é½**ä¸¤ä¸ªé˜¶æ®µ

ç»è¿‡å¤§è§„æ¨¡æ•°æ®**é¢„è®­ç»ƒ**åçš„è¯­è¨€æ¨¡å‹å·²ç»å…·å¤‡è¾ƒå¼ºçš„æ¨¡å‹èƒ½åŠ›ï¼Œèƒ½å¤Ÿç¼–ç ä¸°

å¯Œçš„ä¸–ç•ŒçŸ¥è¯†ï¼Œä½†æ˜¯ç”±äºé¢„è®­ç»ƒä»»åŠ¡å½¢å¼æ‰€é™ï¼Œè¿™äº›æ¨¡å‹æ›´æ“…é•¿äºæ–‡æœ¬è¡¥å…¨ï¼Œå¹¶ä¸é€‚åˆç›´æ¥è§£å†³å…·ä½“çš„ä»»åŠ¡ã€‚

**â€œæŒ‡ä»¤å¾®è°ƒâ€**ï¼ˆä¹Ÿå«åšæœ‰ç›‘ç£å¾®è°ƒï¼ŒSupervised Fine-tuning, SFTï¼‰ï¼Œé€šè¿‡ä½¿ç”¨ä»»åŠ¡è¾“å…¥ä¸è¾“å‡ºçš„é…å¯¹æ•°æ®è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œå¯ä»¥ä½¿å¾—è¯­è¨€æ¨¡å‹è¾ƒå¥½åœ°æŒæ¡é€šè¿‡é—®ç­”å½¢å¼è¿›è¡Œä»»åŠ¡æ±‚è§£çš„èƒ½åŠ›ã€‚

åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ å¯¹é½æ–¹æ³• **RLHF**ï¼ˆReinforcement Learning from Human Feedbackï¼‰ï¼Œåœ¨æŒ‡ä»¤å¾®è°ƒåä½¿ç”¨å¼ºåŒ–å­¦ä¹ åŠ å¼ºæ¨¡å‹çš„å¯¹é½èƒ½åŠ›ã€‚

è®­ç»ƒä¸€ä¸ªç¬¦åˆäººç±»ä»·å€¼è§‚çš„å¥–åŠ±æ¨¡å‹ï¼ˆReward Modelï¼‰ã€‚

## é¢„è®­ç»ƒ

### **å¯æ‰©å±•çš„è®­ç»ƒæŠ€æœ¯**

#### **3D** **å¹¶è¡Œè®­ç»ƒ**

å³æ•°æ®å¹¶è¡Œï¼ˆDataParallelismï¼‰ã€æµæ°´çº¿å¹¶è¡Œï¼ˆPipeline Parallelismï¼‰å’Œå¼ é‡å¹¶è¡Œï¼ˆTensor Parallelismï¼‰ã€‚

![image-20250329110122884](pic/image-20250329110122884.png)

```
â€¢ æ•°æ®å¹¶è¡Œ. æ•°æ®å¹¶è¡Œæ˜¯ä¸€ç§æé«˜è®­ç»ƒååé‡çš„æ–¹æ³•ï¼Œå®ƒå°†æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨
çŠ¶æ€å¤åˆ¶åˆ°å¤šä¸ª GPU ä¸Šï¼Œç„¶åå°†è®­ç»ƒæ•°æ®å¹³å‡åˆ†é…åˆ°è¿™äº› GPU ä¸Šã€‚è¿™æ ·ï¼Œæ¯ä¸ªGPU åªéœ€è¦å¤„ç†åˆ†é…ç»™å®ƒçš„æ•°æ®ï¼Œç„¶åæ‰§è¡Œå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ä»¥è·å–æ¢¯åº¦ã€‚å½“æ‰€æœ‰ GPU éƒ½æ‰§è¡Œå®Œæ¯•åï¼Œè¯¥ç­–ç•¥ä¼šå°†ä¸åŒ GPU çš„æ¢¯åº¦è¿›è¡Œå¹³å‡ï¼Œä»¥å¾—åˆ°æ•´ä½“çš„æ¢¯åº¦æ¥ç»Ÿä¸€æ›´æ–°æ‰€æœ‰ GPU ä¸Šçš„æ¨¡å‹å‚æ•°ã€‚
â€¢ æµæ°´çº¿å¹¶è¡Œ. æµæ°´çº¿å¹¶è¡Œæ—¨åœ¨å°†å¤§è¯­è¨€æ¨¡å‹ä¸åŒå±‚çš„å‚æ•°åˆ†é…åˆ°ä¸åŒçš„GPU ä¸Šã€‚åœ¨å®è·µä¸­ï¼Œå¯ä»¥å°† Transformer è¿ç»­çš„å±‚åŠ è½½åˆ°åŒä¸€ GPU ä¸Šï¼Œä»¥å‡å°‘
GPU ä¹‹é—´ä¼ è¾“éšè—çŠ¶æ€æˆ–æ¢¯åº¦çš„æˆæœ¬ã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾ 6.3 (d) ä¸­Transformer çš„ç¬¬ 1-2å±‚éƒ¨ç½²åœ¨ 1 å· GPUï¼Œå°† 3-4 å±‚éƒ¨ç½²åœ¨ 2 å· GPUã€‚ç„¶è€Œï¼Œæœ´ç´ çš„æµæ°´çº¿è°ƒåº¦å¹¶ä¸èƒ½è¾¾åˆ°çœŸæ­£çš„å¹¶è¡Œæ•ˆæœã€‚ä»¥å›¾ 6.3 (d) ä¸ºä¾‹ï¼Œ1 å· GPU åœ¨å‰å‘ä¼ æ’­åéœ€è¦ç­‰å¾… 2 å· GPUåå‘ä¼ æ’­çš„ç»“æœæ‰èƒ½è¿›è¡Œæ¢¯åº¦ä¼ æ’­ï¼Œå› æ­¤æ•´ä¸ªæµç¨‹æ˜¯â€œ1 å·å‰å‘-2 å·å‰å‘-2 å·åå‘-1 å·åå‘â€çš„ä¸²è¡Œæ“ä½œï¼Œå¤§å¤§é™ä½äº† GPU çš„åˆ©ç”¨ç‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæµæ°´çº¿å¹¶è¡Œé€šå¸¸éœ€è¦é…åˆæ¢¯åº¦ç´¯ç§¯ï¼ˆGradient Accumulationï¼‰æŠ€æœ¯è¿›è¡Œä¼˜åŒ–ã€‚è¯¥æŠ€æœ¯çš„ä¸»è¦æ€æƒ³æ˜¯ï¼Œè®¡ç®—ä¸€ä¸ªæ‰¹æ¬¡çš„æ¢¯åº¦åä¸ç«‹åˆ»æ›´æ–°æ¨¡å‹å‚æ•°ï¼Œè€Œæ˜¯ç´¯ç§¯å‡ ä¸ªæ‰¹æ¬¡åå†æ›´æ–°ï¼Œè¿™æ ·ä¾¿å¯ä»¥åœ¨ä¸å¢åŠ æ˜¾å­˜æ¶ˆè€—çš„æƒ…å†µä¸‹æ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹æ¬¡ã€‚åœ¨æµæ°´çº¿å¹¶è¡Œä¸­ä½¿ç”¨äº†æ¢¯åº¦ç´¯ç§¯åï¼Œ1 å·å¡å‰å‘ä¼ æ’­å®Œç¬¬ä¸€ä¸ªæ‰¹æ¬¡åï¼Œä¾¿å¯ä»¥ä¸ç”¨ç­‰å¾…ï¼Œç»§ç»­ä¼ æ’­ç¬¬äºŒä¸ªå’Œåç»­çš„æ‰¹æ¬¡ï¼Œä»è€Œæé«˜äº†æµæ°´çº¿çš„æ•ˆç‡ã€‚
â€¢ å¼ é‡å¹¶è¡Œ. å¼ é‡å¹¶è¡Œä¸æµæ°´çº¿å¹¶è¡Œæ˜¯ä¸¤ç§å°†å¤§æ¨¡å‹å‚æ•°åŠ è½½åˆ°å¤šä¸ª GPU ä¸Š
çš„è®­ç»ƒæŠ€æœ¯ã€‚æµæ°´çº¿å¹¶è¡Œä¾§é‡äºå°†æ¨¡å‹çš„ä¸åŒå±‚åˆ†é…åˆ°ä¸åŒçš„ GPU ä¸Šã€‚ç›¸è¾ƒä¹‹ä¸‹ï¼Œå¼ é‡å¹¶è¡Œçš„åˆ†é…ç²’åº¦æ›´ç»†ï¼Œå®ƒè¿›ä¸€æ­¥åˆ†è§£äº†æ¨¡å‹çš„å‚æ•°å¼ é‡ï¼ˆå³å‚æ•°çŸ©é˜µï¼‰ï¼Œä»¥ä¾¿æ›´é«˜æ•ˆåœ°åˆ©ç”¨å¤šä¸ª GPU çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›ã€‚å…·ä½“åœ°ï¼Œå¯¹äºå¤§è¯­è¨€æ¨¡å‹ä¸­çš„æŸä¸ªçŸ©é˜µä¹˜æ³•æ“ä½œ ğ‘¾ğ‘¯ï¼Œå‚æ•°çŸ©é˜µ ğ‘¾ å¯ä»¥æŒ‰åˆ—åˆ†æˆä¸¤ä¸ªå­çŸ©é˜µ ğ‘¾1 å’Œ ğ‘¾2ï¼Œè¿›è€ŒåŸå¼å¯ä»¥è¡¨ç¤ºä¸º [ğ‘¾1ğ‘¯, ğ‘¾2ğ‘¯]ã€‚ç„¶åï¼Œå¯ä»¥å°†å‚æ•°çŸ©é˜µ ğ‘¾1 å’Œ ğ‘¾2 æ”¾ç½®åœ¨ä¸¤å¼ ä¸åŒçš„ GPUä¸Šï¼Œç„¶åå¹¶è¡Œåœ°æ‰§è¡Œä¸¤ä¸ªçŸ©é˜µä¹˜æ³•æ“ä½œï¼Œæœ€åé€šè¿‡è·¨ GPU é€šä¿¡å°†ä¸¤ä¸ª GPU çš„è¾“å‡ºç»„åˆæˆæœ€ç»ˆç»“æœã€‚å¸¸è§çš„å¼ é‡å¹¶è¡Œç­–ç•¥æ˜¯åˆ†è§£æ¨¡å‹æ³¨æ„åŠ›å±‚çš„ ğ‘¾ğ‘„ï¼Œğ‘¾ğ¾ï¼Œğ‘¾ğ‘‰ï¼Œğ‘¾ğ‘‚ çŸ©é˜µå‚æ•°å’Œå‰é¦ˆç½‘ç»œå±‚çš„ ğ‘¾ğ‘ˆï¼Œğ‘¾ğ· çŸ©é˜µå‚æ•°ã€‚
```

#### **é›¶å†—ä½™ä¼˜åŒ–å™¨**

é›¶å†—ä½™ä¼˜åŒ–å™¨ï¼ˆZero Redundancy Optimizer, ZeROï¼‰**ä¸»è¦ç”¨äºè§£å†³æ•°æ®å¹¶è¡Œä¸­çš„æ¨¡å‹å†—ä½™é—®é¢˜**ï¼Œå³æ¯å¼  GPU å‡éœ€è¦å¤åˆ¶ä¸€ä»½æ¨¡å‹å‚æ•°ã€‚åœ¨å›¾ 6.3 (a) ä¸­å¯ä»¥çœ‹åˆ°ï¼Œæ•°æ®å¹¶è¡Œæ—¶æ¯ä¸ª GPU éƒ½éœ€è¦å­˜å‚¨å¤§è¯­è¨€æ¨¡å‹çš„ç›¸åŒå‰¯æœ¬ï¼ŒåŒ…æ‹¬æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨å‚æ•°ç­‰ã€‚å¯¹äºæ¯ä¸ª GPUï¼Œåœ¨æ¨¡å‹ä¼ æ’­åˆ°æŸä¸€å±‚æ—¶ï¼Œå…¶ä»–å±‚çš„æ¨¡å‹å’Œä¼˜åŒ–å™¨å‚æ•°å¹¶ä¸å‚æ•°è®¡ç®—ï¼Œè¿™å¯¼è‡´äº†ä¸¥é‡çš„æ˜¾å­˜å†—ä½™ç°è±¡ï¼ŒåŒæ—¶ä¹Ÿé™åˆ¶äº†æ¯ä¸ª GPU å¯ä»¥æ”¯æŒçš„å‰å‘ä¼ æ’­æ•°æ®é‡ï¼Œé™ä½äº†è®­ç»ƒæ•ˆç‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œ**ZeRO æŠ€æœ¯ä»…åœ¨æ¯ä¸ª GPU ä¸Šä¿ç•™éƒ¨åˆ†æ¨¡å‹å‚æ•°å’Œä¼˜åŒ–å™¨å‚æ•°ï¼Œå½“éœ€è¦æ—¶å†ä»å…¶å®ƒ GPU ä¸­è¯»å–**ã€‚å¦‚å›¾ 6.3 (b) æ‰€ç¤ºï¼Œæ¨¡å‹è¢«å‡åˆ†åœ¨ä¸¤å¼  GPU ä¸Šï¼Œå½“éœ€è¦ä½¿ç”¨ç¬¬ä¸€å±‚è®¡ç®—æ—¶ï¼Œä¸¤å¼ å¡åˆ†åˆ«ä»å¯¹æ–¹è·å–ç›¸åº”çš„æ¨¡å‹å‚æ•°è¿›è¡Œè®¡ç®—ï¼Œä½¿ç”¨å®Œä¹‹åä¾¿å¯ä»¥é‡Šæ”¾ç›¸åº”æ˜¾å­˜ï¼Œä»è€Œé™ä½äº†æ˜¾å­˜å†—ä½™åº¦ã€‚

#### **æ¿€æ´»é‡è®¡ç®—**

æ¿€æ´»é‡è®¡ç®—ï¼ˆActivation Recomputationï¼‰ï¼Œä¹Ÿç§°ä¸ºæ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆGradient Checkpointingï¼‰ï¼Œæ˜¯ä¸€ç§ç”¨äºä¼˜åŒ–åå‘ä¼ æ’­æ—¶æ˜¾å­˜å ç”¨çš„æŠ€æœ¯ã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€ä¸ªå¾…ä¼˜åŒ–å‡½æ•° *ğ’€* = *ğ‘¿ğ‘¾*ï¼Œåœ¨åå‘ä¼ æ’­æ—¶éœ€è¦ *ğ‘¿* çš„å€¼æ‰èƒ½è®¡ç®— *ğ‘¾* çš„å¯¼æ•°ï¼Œæ‰€ä»¥åœ¨å‰å‘ä¼ æ’­æ—¶éœ€è¦ä¿ç•™è¿™äº› *ğ‘¿*ï¼ˆé€šå¸¸è¢«ç§°ä¸ºæ¿€æ´»å€¼ï¼‰ã€‚ç„¶è€Œï¼Œä¿å­˜æ¯ä¸€å±‚æ‰€æœ‰çš„æ¿€æ´»å€¼éœ€è¦å ç”¨å¤§é‡çš„æ˜¾å­˜èµ„æºï¼ˆå…·ä½“çš„æ˜¾å­˜å ç”¨è§ç¬¬ 6.4.4 èŠ‚ï¼‰ã€‚å› æ­¤ï¼Œæ¿€æ´»é‡è®¡ç®—æŠ€æœ¯åœ¨å‰å‘ä¼ æ’­æœŸé—´ä»…ä¿ç•™éƒ¨åˆ†çš„æ¿€æ´»å€¼ï¼Œç„¶ååœ¨åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—è¿™äº›æ¿€æ´»å€¼ï¼Œä»¥è¾¾åˆ°èŠ‚çº¦æ˜¾å­˜çš„ç›®çš„ï¼Œä½†æ˜¯åŒæ—¶ä¹Ÿä¼šå¼•å…¥é¢å¤–çš„è®¡ç®—å¼€é”€ã€‚åœ¨å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¿€æ´»é‡è®¡ç®—çš„å¸¸è§æ–¹æ³•æ˜¯å°† Transformer çš„æ¯ä¸€å±‚çš„è¾“å…¥ä¿å­˜ä¸‹æ¥ï¼Œç„¶ååœ¨åå‘ä¼ æ’­æ—¶è®¡ç®—å¯¹åº”å±‚å†…çš„æ¿€æ´»å€¼ã€‚

#### **æ··åˆç²¾åº¦è®­ç»ƒ**

é€šè¿‡åŒæ—¶ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°ï¼ˆ2 ä¸ªå­—èŠ‚ï¼‰å’Œå•ç²¾åº¦æµ®ç‚¹æ•°ï¼ˆ4 ä¸ªå­—èŠ‚ï¼‰è¿›è¡Œè¿ç®—ï¼Œä»¥å®ç°æ˜¾å­˜å¼€é”€å‡åŠã€è®­ç»ƒæ•ˆç‡ç¿»å€çš„æ•ˆæœã€‚ä¸ºäº†ä¿è¯è¡¨ç¤ºç²¾åº¦ï¼Œéœ€è¦ä¿ç•™åŸå§‹ 32 ä½æ¨¡å‹çš„å‚æ•°å‰¯æœ¬ã€‚ä½†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šå…ˆå°†è¿™äº› 32 ä½å‚æ•°è½¬æ¢ä¸º 16 ä½å‚æ•°ï¼Œéšåä»¥ 16 ä½ç²¾åº¦æ‰§è¡Œå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ç­‰æ“ä½œï¼Œæœ€ååœ¨å‚æ•°æ›´æ–°æ—¶å†å¯¹ 32 ä½æ¨¡å‹è¿›è¡Œä¼˜åŒ–ã€‚ç”±äºåœ¨æ¨¡å‹è®­ç»ƒä¸­å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­å ç”¨äº†ç»å¤§éƒ¨åˆ†ä¼˜åŒ–æ—¶é—´ï¼Œæ··åˆç²¾åº¦è®­ç»ƒå› è€Œèƒ½å¤Ÿæ˜¾è‘—æå‡æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡ã€‚

### **æ¨¡å‹å‚æ•°é‡è®¡ç®—ä¸æ•ˆç‡åˆ†æ**

#### **å‚æ•°é‡è®¡ç®—**

ç”±äºå½“å‰ä¸»æµçš„å¤§æ¨¡å‹æ™®éé‡‡ç”¨å› æœè§£ç å™¨æ¶æ„ï¼Œå› æ­¤ä¸‹é¢ä»¥ LLaMA æ¨¡å‹ä¸ºèŒƒä¾‹ï¼Œæ·±å…¥å‰–æå…¶å‚æ•°æ•°é‡è®¡ç®—æ–¹å¼ã€‚é¦–å…ˆï¼Œå‡è®¾è¯è¡¨å¤§å°ä¸º *ğ‘‰*ï¼Œæ¨¡å‹åŒ…å« *ğ¿* å±‚è§£ç å™¨ï¼Œä¸­é—´çŠ¶æ€çš„ç»´åº¦å¤§å°ä¸º *ğ»*ï¼Œå‰é¦ˆç½‘ç»œå±‚çš„ä¸­é—´çŠ¶æ€ç»´åº¦å¤§å°ä¸º *ğ»* â€²ã€‚æˆ‘ä»¬ä¸»è¦å…³æ³¨è®¡ç®—ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†çš„å‚æ•°é‡ï¼š

![image-20250329111758960](pic/image-20250329111758960.png)

![image-20250329111810677](pic/image-20250329111810677.png)

#### **è®­ç»ƒè¿ç®—é‡ä¼°è®¡**

æ¨¡å‹è®­ç»ƒè¿ç®—é‡æŒ‡çš„æ˜¯æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œéœ€è¦è¿›è¡Œçš„æµ®ç‚¹è¿ç®—æ¬¡æ•°ï¼ˆFloatingPoint Operations, FLOPï¼‰ã€‚è¿™é‡Œçš„æµ®ç‚¹è¿ç®—åŒ…æ‹¬æµ®ç‚¹æ•°çš„åŠ å‡ä¹˜é™¤è¿ç®—ï¼Œä»¥åŠæµ®ç‚¹æ•°çš„æŒ‡æ•°å‡½æ•°ï¼Œå¯¹æ•°å‡½æ•°ï¼Œä¸‰è§’å‡½æ•°ç­‰è¿ç®—æ“ä½œã€‚ä½¿ç”¨ Transformer æ¶æ„è¿›è¡Œè®­ç»ƒçš„è¿ç®—é‡ä¸»è¦é›†ä¸­åœ¨å¤šå¤´æ³¨æ„åŠ›è®¡ç®—å’Œçº¿æ€§å˜æ¢è®¡ç®—ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå½’ä¸€åŒ–ã€è¾“å‡ºæ˜ å°„å’Œæ—‹è½¬ä½ç½®ç¼–ç è®¡ç®—æ‰€éœ€çš„è¿ç®—é‡è¾ƒå°‘ï¼Œè€Œè¾“å…¥ç¼–ç å±‚åˆ™æ— éœ€è®¡ç®—ï¼Œå› æ­¤åç»­çš„åˆ†æä¸­çœç•¥äº†è¿™äº›éƒ¨åˆ†ã€‚åœ¨åˆ†æå¤šå¤´æ³¨æ„åŠ›å’Œçº¿æ€§å˜æ¢çš„è¿ç®—é‡æ—¶ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥è®¾å®šä»¥ä¸‹å‚æ•°ï¼šæ¨¡å‹æ€»å‚æ•°é‡ä¸º *ğ‘ƒ*ï¼Œæ‰¹å¤„ç†å¤§å°ä¸º *ğµ*ï¼Œè¾“å…¥åºåˆ—é•¿åº¦ä¸º *ğ‘‡*ï¼Œå› æ­¤è®­ç»ƒè¯å…ƒæ€»æ•°ä¸º *ğ¶* = *ğµğ‘‡*ï¼›å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶åŒ…å« *ğ‘* ä¸ªå¤´ï¼Œæ¯ä¸ªå¤´çš„ç»´åº¦ä¸º *ğ·*ï¼Œå› æ­¤å’Œä¸­é—´çŠ¶æ€ç»´åº¦ *ğ»* æ»¡è¶³å…³ç³» *ğ»* = *ğ‘ğ·*ã€‚å…¶å®ƒå®šä¹‰ä¸å‚æ•°é‡è®¡ç®—ä¸€èŠ‚ 6.4.1 ä¿æŒä¸€è‡´ã€‚

**çŸ©é˜µä¹˜æ³•è¿ç®—é‡**

çŸ©é˜µ *ğ‘¨* âˆˆ R *ğ‘›*Ã—*ğ‘š* å’ŒçŸ©é˜µ *ğ‘©* âˆˆ R *ğ‘š*Ã—*ğ‘* ç›¸ä¹˜æ‰€éœ€çš„è¿ç®—é‡ä¸º 2*ğ‘›ğ‘š ğ‘*ã€‚

```
æ¯ä¸€è¡Œä¹˜ä»¥æ¯ä¸€åˆ—éœ€è¦mæ¬¡ï¼Œç›¸åŠ éœ€è¦mæ¬¡
æ¯ä¸€è¡Œä¹˜ä»¥çŸ©é˜µBæ€»å…±éœ€è¦2mpæ¬¡
Aä¹˜ä»¥çŸ©é˜µBæ€»å…±éœ€è¦2nmpæ¬¡
```

![image-20250329140112459](pic/image-20250329140112459.png)

```
åå‘ä¼ æ’­çš„è¿ç®—é‡å¤§è‡´ä¸ºå‰å‘ä¼ çš„ä¸¤å€ï¼š
è€ƒè™‘åˆ° Transformer ç»“æ„ä¸­å¤§å¤šæ•°è¿ç®—ä¸ºäºŒå…ƒè¿ç®—ï¼ˆå¦‚ä¸¤ä¸ªçŸ©é˜µç›¸ä¹˜ï¼‰ï¼Œéœ€è¦åˆ†åˆ«è®¡ç®—æŸå¤±å¯¹ä¸¤ä¸ªçŸ©
é˜µçš„æ¢¯åº¦ï¼ˆå¯¹æƒé‡æ¢¯åº¦ï¼›å¯¹è¾“å…¥æ¢¯åº¦ ï¼‰ï¼Œå› æ­¤éœ€è¦ä¸¤å€çš„è¿ç®—é‡ã€‚
å¯¹è¾“å…¥æ¢¯åº¦ï¼š
å³ä½¿è¾“å…¥æ•°æ®æœ¬èº«ä¸éœ€è¦æ›´æ–°ï¼ˆå¦‚è®­ç»ƒé›†ä¸­çš„æ ·æœ¬ï¼‰ï¼Œå…¶æ¢¯åº¦ä»éœ€è®¡ç®—ï¼Œä»¥ç¡®ä¿å‰ä¸€å±‚ï¼ˆå¦‚æ›´é è¿‘è¾“å…¥çš„å±‚ï¼‰çš„å‚æ•°èƒ½å¤Ÿæ¥æ”¶åˆ°æ­£ç¡®çš„æ¢¯åº¦ä¿¡å·ã€‚
```

![image-20250329140146945](pic/image-20250329140146945.png)

```
æ¿€æ´»é‡è®¡ç®—æŠ€æœ¯ï¼ˆActivation Recomputationï¼Œä¹Ÿç§°ä¸ºæ¢¯åº¦æ£€æŸ¥ç‚¹ï¼‰çš„æ ¸å¿ƒç›®çš„æ˜¯é€šè¿‡ç‰ºç‰²è®¡ç®—æ—¶é—´æ¥å‡å°‘å†…å­˜å ç”¨ã€‚åœ¨åå‘ä¼ æ’­æ—¶â€œå¤šè®¡ç®—ä¸€æ¬¡â€çš„æœ¬è´¨æ˜¯ï¼šç”±äºå‰å‘ä¼ æ’­é˜¶æ®µæœªä¿å­˜å…¨éƒ¨ä¸­é—´æ¿€æ´»å€¼ï¼Œåå‘ä¼ æ’­æ—¶éœ€è¦é‡æ–°è®¡ç®—è¿™äº›ä¸¢å¼ƒçš„æ¿€æ´»å€¼ï¼Œå¯¼è‡´é¢å¤–çš„è®¡ç®—å¼€é”€
ç›¸å½“äºé‡æ–°è¿›è¡Œäº†ä¸€æ¬¡å‰å‘ä¼ æ’­

ç»è®¡ç®—ç¡®å®å¤šå¤´æ³¨æ„åŠ›çš„è¿ç®—é‡ä¸ºçº¿æ€§å˜æ¢çš„T/6H
```

![](pic/image-20250329140206549.png)

#### **è®­ç»ƒæ˜¾å­˜ä¼°è®¡**

æ¥ä¸‹æ¥è®¨è®ºå¦‚ä½•ä¼°è®¡æ¨¡å‹åœ¨è®­ç»ƒä¸­éœ€è¦çš„æ˜¾å­˜èµ„æºå ç”¨ï¼Œä¸»è¦å¯ä»¥åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼šæ¨¡å‹å‚æ•°ä¸ä¼˜åŒ–å™¨ã€è®­ç»ƒä¸­éœ€è¦ä¿å­˜çš„æ¿€æ´»å€¼å’Œå…¶ä»–æ˜¾å­˜å ç”¨ã€‚

**æ¨¡å‹å‚æ•°ä¸ä¼˜åŒ–å™¨**

æ¨¡å‹å‚æ•°å’Œæ¨¡å‹æ¢¯åº¦é€šå¸¸ä»¥ 16 ä½æµ®ç‚¹æ•°å­˜å‚¨ï¼Œ

è€Œ Adam æˆ– AdamWä¼˜åŒ–å™¨åˆ™éœ€è¦é¢å¤–å­˜å‚¨ 32 ä½æµ®ç‚¹æ•°çš„æ¨¡å‹å‚æ•°ã€åŠ¨é‡å‚æ•°ä»¥åŠåŠ¨é‡äºŒé˜¶çŸ©å‚æ•°ã€‚

ä¸ä½¿ç”¨ *ZeRO* ä¼˜åŒ–æŠ€æœ¯*.* åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”±äºä¸€ä¸ª 16 ä½æµ®ç‚¹æ•°éœ€è¦ 2 å­—èŠ‚ï¼Œä¸€ä¸ª 32 ä½æµ®ç‚¹æ•°éœ€è¦ 4 å­—èŠ‚ï¼Œå› æ­¤æ¨¡å‹å‚æ•°å’Œæ¨¡å‹æ¢¯åº¦å„éœ€è¦ 2*ğ‘ƒ* å­—èŠ‚çš„æ˜¾å­˜ï¼ŒAdam ä¼˜åŒ–å™¨çš„æ¨¡å‹å‚æ•°ã€åŠ¨é‡å‚æ•°ä»¥åŠåŠ¨é‡äºŒé˜¶çŸ©å‚æ•°åˆ™å„éœ€è¦ 4*ğ‘ƒ* å­—èŠ‚çš„æ˜¾å­˜ã€‚é€šè¿‡å¯¹äºè¿™äº›æ˜¾å­˜å ç”¨è¿›è¡Œç´¯å’Œï¼Œæ¯å¼  GPU ä¸Šä¼šéœ€è¦ä½¿ç”¨ (2+2+4+4+4) Â·*ğ‘ƒ* = 16*ğ‘ƒ*å­—èŠ‚çš„æ˜¾å­˜ç”¨äºå­˜å‚¨æ¨¡å‹å‚æ•°ä¸ä¼˜åŒ–å™¨ã€‚

**è®­ç»ƒæ¿€æ´»å€¼çš„æ˜¾å­˜å ç”¨**

åœ¨å¤§æ¨¡å‹çš„è®­ç»ƒæœŸé—´ï¼Œå‰å‘ä¼ æ’­ä¸­éœ€è¦ä¿ç•™æ¯å±‚çš„æ¿€æ´»å€¼ï¼ˆä¸­é—´çŠ¶æ€ï¼‰ï¼Œæ¥ç”¨äºåç»­åå‘ä¼ æ’­ä¸­è®¡ç®—æ¢¯åº¦å¹¶æ›´æ–°æ¨¡å‹å‚æ•°

![image-20250319185604434](../my_minimind/images/image-20250319185604434.png)

```
FFNå±‚éœ€è¦ä¿å­˜swiGLUçš„è¾“å‡º

å¯èƒ½è¿˜éœ€è¦dropout
```

![image-20250329144837370](pic/image-20250329144837370.png)

![image-20250329144904486](pic/image-20250329144904486.png)

**SwiGLUæ¿€æ´»å‡½æ•°**

![image-20250329145711802](pic/image-20250329145711802.png)

## æŒ‡ä»¤å¾®è°ƒ

### LoRA

ä½ç§©é€‚é…ï¼ˆLow-Rank Adaptation, LoRAï¼‰å¾®è°ƒæŠ€æœ¯

![image-20250329150002237](pic/image-20250329150002237.png)

æ¨¡å‹åœ¨é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œé€‚é…æ—¶ï¼Œå‚æ•°çŸ©é˜µå¾€å¾€æ˜¯è¿‡å‚æ•°åŒ–ï¼ˆOver-parametrizedï¼‰çš„ï¼Œå…¶å­˜åœ¨ä¸€ä¸ªè¾ƒä½çš„å†…åœ¨ç§©ã€‚

![image-20250329150317476](pic/image-20250329150317476.png)

### **LoRAæ˜¾å­˜å ç”¨**

è¿™é‡Œå‡è®¾ LoRA éœ€è¦è®­ç»ƒçš„å‚æ•°é‡ä¸º *ğ‘ƒ*_LoRAï¼Œæ¨¡å‹åŸå§‹å‚æ•°ä¸ºP

![image-20250329152625122](pic/image-20250329152625122.png)

## **äººç±»å¯¹é½**

åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning from Human Feedback, RLHFï¼‰

å°½ç®¡å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºä¼˜ç§€çš„æ€§èƒ½ï¼Œè¿™äº›æ¨¡å‹æœ‰æ—¶ä¼šå‡ºç°é”™è¯¯æˆ–å…·æœ‰å±å®³æ€§çš„è¡Œä¸ºï¼Œä¾‹å¦‚æ— æ³•æ­£ç¡®éµå¾ªæŒ‡ä»¤ã€ç”Ÿæˆè™šå‡ä¿¡æ¯ã€ä»¥åŠäº§ç”Ÿæœ‰å®³ã€æœ‰è¯¯å¯¼æ€§ä»¥åŠå¸¦æœ‰åè§çš„è¡¨è¾¾ã€‚

æ—¨åœ¨ä¿è¯å¤§è¯­è¨€æ¨¡å‹çš„è¡Œä¸ºä¸äººç±»æœŸæœ›å’Œä»·å€¼è§‚ç›¸ä¸€è‡´

RLHF é¦–å…ˆéœ€è¦æ”¶é›†äººç±»å¯¹äºä¸åŒæ¨¡å‹è¾“å‡ºçš„åå¥½ï¼Œç„¶åä½¿ç”¨æ”¶é›†åˆ°çš„äººç±»åé¦ˆæ•°æ®è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œæœ€ååŸºäºå¥–åŠ±æ¨¡å‹ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆä¾‹å¦‚ Proximal Policy Optimization, PPO ï¼‰å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ã€‚

![image-20250329153526380](pic/image-20250329153526380.png)

### **PPO** **ä»‹ç»**

è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆProximal Policy Optimization, PPOï¼‰ç®—æ³•æ˜¯å¼ºåŒ–å­¦ä¹ é¢†åŸŸçš„ä¸€ç§é‡è¦ä¼˜åŒ–æ–¹æ³•ï¼Œä¸»è¦ç”¨äºè®­ç»ƒèƒ½å¤Ÿæ ¹æ®å¤–éƒ¨ç¯å¢ƒçŠ¶æ€åšå‡ºè¡Œä¸ºå†³ç­–çš„ç­–ç•¥æ¨¡å‹ã€‚PPO ç®—æ³•åœ¨ç­–ç•¥æ¢¯åº¦ç®—æ³•çš„åŸºç¡€ä¸Šï¼Œä¸»è¦ä½¿ç”¨ä¼˜åŠ¿ä¼°è®¡æ¥æ›´åŠ å‡†ç¡®çš„è¯„ä¼°å†³ç­–è½¨è¿¹èƒ½è·å¾—çš„å¥–åŠ±ï¼Œä½¿ç”¨äº†é‡è¦æ€§é‡‡æ ·æ¥è¿›è¡Œç¦»çº¿ç­–ç•¥è®­ç»ƒã€‚æ­¤å¤–ï¼Œä¸ºäº†ä¿è¯é‡è¦æ€§é‡‡æ ·çš„ç¨³å®šæ€§ï¼ŒPPO ç®—æ³•é€šè¿‡åœ¨ç›®æ ‡å‡½æ•°ä¸­åŠ å…¥äº†æ¢¯åº¦è£å‰ªä»¥åŠç›¸å…³çš„æƒ©ç½šé¡¹æ¥å‡å°é‡‡æ ·è¯¯å·®ã€‚ä¸ºäº†èƒ½å¤Ÿå®ç°ä¸Šè¿°ä¼˜åŒ–è¿‡ç¨‹ï¼ŒPPO åœ¨ç­–ç•¥æ¨¡å‹å’Œå¥–åŠ±æ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œè¿˜å¼•å…¥äº†å‚è€ƒæ¨¡å‹å’Œè¯„ä»·æ¨¡å‹

#### ä¼˜åŠ¿ä¼°è®¡

![image-20250329154039720](pic/image-20250329154039720.png)

åœ¨ PPO çš„ä¼˜åŠ¿å‡½æ•°ä¸­ï¼Œé€šè¿‡å°†å†³ç­–çš„å¥–åŠ±ä¸æœŸæœ›å¥–åŠ±åšå·®ï¼Œäº§ç”Ÿè¾ƒä½å¥–åŠ±çš„å†³ç­–å°†ä¼šå¾—åˆ°ä¸€ä¸ªè´Ÿçš„ä¼˜åŠ¿å€¼ï¼Œè€Œäº§ç”Ÿè¾ƒé«˜å¥–åŠ±çš„å†³ç­–ä¼šå¾—åˆ°ä¸€ä¸ªæ­£çš„ä¼˜åŠ¿å€¼ã€‚è¿™äº›ç›¸å¯¹è¾ƒå·®çš„å†³ç­–å°±ä¼šè¢«æŠ‘åˆ¶ï¼ŒåŒæ—¶é¼“åŠ±ç­–ç•¥æ¨¡å‹äº§ç”Ÿæ”¶ç›Šæ›´é«˜çš„å†³ç­–ã€‚å› æ­¤ï¼Œä¼˜åŠ¿å‡½æ•°å¯ä»¥å¸®åŠ©ç­–ç•¥æ¨¡å‹å­¦ä¹ åœ¨ä¼—å¤šå†³ç­–ä¸­åšå‡ºæ›´å¥½çš„é€‰æ‹©ã€‚

#### é‡è¦æ€§é‡‡æ ·

![image-20250329154209810](pic/image-20250329154209810.png)

![image-20250329154326683](pic/image-20250329154326683.png)

#### åŸºäºæ¢¯åº¦è£å‰ªçš„ç›®æ ‡å‡½æ•°

![image-20250329154430517](pic/image-20250329154430517.png)

#### KLæ•£åº¦

```
ç¬¬ä¸€é¡¹ï¼šé¼“åŠ±ç­–ç•¥å‘é«˜ä¼˜åŠ¿åŠ¨ä½œæ–¹å‘æ›´æ–°ï¼ˆæœ€å¤§åŒ–å›æŠ¥ï¼‰ã€‚
ç¬¬äºŒé¡¹ï¼ˆKLæƒ©ç½šé¡¹ï¼‰ï¼šé™åˆ¶ç­–ç•¥å˜åŒ–çš„å¹…åº¦ï¼ˆæœ€å°åŒ–KLæ•£åº¦ï¼‰ã€‚
å‚æ•° Î²ï¼šæ§åˆ¶â€œæœ€å¤§åŒ–å›æŠ¥â€ä¸â€œé™åˆ¶ç­–ç•¥å˜åŒ–â€ä¹‹é—´çš„æƒè¡¡ã€‚

D_kl>d_target:è¯´æ˜ç­–ç•¥å˜åŒ–è¿‡å¤§ï¼Œéœ€å¢å¤§Î²ï¼ŒåŠ å¼ºæƒ©ç½šåŠ›åº¦ã€‚ä½¿å¾—æ›´æ–°å¹…åº¦å‡å°
D_kl<d_target:è¯´æ˜ç­–ç•¥å˜åŒ–è¿‡å°ï¼Œå¯å‡å°Î²ï¼Œå…è®¸æ›´å¤§æ›´æ–°ã€‚ä½¿å¾—æ›´æ–°å¹…åº¦å¢å¤§
```

![image-20250329154826308](pic/image-20250329154826308.png)

#### ç®—æ³•æµç¨‹

![image-20250329155220877](pic/image-20250329155220877.png)

### **åŸºäºç›‘ç£å¾®è°ƒçš„å¯¹é½æ–¹æ³•(éå¼ºåŒ–å­¦ä¹ çš„å¯¹é½æ–¹æ³•)DPO**

å°½ç®¡ RLHF å·²è¢«è¯æ˜æ˜¯ä¸€ç§è¾ƒä¸ºæœ‰æ•ˆçš„è¯­è¨€æ¨¡å‹å¯¹é½æŠ€æœ¯ï¼Œä½†æ˜¯å®ƒä¹Ÿå­˜åœ¨ä¸€äº›å±€é™æ€§ã€‚é¦–å…ˆï¼Œåœ¨ RLHF çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œéœ€è¦åŒæ—¶ç»´æŠ¤å’Œæ›´æ–°å¤šä¸ªæ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹åŒ…æ‹¬**ç­–ç•¥æ¨¡å‹ã€å¥–åŠ±æ¨¡å‹ã€å‚è€ƒæ¨¡å‹ä»¥åŠè¯„ä»·æ¨¡å‹**ã€‚è¿™ä¸ä»…ä¼šå ç”¨å¤§é‡çš„å†…å­˜èµ„æºï¼Œè€Œä¸”æ•´ä¸ªç®—æ³•çš„æ‰§è¡Œè¿‡ç¨‹ä¹Ÿç›¸å¯¹å¤æ‚ã€‚æ­¤å¤–ï¼ŒRLHF ä¸­å¸¸ç”¨çš„è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ç®—æ³•åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§æ¬ ä½³ï¼Œå¯¹è¶…å‚æ•°çš„å–å€¼è¾ƒä¸ºæ•æ„Ÿï¼Œè¿™è¿›ä¸€æ­¥å¢åŠ äº†æ¨¡å‹è®­ç»ƒçš„éš¾åº¦å’Œä¸ç¡®å®šæ€§ã€‚

**ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDirect Preference Optimization, DPOï¼‰**æ˜¯ä¸€ç§ä¸éœ€è¦å¼ºåŒ–å­¦ä¹ çš„å¯¹é½ç®—æ³•ã€‚ç”±äºå»é™¤äº†å¤æ‚çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ŒDPO å¯ä»¥é€šè¿‡ä¸æœ‰ç›‘ç£å¾®è°ƒç›¸ä¼¼çš„å¤æ‚åº¦å®ç°æ¨¡å‹å¯¹é½ï¼Œä¸å†éœ€è¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œé‡‡æ ·ï¼ŒåŒæ—¶è¶…å‚æ•°çš„é€‰æ‹©æ›´åŠ å®¹æ˜“ã€‚

```
DPO ç®—æ³•çš„ä¸»è¦æ€æƒ³æ˜¯åœ¨å¼ºåŒ–å­¦ä¹ çš„ç›®æ ‡å‡½æ•°ä¸­å»ºç«‹å†³ç­–å‡½æ•°ä¸å¥–åŠ±å‡½æ•°ä¹‹é—´çš„å…³ç³»ï¼Œä»¥è§„é¿å¥–åŠ±å»ºæ¨¡çš„è¿‡ç¨‹ã€‚å½¢å¼åŒ–åœ°ï¼ŒDPO ç®—æ³•é¦–å…ˆéœ€è¦æ‰¾åˆ°å¥–åŠ±å‡½æ•° ğ‘Ÿ(ğ‘¥, ğ‘¦) ä¸å†³ç­–å‡½æ•° ğœ‹ğœƒ (ğ‘¦|ğ‘¥)ä¹‹é—´çš„å…³ç³»ï¼Œå³ä½¿ç”¨ ğœ‹ğœƒ (ğ‘¦|ğ‘¥) æ¥è¡¨ç¤º ğ‘Ÿ(ğ‘¥, ğ‘¦)ã€‚
```

![image-20250329160443713](pic/image-20250329160443713.png)

ä¸ RLHF ç®—æ³•ç›¸æ¯”ï¼ŒDPO ç®—æ³•æ²¡æœ‰é‡‡ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•æ¥è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œè€Œæ˜¯é€šè¿‡ç›‘ç£å¾®è°ƒçš„æ–¹å¼å¯¹äºè¯­è¨€æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚ä¸ä¼ ç»Ÿæœ‰ç›‘ç£å¾®è°ƒæ–¹æ³•ä¸åŒï¼ŒDPO ç®—æ³•ä¸­ä¸ä»…è®­ç»ƒæ¨¡å‹ç”Ÿæˆç¬¦åˆäººç±»åå¥½çš„å†…å®¹ï¼ŒåŒæ—¶é™ä½æ¨¡å‹ç”Ÿæˆä¸ç¬¦åˆäººç±»åå¥½å†…å®¹çš„æ¦‚ç‡ã€‚ç›¸æ¯”äºå¼ºåŒ–å­¦ä¹ ç®—æ³• PPOï¼ŒDPO åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åªéœ€è¦åŠ è½½ç­–ç•¥æ¨¡å‹å’Œå‚è€ƒæ¨¡å‹ï¼Œå¹¶ä¸ç”¨åŠ è½½å¥–åŠ±æ¨¡å‹å’Œè¯„ä»·æ¨¡å‹ã€‚å› æ­¤ï¼ŒDPO ç®—æ³•å ç”¨çš„èµ„æºæ›´å°‘ã€è¿è¡Œæ•ˆç‡æ›´é«˜ï¼Œå¹¶ä¸”å…·æœ‰è¾ƒå¥½çš„å¯¹é½æ€§èƒ½ï¼Œåœ¨å®è·µä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚

### RLHFå’ŒSFTçš„å¯¹æ¯”

![image-20250329161007295](pic/image-20250329161007295.png)

åœ¨ RLHF ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆå­¦ä¹ ä¸€ä¸ªå¥–åŠ±æ¨¡å‹ï¼Œç„¶ååˆ©ç”¨è¯¥å¥–åŠ±æ¨¡å‹é€šè¿‡å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå¦‚ PPOï¼‰æ¥æ”¹è¿›å¤§è¯­è¨€æ¨¡å‹ã€‚è€Œåœ¨ SFT ä¸­ï¼Œæˆ‘ä»¬åˆ™é‡‡ç”¨äº† Teacher-Forcing çš„æ–¹æ³•ï¼Œç›´æ¥ä¼˜åŒ–æ¨¡å‹å¯¹å®ä¾‹è¾“å‡ºçš„é¢„æµ‹æ¦‚ç‡ã€‚ä»æœ¬è´¨ä¸Šè¯´ï¼ŒSFT æ‰€é‡‡ç”¨çš„è¿™ç§è¯å…ƒçº§åˆ«çš„è®­ç»ƒæ–¹å¼æ˜¯ä¸€ç§â€œè¡Œä¸ºå…‹éš†â€ã€‚å®ƒåˆ©ç”¨æ•™å¸ˆçš„è¡Œä¸ºæ•°æ®ï¼ˆå³æ¯ä¸ªæ­¥éª¤çš„ç›®æ ‡è¯å…ƒï¼‰ä½œä¸ºç›‘ç£æ ‡ç­¾ï¼Œæ¥ç›´æ¥è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹æ¨¡ä»¿æ•™å¸ˆçš„è¡Œä¸ºã€‚åœ¨å®ç°ä¸Šï¼ŒSFT ä¸»è¦ä¾èµ–äºåºåˆ—åˆ°åºåˆ—çš„ç›‘ç£æŸå¤±æ¥ä¼˜åŒ–æ¨¡å‹ï¼Œè€Œ RLHF åˆ™ä¸»è¦å…³äº SFT å’Œ RLHF çš„è¿›ä¸€æ­¥è®¨è®ºè¿‡å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ¥å®ç°å¤§æ¨¡å‹ä¸äººç±»ä»·å€¼è§‚çš„å¯¹é½ã€‚æœ¬è´¨ä¸Šæ¥è¯´ï¼Œä¸ºäº†å­¦ä¹ æ•™å¸ˆçš„ç”Ÿæˆç­–ç•¥ï¼ŒSFT é‡‡ç”¨äº†åŸºäºç¤ºä¾‹æ•°æ®çš„â€œå±€éƒ¨â€ä¼˜åŒ–æ–¹å¼ï¼Œå³è¯å…ƒçº§åˆ«çš„æŸå¤±å‡½æ•°ã€‚ä½œä¸ºå¯¹æ¯”ï¼ŒRLHF åˆ™é‡‡ç”¨äº†æ¶‰åŠäººç±»åå¥½çš„â€œå…¨å±€â€ä¼˜åŒ–æ–¹å¼ï¼Œå³æ–‡æœ¬çº§åˆ«çš„æŸå¤±å‡½æ•°ã€‚

#### SFTçš„ç¼ºç‚¹

å…³äº SFTï¼Œå…¶ä½œç”¨åœ¨äºâ€œè§£é”â€å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œè€Œéå‘å¤§è¯­è¨€æ¨¡å‹â€œæ³¨å…¥â€æ–°èƒ½åŠ›ã€‚å½“å¾…å­¦ä¹ çš„æ ‡æ³¨æŒ‡ä»¤æ•°æ®è¶…å‡ºäº†å¤§è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†æˆ–èƒ½åŠ›èŒƒå›´ï¼Œä¾‹å¦‚è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹å›ç­”å…³äºæ¨¡å‹æœªçŸ¥äº‹å®çš„é—®é¢˜æ—¶ï¼Œå¯èƒ½ä¼šåŠ é‡æ¨¡å‹çš„**å¹»è±¡**ï¼ˆHallucinationï¼‰è¡Œä¸ºã€‚

ä½œä¸ºä¸€ç§åŸºäºè¡Œä¸ºå…‹éš†çš„å­¦ä¹ æ–¹æ³•ï¼ŒSFT æ—¨åœ¨æ¨¡ä»¿æ„å»ºæ ‡æ³¨æ•°æ®çš„æ•™å¸ˆçš„è¡Œä¸ºï¼Œè€Œæ— æ³•åœ¨è¿™ä¸€è¿‡ç¨‹ä¸­è¿›è¡Œæœ‰æ•ˆçš„è¡Œä¸ºæ¢ç´¢ã€‚ç„¶è€Œï¼Œæ ‡æ³¨è€…åœ¨å†™ä½œé£æ ¼ã€åˆ›ä½œæ°´å¹³å’Œä¸»é¢˜åå¥½ç­‰æ–¹é¢ç»å¸¸å­˜åœ¨ä¸€å®šçš„å·®å¼‚ï¼Œè¿™äº›éƒ½ä¼šä½¿å¾—æ ‡æ³¨æ•°æ®ä¸­å‡ºç°ä¸ä¸€è‡´çš„æ•°æ®ç‰¹å¾ï¼Œè¿›è€Œå½±å“ SFT çš„å­¦ä¹ æ€§èƒ½ã€‚å› æ­¤ï¼Œåœ¨ SFT é˜¶æ®µï¼Œ**é«˜è´¨é‡çš„æŒ‡ä»¤æ•°æ®**ï¼ˆè€Œéæ•°é‡ï¼‰æ˜¯å½±å“å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒçš„ä¸»è¦å› ç´ ã€‚

#### RLHFçš„ç¼ºç‚¹

RLHF é€šè¿‡å¯¹æ¯”æ¨¡å‹çš„è¾“å‡ºæ•°æ®ï¼ˆåŒºåˆ†â€œå¥½â€è¾“å‡ºä¸â€œåâ€è¾“å‡ºï¼‰æ¥æŒ‡å¯¼å¤§è¯­è¨€æ¨¡å‹å­¦ä¹ æ­£ç¡®çš„ç”Ÿæˆç­–ç•¥ï¼Œå®ƒä¸å†å¼ºè¿«å¤§è¯­è¨€æ¨¡å‹æ¨¡ä»¿æ•™å¸ˆçš„ç¤ºä¾‹æ•°æ®ï¼Œå› æ­¤å¯ä»¥ç¼“è§£ä¸Šè¿°æåˆ°çš„ SFT æ‰€å¯¼è‡´çš„å¹»è±¡é—®é¢˜ã€‚

RLHFç»§æ‰¿äº†ç»å…¸å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„ç¼ºç‚¹ï¼Œ**å¦‚æ ·æœ¬å­¦ä¹ æ•ˆç‡ä½å’Œè®­ç»ƒè¿‡ç¨‹ä¸ç¨³å®šç­‰é—®é¢˜ã€‚**

RLHF çš„è¿‡ç¨‹é€šå¸¸ä¼šæŒç»­å¤šè½®ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„è¿­ä»£ä¼˜åŒ–è¿‡ç¨‹ï¼Œå…¶ä¸­**æ¶‰åŠäº†å¾ˆå¤šé‡è¦ç»†èŠ‚çš„è®¾å®š**ï¼ˆä¾‹å¦‚æç¤ºé€‰æ‹©ã€å¥–åŠ±æ¨¡å‹è®­ç»ƒã€PPOçš„è¶…å‚æ•°è®¾ç½®ä»¥åŠè®­ç»ƒè¿‡ç¨‹ä¸­å¯¹è¶…å‚æ•°çš„è°ƒæ•´ï¼‰ï¼Œéƒ½ä¼šå½±å“æ•´ä¸ªæ¨¡å‹çš„æ€§èƒ½ï¼Œå¯¹äºç²¾ç¡®çš„é«˜æ•ˆå¤ç°æå‡ºäº†è¾ƒå¤§æŒ‘æˆ˜ã€‚

#### æ€»ç»“

æ€»çš„æ¥è¯´ï¼ŒSFT ç‰¹åˆ«é€‚åˆé¢„è®­ç»ƒåå¢å¼ºæ¨¡å‹çš„æ€§èƒ½ï¼Œå…·æœ‰å®ç°ç®€å•ã€å¿«é€Ÿé«˜æ•ˆç­‰ä¼˜ç‚¹ï¼›è€Œ RLHF å¯åœ¨æ­¤åŸºç¡€ä¸Šè§„é¿å¯èƒ½çš„æœ‰å®³è¡Œä¸ºå¹¶è¿›ä¸€æ­¥æé«˜æ¨¡å‹æ€§èƒ½ï¼Œä½†æ˜¯å®ç°è¾ƒä¸ºå›°éš¾ï¼Œä¸æ˜“è¿›è¡Œé«˜æ•ˆä¼˜åŒ–ã€‚

## æ¨¡å‹éƒ¨ç½²

### æ¨¡å‹è’¸é¦

![image-20250329162702259](pic/image-20250329162702259.png)

æ¨¡å‹è’¸é¦ï¼ˆModel Distillationï¼‰çš„ç›®æ ‡æ˜¯å°†å¤æ‚æ¨¡å‹ï¼ˆç§°ä¸ºæ•™å¸ˆæ¨¡å‹ï¼‰åŒ…å«çš„çŸ¥è¯†è¿ç§»åˆ°ç®€å•æ¨¡å‹ï¼ˆç§°ä¸ºå­¦ç”Ÿæ¨¡å‹ï¼‰ä¸­ï¼Œä»è€Œå®ç°å¤æ‚æ¨¡å‹çš„å‹ç¼©ã€‚

æ¨¡å‹è’¸é¦çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œå¼•å…¥é¢å¤–çš„æŸå¤±å‡½æ•°ï¼ˆç§°ä¸ºè’¸é¦æŸå¤±å‡½æ•°ï¼‰ï¼Œè®­ç»ƒå­¦ç”Ÿæ¨¡å‹çš„è¾“å‡ºå°½å¯èƒ½æ¥è¿‘æ•™å¸ˆæ¨¡å‹çš„è¾“å‡ºã€‚

![image-20250329162935542](pic/image-20250329162935542.png)

![image-20250329163008380](pic/image-20250329163008380.png)

ç›¸è¾ƒäºæœ€ç»ˆçš„é¢„æµ‹åˆ†å¸ƒï¼Œä¸­é—´å±‚ç‰¹å¾æä¾›äº†æ›´ä¸ºä¸°å¯Œçš„æ¨¡å‹ä¿¡æ¯ï¼Œæœ‰åŠ©äºåœ¨æ¨¡å‹è’¸é¦è¿‡ç¨‹ä¸­å®ç°æ›´ä¸ºæœ‰æ•ˆçš„çŸ¥è¯†è¿ç§»ã€‚

# Deepseek

## deepseek-v3

```
å¯è¯»æ€§å·®ï¼Œè¯­è¨€æ··æ‚
```

pre-training remarkably stable

two architectureï¼šMLA(multi-head latent attention) Moe(mixture of experts)

two strategiesï¼šauxiliary-loss-free + MTP(multi-token-prediction training objective)

FP8 mixed precision

### MLA å¤šå¤´éšå¼æ³¨æ„åŠ›æœºåˆ¶ ï¼šinference

```
ç”¨ä½ç»´çš„å‘é‡æˆ–çŸ©é˜µå–ä»£åŸå§‹çš„kv cacheé‡Œçš„kvï¼›ä»…cache c
```

#### **kv-cache**ï¼šç©ºé—´æ¢æ—¶é—´

```
inferenceé˜¶æ®µæ‰æœ‰kv-cache

attentionså®é™…æ˜¯çŸ©é˜µç›¸ä¹˜å¾—åˆ°correlation


QK^Tç”±äºæ˜¯å› æœæ¨¡å‹ï¼Œç¬¬ä¸€ä¸ªtokençœ‹ä¸åˆ°åé¢çš„è¾“å‡ºï¼Œéœ€è¦maskæ©ç 
ä¸éœ€è¦æ¯æ¬¡é‡å¤è®¡ç®—K,Vï¼Œç›´æ¥concatå¤ç”¨
ç”±äºåªéœ€è¦attentionçš„æœ€åä¸€è¡Œï¼Œåªéœ€è¦è®¡ç®—Qçš„æœ€åä¸€è¡Œï¼Œå› æ­¤qä¸éœ€è¦cache
```

![image-20250414222734715](pic/image-20250414222734715.png)

#### low-rank kv

```
å‹ç¼©åˆ°ä½ç»´å­˜å‚¨ï¼Œç±»ä¼¼lora
ä½¿ç”¨æ—¶å†æŠ•å½±æ¢å¤
```

![image-20250414223520322](pic/image-20250414223520322.png)

```
ä»…cache c
```

![image-20250414223746942](pic/image-20250414223746942.png)

```
##trick  abosorb å‚æ•°çŸ©é˜µ
åšæ¨ç†çš„æ—¶å€™ï¼Œä¸ç”¨è®¡ç®—k,vï¼›ç›´æ¥ç”¨ä¸€ä¸ªå‚æ•°çŸ©é˜µä»£æ›¿ä¸¤ä¸ªå‚æ•°çŸ©é˜µç›¸ä¹˜ï¼Œå‡å°‘å‚æ•°é‡
```

![image-20250414224008978](pic/image-20250414224008978.png)

```
åŒæ—¶å¯¹qä¹Ÿè¿›è¡Œäº†å‹ç¼©
ä½†æ˜¯å’Œkvä¸æ˜¯åŒä¸€ä¸ªå‚æ•°çŸ©é˜µ
```

![image-20250414224224489](pic/image-20250414224224489.png)

#### **rotary position embeding**ï¼ˆabsolute+relativeï¼‰

ç»å¯¹ä½ç½®ï¼šå¯¹é•¿å¥å­ä¸å¥½ï¼ˆæ‰©å±•æ€§å·®ï¼‰

ç›¸å¯¹ä½ç½®ï¼šè®¡ç®—å¤æ‚

```
relativeå¯èƒ½ä¼šæ”¹å˜è§’åº¦å’Œé•¿åº¦
ropeä»…ä¼šæ”¹å˜è§’åº¦
```

![image-20250414224905015](pic/image-20250414224905015.png)

```
ropeç»™qkä¹˜ä¸Šä¸€ä¸ªæ—‹è½¬çŸ©é˜µï¼Œæ¯ä¸ªæ—‹è½¬çŸ©é˜µä»£è¡¨tokençš„absoluteä½ç½®ï¼Œattnçš„ç»“æœä»£è¡¨relativeä½ç½®

RoPEï¼ˆRotary Position Embeddingï¼‰çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¤æ•°ç©ºé—´æ—‹è½¬å°†ä½ç½®ä¿¡æ¯ç¼–ç åˆ°Queryå’ŒKeyä¸­
```

![image-20250414225155043](pic/image-20250414225155043.png)

#### è§£å†³kv cacheå’Œropeé—®é¢˜ï¼ˆè§£è€¦ï¼‰

```
å–qå’Œkçš„å°éƒ¨åˆ†apply ropeï¼›å†å’Œå¦ä¸€éƒ¨åˆ†æœªç»è¿‡ropeçš„æ•°æ®concatï¼›è®¡ç®—
ç»“åˆäº†ropeä½ç½®ç¼–ç çš„ä¼˜ç‚¹å’Œlow-rankå‚æ•°é‡å°çš„ä¼˜ç‚¹

ä½ç§©å‹ç¼©
çŸ©é˜µçš„ç§©ä¸ºrï¼Œåˆ™å¯åˆ†è§£ä¸ºä¸¤ä¸ªå°çŸ©é˜µçš„ä¹˜ç§¯ï¼›è¿™ç§åˆ†è§£ä½¿å¾—å‚æ•°æ•°é‡å‡å°‘ï¼Œä»è€Œé™ä½è®¡ç®—å¤æ‚åº¦ã€‚ä½†ä½ç§©çŸ©é˜µå¯èƒ½ä¸¢å¤±éƒ¨åˆ†ä¿¡æ¯ï¼Œå› æ­¤éœ€è¦è®¾è®¡æ–¹æ³•ç¡®ä¿å…³é”®ç‰¹å¾ï¼ˆå¦‚ä½ç½®ç¼–ç ï¼‰ä¸å—å½±å“

MLAåœ¨æ¨ç†çš„æ—¶å€™ä¸æƒ³ç¼“å­˜å®Œæ•´çš„kv cacheï¼Œåªæƒ³ç¼“å­˜å‹ç¼©çš„ckvï¼Œä½†è¿™æ ·çš„è¯éœ€è¦åœ¨å‡ç»´åå†é‡æ–°è®¡ç®—ropeï¼Œå®ƒä¹Ÿä¸æƒ³ï¼Œæ‰€ä»¥å¹²è„†æŠŠqå’Œkæ‹†æˆä¸¤éƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†æ˜¯ä½ç½®ç¼–ç çš„ï¼Œä¸€éƒ¨åˆ†æ˜¯æ— å…³ä½ç½®ç¼–ç çš„ã€‚å¸¦ä½ç½®ç¼–ç çš„kå¯ä»¥ç¼“å­˜ï¼Œæ¯”ç¼“å­˜å…¨éƒ¨ç»´åº¦éƒ½å¸¦ä½ç½®çš„kå¼º

å¦‚ä¸‹å›¾ï¼Œkv cacheå­˜å‚¨çš„æ˜¯k_ropeå’Œæ½œåœ¨å‘é‡c
```

![image-20250414231551311](pic/image-20250414231551311.png)

**ropeåˆ†é‡ç‹¬è‡ªç”Ÿæˆ**

kçš„ropeç”±hç›´æ¥è®¡ç®—ï¼Œä¸ç»è¿‡ä½ç§©å‹ç¼©

qçš„ropeç”±æ½œåœ¨å‘é‡cç”Ÿæˆ

å…³é”®ç‚¹ï¼šropeä»…ä½œç”¨äºæœªè¢«ä½ç§©å‹ç¼©ç ´åçš„åŸå§‹è¾“å…¥æˆ–ä¸­é—´è¡¨ç¤ºï¼Œé¿å…ä½ç½®ç¼–ç ä¸å‹ç¼©è·¯å¾„çš„å†²çª

**éropeé€šè¿‡ä½ç§©å‹ç¼©ç”Ÿæˆ**

qï¼Œkï¼Œvçš„éropeç”±ä½ç§©å‹ç¼©è·¯å¾„ç”Ÿæˆ

ä¸æºå¸¦ä½ç½®ä¿¡æ¯ï¼Œä»…ç¼–ç å†…å®¹ç‰¹å¾

**æ‹¼æ¥åè®¡ç®—attn**

æ‹¼æ¥qï¼Œkçš„ropeå’Œéropeï¼Œè®¡ç®—

```
W_qr,W_kræ˜¯ropeæ—‹è½¬çŸ©é˜µ
```



![img](images/v2-db832a57ffb06b6d23b55bdf26750eac_1440w.webp)

![image-20250418103706299](images/image-20250418103706299.png)

![image-20250418115334070](images/image-20250418115334070.png)

### Moeï¼štraining

#### **origin moe**

```
dense moeè®¡ç®—æ‰€æœ‰çš„ffnåŠ æƒå¹³å‡
sparse moeè®¡ç®—top kçš„åŠ æƒå¹³å‡


moeå¥½å¤„ï¼šä»…è®¡ç®—å°‘æ•°çš„expertï¼ŒèŠ±è´¹å°‘ï¼›æ¯ä¸ªexpertå¯ä»¥å­¦ä¹ ä¸“é•¿ç‰¹å¾
```

![image-20250415094553846](pic/image-20250415094553846.png)

#### deepseek moe

```
æ”¹è¿›:
1.åˆ’åˆ†å¤šä¸ªexpert
å‡å°‘ä¸­é—´ç»´åº¦ï¼Œå¢åŠ expertæ•°é‡ï¼Œå› æ­¤å‚æ•°æ•°é‡å¤§è‡´ä¸å˜
ç±»ä¼¼model ensemble, é™ä½varienceï¼Œæé«˜æ¨¡å‹æ€§èƒ½

2.æ·»åŠ shared expert
å­¦ä¹ å…¬å…±çš„çŸ¥è¯†
```

![image-20250415094958016](pic/image-20250415094958016.png)

#### auxiliary-loss-free load balancing 

è´Ÿè½½å‡è¡¡

```
MoE è®­ç»ƒä¸­ä¸€ä¸ªå…³é”®æŒ‘æˆ˜æ˜¯è´Ÿè½½å‡è¡¡â€”â€”æŸäº›ä¸“å®¶å¯èƒ½è¢«è¿‡åº¦ä½¿ç”¨ï¼Œè€Œå…¶ä»–ä¸“å®¶åˆ™è¢«å†·è½ã€‚è¿™ä¸ä»…ä¼šå¯¼è‡´è®¡ç®—èµ„æºçš„æµªè´¹ï¼ˆå¦‚éƒ¨åˆ†è®¾å¤‡é—²ç½®ï¼‰ï¼Œè¿˜å¯èƒ½å¼•å‘è·¯ç”±å´©æºƒï¼ˆRouting Collapseï¼‰ï¼Œå³æ¨¡å‹ä»…ä¾èµ–å°‘æ•°ä¸“å®¶ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨æ‰€æœ‰ä¸“å®¶èƒ½åŠ›ã€‚

ä¼ ç»Ÿè§£å†³æ–¹æ¡ˆé€šè¿‡å¼•å…¥è¾…åŠ©æŸå¤±ï¼ˆAuxiliary Lossï¼‰ å¼ºåˆ¶å‡è¡¡ä¸“å®¶è´Ÿè½½ï¼Œä½†è¿™ç§æ–¹æ³•å­˜åœ¨æ˜æ˜¾ç¼ºé™·ï¼šè¾…åŠ©æŸå¤±ä¼šå‘æ¨¡å‹æ³¨å…¥å¹²æ‰°æ¢¯åº¦ï¼Œä¸ä¸»ä»»åŠ¡ï¼ˆå¦‚è¯­è¨€å»ºæ¨¡ï¼‰çš„ä¼˜åŒ–ç›®æ ‡å†²çªï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„æ— è¾…åŠ©æŸå¤±è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼ˆLoss-Free Balancingï¼‰ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´è·¯ç”±å¾—åˆ†åç½®ï¼ˆBiasï¼‰å®ç°è´Ÿè½½å‡è¡¡ï¼ŒåŒæ—¶é¿å…å¼•å…¥é¢å¤–æ¢¯åº¦å¹²æ‰°ã€‚



åœ¨softmaxå‰åŠ ä¸€ä¸ªbias
å¦‚æœå¸Œæœ›å¢å¤§æŸä¸ªexpertçš„tokenæ•°ï¼Œåˆ™åŠ ä¸Šä¸€ä¸ªè¾ƒå¤§çš„bå¢å¤§æ¦‚ç‡
```

![image-20250415112541701](pic/image-20250415112541701.png)

![image-20250416232032597](pic/image-20250416232032597.png)

```
æ ¸å¿ƒæ€æƒ³
Auxiliary-Loss-Free Load Balancingçš„æ ¸å¿ƒæ˜¯åŠ¨æ€è°ƒæ•´ä¸“å®¶è·¯ç”±å¾—åˆ†çš„åç½®ï¼Œè€Œéä¾èµ–è¾…åŠ©æŸå¤±ã€‚å…·ä½“æ­¥éª¤ï¼š
åç½®æ³¨å…¥ï¼šåœ¨ Top-K è·¯ç”±å‰ï¼Œä¸ºæ¯ä¸ªä¸“å®¶çš„åŸå§‹è·¯ç”±å¾—åˆ† sæ·»åŠ åŠ¨æ€åç½®bï¼Œç”Ÿæˆåç½®å¾—åˆ†s+b
åç½®æ›´æ–°ï¼šæ ¹æ®è¿‘æœŸè´Ÿè½½æƒ…å†µè°ƒæ•´åç½®ï¼Œé«˜è´Ÿè½½ä¸“å®¶çš„åç½®è¢«æŠ‘åˆ¶ï¼Œä½è´Ÿè½½ä¸“å®¶çš„åç½®è¢«æå‡
```

![img](pic/dd8364f455c7e8f0ab9023edbcedcaee.png)

### MTPï¼šenhance model

```
ä¼˜ç‚¹ï¼š
1. trianing efficience
2. reasoning

åº”ç”¨ MTP æœºåˆ¶çš„ä¸»è¦ç›®çš„æ˜¯æå‡åŸºç¡€æ¨¡å‹çš„æ€§èƒ½ï¼Œå› æ­¤åœ¨å®é™…æ¨ç†é˜¶æ®µå¯ä»¥ä¸ä½¿ç”¨ MTP æ¨¡å—ï¼ŒåŸºç¡€æ¨¡å‹èƒ½å¤Ÿç‹¬ç«‹å®Œæˆæ­£å¸¸æ¨ç†
```

#### ä»¥å‰çš„mtp

```
deepseekå°†inferenceé˜¶æ®µçš„EAGLEçš„causalæ¨¡å‹æ›¿æ¢trainé˜¶æ®µçš„meata MTPçš„parallel headsæ¨¡å‹
```

![image-20250415113246227](pic/image-20250415113246227.png)

#### llm trainå’ŒInference

```
trainé˜¶æ®µæ¯æ¬¡éƒ½æ˜¯ç”¨ground truthæ¥è®­ç»ƒ
å­˜åœ¨çš„é—®é¢˜ï¼š
1.æ¯æ¬¡ç”¨truthè®­ç»ƒ
2.æ¯æ¬¡é¢„æµ‹ä¸€ä¸ªtokenï¼ˆçŸ­è§†ï¼‰
3.training signalå·® 


å®é™…ä¸Štrianè¿‡ç¨‹æ˜¯å¹¶è¡Œçš„auto regressiveï¼ŒæŒ‡å°†ä¸€æ•´ä¸ªå¥å­è¾“å…¥ï¼Œè·å¾—ä¸€æ•´ä¸ªè¾“å‡ºï¼›ä¸ºäº†ä¿è¯causalï¼Œéœ€è¦mask
æœ¬è´¨ä¸Šè¿˜æ˜¯é¢„æµ‹ä¸€ä¸ªtoken
```

![image-20250415113756534](pic/image-20250415113756534.png)

```
inferenceé˜¶æ®µæ¯æ¬¡å°†ä¸Šä¸€æ¬¡é¢„æµ‹çš„ä½œä¸ºè¾“å…¥
```

![image-20250415113949336](pic/image-20250415113949336.png)

#### meta MTP

![image-20250415114525346](pic/image-20250415114525346.png)

```
hard transitionï¼šæ¯”å¦‚5é¢„æµ‹A

one token predictionï¼šæ­¤æ—¶hard transitionçš„æ¯”ä¾‹æ˜¯1/7ï¼Œæƒé‡æ˜¯0.14
three token predictionï¼šæ­¤æ—¶hard transitionçš„æ¯”ä¾‹æ˜¯2/7ï¼Œæƒé‡æ˜¯0.28ï¼›å¯ä»¥å­¦åˆ°æ›´å¤šçš„hard transition

ç¼ºç‚¹ï¼š
parallel headsï¼š1é¢„æµ‹å¤šä¸ªtoken 2ï¼Œ3ï¼Œ4ï¼Œè¿èƒŒäº†causalï¼ˆå› ä¸º3å’Œ2åº”è¯¥æ˜¯æœ‰å› æœçš„ï¼‰
```

![image-20250415114856619](pic/image-20250415114856619.png)

#### speculative decoding

```
æœ‰ä¸¤ç§å½¢å¼ï¼š
1. small LLM
2. headsï¼ˆself)
```

![image-20250415151412706](pic/image-20250415151412706.png)

```
ç”¨ä¸€ä¸ªå¤§æ¨¡å‹å’Œä¸€ä¸ªå°æ¨¡å‹

tokenå…ˆç»™å°æ¨¡å‹å¤„ç†ï¼Œç”¨å¤§æ¨¡å‹éªŒè¯ï¼Œå¹¶ç”¨å¤§æ¨¡å‹é‡æ–°å¤„ç†å°æ¨¡å‹é¢„æµ‹é”™è¯¯çš„token
```

![image-20250415151500307](pic/image-20250415151500307.png)

![image-20250415151735664](pic/image-20250415151735664.png)

```
å°†å°æ¨¡å‹åµŒå…¥å¤§æ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯ç”¨è‡ªå·±çš„headsä½œä¸ºå°æ¨¡å‹ï¼Œæœ‰ä¸¤è€…å½¢å¼ï¼š
Medusa: å¹¶è¡Œé¢„æµ‹
EAGLE: casualé¢„æµ‹
```

![image-20250415151952344](pic/image-20250415151952344.png)

![image-20250415120628021](pic/image-20250415120628021.png)

#### deepseek MTP

```
deeepseek MTPæœ‰ä¸¤ä¸ªMTP module
å°†main modelè¾“å‡ºä¹‹å‰çš„featureè¾“é€åˆ°MTP model1ï¼Œè¿™æ ·MTP model1æ—¢æœ‰ä»¥å‰tokençš„é¢„æµ‹è¾“å‡ºä¹Ÿæœ‰å½“å‰tokençš„embed
æœ€åè®¡ç®—ä¸‰ä¸ªLossçš„å¹³å‡å€¼

inferenceä¸éœ€è¦MTP module


ä½¿ç”¨MTPæé«˜äº†planningè§„åˆ’å’Œreasoningæ¨ç†èƒ½åŠ›
planning: main modelè¾“é€çš„featureåŒ…å«å¯¹feature tokenæœ‰å¸®åŠ©çš„ä¿¡æ¯ï¼Œå…·æœ‰planning
reasoning


é¦–å…ˆï¼ŒMTP ç›®æ ‡é€šè¿‡å¢åŠ è®­ç»ƒä¿¡å·çš„å¯†åº¦å¯èƒ½æé«˜æ•°æ®åˆ©ç”¨æ•ˆç‡ï¼›å…¶æ¬¡ï¼Œå®ƒä½¿æ¨¡å‹èƒ½å¤Ÿæå‰è§„åˆ’è¡¨å¾ï¼Œä»è€Œæ›´å‡†ç¡®åœ°é¢„æµ‹åç»­ tokenã€‚
DeepSeek-V3 é‡‡ç”¨é¡ºåºé¢„æµ‹æ–¹å¼ï¼Œå¹¶åœ¨æ¯ä¸ªé¢„æµ‹å±‚çº§ä¿æŒå®Œæ•´çš„å› æœå…³ç³»é“¾ã€‚
```

![image-20250415153414784](pic/image-20250415153414784.png)

![image-20250418105726712](images/image-20250418105726712.png)

![image-20250418105826356](images/image-20250418105826356.png)

## deepseek-R1

### top-down

```
COT: chain of thought

AGIï¼šartificial general intelligence é€šç”¨äººå·¥æ™ºèƒ½

deepseek-R1æ³¨é‡æé«˜reasoning ability
```

![image-20250415154636605](pic/image-20250415154636605.png)

### ä¸¤ä¸ªç‰ˆæœ¬

```
pre-training
post-training:SFT+RLHF

deepseek-R1-zero:ä¸ç”¨SFT,ç›´æ¥ä½¿ç”¨RLHF
å¯è¯»æ€§å·®ï¼Œè¯­è¨€æ··æ‚

deepseek-R1:å°‘é‡SFTï¼Œæ¥ç€RLHF
cold-start data + multi-stage+training + bootstraping

è´¡çŒ®:
post-training
distillation
```

### RL

#### slå’ŒRL

```
AGIï¼šartificial general intelligence é€šç”¨äººå·¥æ™ºèƒ½

sl memoriseï¼šæ— æ³•è¶…è¿‡äººç±»
RL generizeï¼šå¯ä»¥è¶…è¿‡äººç±»
```

![image-20250415161800384](pic/image-20250415161800384.png)

```
RLå’ŒSFTçš„å¯¹æ¯”

sft:è®­ç»ƒä¸€ä¸ªNNï¼Œè®©predè¶Šæ¥è¿‘ground truthï¼Œæ¯ä¸€æ­¥éƒ½æœ‰ground truth

rlï¼šä»…åœ¨æœ€åæ‰ç»™å‡ºreward
policy based é¢„æµ‹é‡‡å–å“ªä¸ªactionårewardå¤§ ï¼ˆplayer)
value based è¯„ä»·å½“å‰state actionçš„å¥½å (coach)
actor-critic= policy based  + value based 
```

![image-20250415162256736](pic/image-20250415162256736.png)

```
RLçš„ç‰¹ç‚¹
```

![image-20250415163102770](pic/image-20250415163102770.png)

#### alphaGoå’ŒalphaZero

```
alphaGo
æœ¬è´¨ä¸Šæ˜¯searchç®—æ³•ï¼Œåªæ˜¯ç”¨åˆ°äº†rl
stage1 supervisedè®­ç»ƒä¸€ä¸ªåˆå§‹æ¨¡å‹
stage2 self-playäº§ç”Ÿdataï¼Œå¹¶è®­ç»ƒä¸€ä¸ªpolicy model
stage3 ä½¿ç”¨dataè®­ç»ƒvalue model

alphaZero å°†stage1çš„supervisedå»æ‰äº†ï¼›è¶…è¿‡äº†äººç±»æ°´å¹³ï¼›è¯æ˜ä¸éœ€è¦äººç±»çš„å…ˆéªŒçŸ¥è¯†
```

![image-20250415163931405](pic/image-20250415163931405.png)

### background

#### scaling law

```
æ¨¡å‹è¶Šå¤§ï¼Œæ€§èƒ½è¶Šå¼º

GPT: ç›¸æ¯”bert less structureï¼Œæ€§èƒ½æé™æ›´é«˜ scale upï¼ˆdata,model,compute)
```

![image-20250415172011098](pic/image-20250415172011098.png)

#### openAIè®­ç»ƒçš„èŒƒå¼

```
pre-training
post-training:sft,reward model,ppo



DPOä¸éœ€è¦reward model

deepseekåªæœ‰sftå’Œrule-based
rule-basedï¼šå¯¹reward modelçš„è°ƒæ•´ï¼Œä½¿ç»“æœç¬¦åˆruleï¼Œé˜²æ­¢å‡ºç°reward-hacking
```

![image-20250415173527412](pic/image-20250415173527412.png)

![image-20250415174501708](pic/image-20250415174501708.png)

#### emergent ability

```
æ¶Œç°:å½“æ¨¡å‹è¶…è¿‡ä¸€å®šå¤§å°ï¼Œæ€§èƒ½ä¼šæå¤§æé«˜
```

### COTï¼šchain of thought

```
æ—©æœŸçš„llméšç€æ¨¡å‹å¢å¤§ï¼Œæ€§èƒ½å¹¶ä¸æ˜¯ä¸€è‡´å¢å¤§ï¼Œscaling lawå¤±æ•ˆäº†ï¼ˆè¿™æ˜¯å› ä¸ºæ²¡æœ‰cotï¼Œæ²¡æœ‰system2æ€è€ƒï¼‰
```

![image-20250415181610559](pic/image-20250415181610559.png)

#### æ—©æœŸï¼šprompt engineering

```
test timeé˜¶æ®µä½¿ç”¨çš„ï¼šä¸å‚ä¸æ¨¡å‹çš„æ¶æ„

zero-shotï¼šä¸æä¾›èŒƒä¾‹
few-shotï¼šæä¾›å°‘æ•°èŒƒä¾‹ï¼›ä¸åŒ…å«cot
few-shot-cotï¼šæä¾›å°‘æ•°èŒƒä¾‹ï¼›ä½†æ˜¯éœ€è¦äººå·¥æ·»åŠ cot
zero-shot-cotï¼šansweræç¤ºè¯step by step

COT promptingï¼šæœ€å¼ºæ€§èƒ½
```

![image-20250415175833136](pic/image-20250415175833136.png)

```
answer-onlyï¼šå°±æ˜¯few-shot

cot promptingï¼šåœ¨answeré‡Œæ·»åŠ cotå’Œstep by step
```

![image-20250415180438469](pic/image-20250415180438469.png)

#### SFTé˜¶æ®µï¼šæ”¶é›†COTæ ‡æ³¨çš„æ•°æ®è®­ç»ƒå¤§æ¨¡å‹äº§ç”ŸCOT

```
self-consistentï¼šCOT prompting+Qç»™llmç”Ÿæˆå¤šä¸ªA,ä½¿ç”¨majority votingé€‰æ‹©æ­£ç¡®çš„Aï¼›
ç¼ºç‚¹æ˜¯åœ¨inferenceé˜¶æ®µäººä¸ºæ·»åŠ cot

è®­ç»ƒæ¨¡å‹äº§ç”Ÿcotæ•°æ®ï¼Ÿ

SFTé˜¶æ®µè®­ç»ƒæ¨¡å‹äº§ç”Ÿcot
self-trainingï¼šå°†self-consistentç”Ÿäº§çš„QAå¯¹ä½œä¸ºæ–°çš„COT exampleï¼›åœ¨trainé˜¶æ®µè®­ç»ƒæ¨¡å‹äº§ç”Ÿcot
å¤§æ¨¡å‹ç”Ÿæˆæ•°æ®-->ç­›é€‰å‡ºhigh confidenceæ•°æ®-->è®­ç»ƒå¤§æ¨¡å‹ç”Ÿæˆcotæ•°æ®



rlhfé˜¶æ®µè®­ç»ƒæ¨¡å‹äº§ç”Ÿcot
```

![image-20250415180853865](pic/image-20250415180853865.png)

#### RLé˜¶æ®µï¼šè®­ç»ƒå¤§æ¨¡å‹äº§ç”Ÿæ›´å¥½çš„COT

```
RLé€‰å–çš„reward model:outcome reward model ormå’Œprecess reward model prm
reward modelæœ¬è´¨æ˜¯è¯„ä»·cotçš„æ¯ä¸€æ­¥çš„å¥½å
 

COTçš„reward modelæœ‰ä¸¤ç§
åœ¨rlæ¡†æ¶ä¸‹reward model
åœ¨test tiem computeæ¡†æ¶ä¸‹verifierï¼ˆverifieræ˜¯ä¸€ä¸ªllmï¼Œå¯ä»¥åˆ¤æ–­ç”Ÿæˆçš„å¤šä¸ªcotå“ªä¸ªæœ€å¥½ï¼‰
```

![image-20250415181610559](pic/image-20250415181610559.png)

```
test time compute çš„verifier


trainé˜¶æ®µ
è®­ç»ƒgeneratorï¼Œä½¿ç”¨generatorç”Ÿæˆcotï¼Œå°†cotå’Œäººç±»æ ‡æ³¨çš„å¥½åçš„æ•°æ®æ¥è®­ç»ƒverifier
inferenceé˜¶æ®µ
Q->generator->å¤šä¸ªs->verifier->ç”Ÿæˆå¤šä¸ªpï¼Œé€‰æ‹©æœ€å¤§çš„p
ç”±äºæ˜¯åœ¨inference/testé˜¶æ®µè¿›è¡Œçš„ï¼Œæ‰€æœ‰å«test time compute
ç±»ä¼¼self-consistentï¼šä¸åŒçš„æ˜¯å¯¹æ‰€æœ‰çš„é¢„æµ‹sç”¨verifierå¤§æ¨¡å‹å¾—åˆ°scoreï¼Œæœ€åé€‰æ‹©æœ€å¤§çš„scoreä½œä¸ºç»“æœï¼›è€Œä¸æ˜¯ç”¨majority vote


å®éªŒè¯æ˜test time computeå¯ä»¥å¢å¼ºæ¨¡å‹çš„æ€§èƒ½
```

![image-20250415182325807](pic/image-20250415182325807.png)

```
éªŒè¯cotæ˜¯å¦æ­£ç¡®ï¼š 

RL
final answerï¼šç›´æ¥è®¡ç®—æœ€åçš„ç­”æ¡ˆå¥½ä¸å¥½ï¼›é€‰å‡ºyesçš„cot
ormï¼šoutcome reward model  å¯¹æ•´ä¸ªcotæ‰“åˆ†ï¼›é€‰å‡ºæœ€å¥½çš„cot
prmï¼šprocess reward model  å¯¹cotçš„æ¯ä¸€ä¸ªstepæ‰“åˆ†ï¼›é€‰å‡ºæ¯ä¸€æ­¥çš„æœ€ä½³stepï¼Œæ ¹æ®æ­¤stepç”Ÿæˆä¸‹ä¸€step
```

![image-20250415183505052](pic/image-20250415183505052.png)

```
deepseek-R1ä½¿ç”¨çš„æ˜¯ SFT+final answer RL+majority voting
orm å’Œprmçš„ç»“æœæ˜æ˜¾å¥½äºdeepseek-R1
å¯èƒ½æ˜¯å› ä¸ºdeepseek-R1ä½¿ç”¨çš„æ˜¯GRPOï¼Œè€Œä¸”å‚æ•°é‡æ˜¯657B,ç”±äºemerging ability å’Œscaling lawå¯¼è‡´æ€§èƒ½æ›´å¥½
```

![image-20250415183956081](pic/image-20250415183956081.png)

### R1çš„è®­ç»ƒ

```
round1: reasoning


round2: reasoning+general
reasoning dataæ˜¯ç”±round1äº§ç”Ÿçš„dataä¼ ç»™V3æ‰“åˆ†å¾—åˆ°çš„ï¼ˆè¿™ä¸€è¿‡ç¨‹å«rejection samplingï¼›æ‹’ç»é‡‡æ ·ã€Œåªæœ‰é‚£äº›æ­£ç¡®ä¸”æ¨ç†æ¸…æ™°çš„è¾“å‡ºæ‰ä¼šè¢«ä¿ç•™ï¼Œè´¨é‡è¾ƒä½çš„è¾“å‡ºä¼šè¢«ä¸¢å¼ƒã€ï¼‰



å…¶è®­ç»ƒæµç¨‹ï¼Œç®€è¨€ä¹‹ æ˜¯å¾®è°ƒ â†’ RL â†’ å¾®è°ƒ â†’ RLï¼Œå…·ä½“è€Œè¨€æ˜¯
1ï¼šé¦–å…ˆæ”¶é›†äº†æ•°åƒä¸ªå†·å¯åŠ¨æ•°æ®æ¥å¾®è°ƒ DeepSeek-V3-Base æ¨¡å‹
2ï¼šéšåï¼Œè¿›è¡Œç±»ä¼¼ DeepSeek-R1-Zero çš„é¢å‘æ¨ç†çš„å¼ºåŒ–å­¦ä¹ 
3ï¼šå½“å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹æ¥è¿‘æ”¶æ•›æ—¶ï¼Œé€šè¿‡å¯¹ RL æ£€æŸ¥ç‚¹è¿›è¡Œæ‹’ç»é‡‡æ ·ï¼Œç»“åˆ DeepSeek-V3 åœ¨å†™ä½œã€äº‹å®é—®ç­”å’Œè‡ªæˆ‘è®¤çŸ¥ç­‰é¢†åŸŸçš„ç›‘ç£æ•°æ®ï¼Œåˆ›å»ºæ–°çš„ SFT æ•°æ®ï¼Œç„¶åé‡æ–°è®­ç»ƒDeepSeek-V3-Base æ¨¡å‹
4ï¼šåœ¨ç”¨æ–°æ•°æ®å¾®è°ƒåï¼Œæ£€æŸ¥ç‚¹ä¼šç»å†é¢å¤–çš„ RL è¿‡ç¨‹â€”â€”ä¸”ä¼šè€ƒè™‘åˆ°æ‰€æœ‰åœºæ™¯çš„æç¤º
ç»è¿‡è¿™äº›æ­¥éª¤åï¼Œæœ€ç»ˆä¸€ä¸ªç§°ä¸º DeepSeek-R1 çš„checkpointï¼Œå…¶æ€§èƒ½å¯ä»¥ä¸ OpenAI-o1-1217 ç›¸åª²ç¾

SFT (æ•°åƒæ¡cold start data)
RL/GRPO
SFT (ç»“åˆrejection samplingï¼Œ80wçš„æ¨ç†å’Œéæ¨ç†æ•°æ®)
RL/GRPO
```

![image-20250415191159995](pic/image-20250415191159995.png)

![image-20250417230350656](images/image-20250417230350656.png)

### rule-based reward

è§„åˆ™å¥–åŠ±å»ºæ¨¡(å‡†ç¡®æ€§å¥–åŠ± + æ ¼å¼å¥–åŠ±)ï¼šä¸ç”¨è®­ç»ƒä¸“é—¨çš„åå¥½å¥–åŠ±æ¨¡å‹

å¥–åŠ±æ˜¯è®­ç»ƒä¿¡å·çš„æ¥æºï¼Œå®ƒå†³å®šäº†å¼ºåŒ–å­¦ä¹ çš„ä¼˜åŒ–æ–¹å‘

ä¸ºäº†è®­ç»ƒDeepSeek-R1-Zeroï¼Œä½œè€…é‡‡ç”¨äº†ä¸€ä¸ªåŸºäºè§„åˆ™çš„å¥–åŠ±ç³»ç»Ÿ(rule-based reward)ï¼Œä¸»è¦ç”±ä¸¤ç§ç±»å‹çš„å¥–åŠ±ç»„æˆï¼š

**å‡†ç¡®æ€§Accuracyå¥–åŠ±**ï¼šå‡†ç¡®æ€§å¥–åŠ±æ¨¡å‹è¯„ä¼°å“åº”æ˜¯å¦æ­£ç¡®
ä¾‹å¦‚ï¼Œå¯¹äºå…·æœ‰ç¡®å®šæ€§ç»“æœçš„æ•°å­¦é—®é¢˜ï¼Œæ¨¡å‹éœ€è¦ä»¥æŒ‡å®šæ ¼å¼ï¼ˆä¾‹å¦‚ï¼Œæ¡†å†…ï¼‰æä¾›æœ€ç»ˆç­”æ¡ˆï¼Œä»è€Œå®ç°åŸºäºè§„åˆ™çš„æ­£ç¡®æ€§éªŒè¯â€”â€”æ¯•ç«Ÿæ•°å­¦é—®é¢˜çš„ç­”æ¡ˆå…·æœ‰æ˜ç¡®çš„ç»“æœç¡®å®šæ€§ä¸å”¯ä¸€æ€§ï¼Œå¯¹å°±æ˜¯å¯¹ï¼Œé”™å°±æ˜¯é”™
**æ ¼å¼å¥–åŠ±**
é™¤äº†å‡†ç¡®æ€§å¥–åŠ±æ¨¡å‹å¤–ï¼Œä½œè€…è¿˜é‡‡ç”¨äº†æ ¼å¼å¥–åŠ±æ¨¡å‹ï¼Œæ¯”å¦‚è¦æ±‚æ¨¡å‹åœ¨'<think>'å’Œ'</think>'æ ‡ç­¾ä¹‹é—´æ”¾ç½®CoTæ€è€ƒè¿‡ç¨‹
é‚£ä¹ˆï¼Œç³»ç»Ÿä¼šæ£€æŸ¥æ¨¡å‹è¾“å‡ºæ˜¯å¦æ­£ç¡®åœ°å°†æ¨ç†è¿‡ç¨‹åŒ…å«åœ¨<think>â€¦</think>æ ‡ç­¾å†…ï¼Œå¹¶å°†æœ€ç»ˆç­”æ¡ˆåŒ…è£¹åœ¨<answer>â€¦</answer>æ ‡ç­¾ä¸­
è‹¥æ ¼å¼æ­£ç¡®ï¼Œåˆ™æ¨¡å‹å¯ä»¥è·å¾—å¥–åŠ±

**promptæ ¼å¼è¾“å‡º**

```
<think>æ¨ç†è½¨è¿¹COT</think>ï¼Œanswer/response
```

![image-20250417225858096](images/image-20250417225858096.png)

![image-20250417225929873](images/image-20250417225929873.png)

### distilling

```
å…·æœ‰å¼ºæ¨ç†èƒ½åŠ›çš„å¤§æ¨¡å‹è’¸é¦åæ¨ç†èƒ½åŠ›ä»å¼º

å®é™…ä¸ŠR1è’¸é¦ç‰ˆæ¨¡å‹ï¼Œæ˜¯R1çš„æ•°æ®é›† å»å¾®è°ƒå…¶ä»–å®¶çš„æ¨¡å‹
ä¸æ˜¯å…¶ä»–å®¶çš„æ¨¡å‹ æ¥æ•™R1
```

# AI agent

![image-20250423161539410](pic/image-20250423161539410.png)

```
ä¸‰ä¸ªé˜¶æ®µï¼š
reasoning/planing
tools
memory
```

## prompt engineering

### ReAct

```
reason+act

thought
search
```

![image-20250417202603436](D:/RL-study/pic/image-20250417202603436.png)

### reflextion

```
thought
search
reflextionï¼ˆç±»ä¼¼memory)
```

![](D:/RL-study/pic/image-20250417203035968.png)

## æœ€é‡è¦çš„èƒ½åŠ›-ToolCall

ä¹Ÿå«function call

![image-20250423162128045](pic/image-20250423162128045.png)



## MCP

```
ç±»ä¼¼æ¥å£
```

![image-20250417211529486](D:/RL-study/pic/image-20250417211529486.png)





# api-key

```
import requests

#   chatmoss openai
def askllm(content):
    url = "https://api.aihao123.cn/luomacode-api/open-api/v1/chat/completions"
    headers={
        'Content-Type':'application/json',
        'Authorization':'Bearer sk-un661ob05nl5o89smn0i89cpi7idf00v6506nkg0ib1morul'
    }
    data={
        "model": "gpt-3.5-turbo",
        'messages':[
            {
            'role':'user',
            'content':content
            },
        ]
    }
    response=requests.post(url,headers=headers,json=data)
    return response.json()



# api2d openai
def askllm(content):
    url = "https://openai.api2d.net/v1/chat/completions"
    headers={
        'Content-Type':'application/json',
        'Authorization':'Bearer fk231350-Ii7dp2ZelILsfhGBun8kPGjGa7EC5X6I'
    }
    data={
        "model": "gpt-3.5-turbo",
        'messages':[
            {
            'role':'user',
            'content':content
            },
        ]
    }
    response=requests.post(url,headers=headers,json=data)
    return response.json()
```





# LLMå­¦ä¹ è·¯å¾„

## ç¼–ç¨‹åŸºç¡€

### webæ¡†æ¶

Gradioå’ŒStreamlitï¼Œå¿«é€Ÿæ„å»ºå‰ç«¯é¡µé¢

### æ•°æ®åˆ†æå’Œå¯è§†åŒ–

pandasï¼Œmatplotlib,seaborn

### æ•°æ®åº“

mysqlï¼Œredis

